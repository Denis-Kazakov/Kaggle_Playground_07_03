{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d541e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import chime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c220b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chime extension is already loaded. To reload it, use:\n",
      "  %reload_ext chime\n"
     ]
    }
   ],
   "source": [
    "%load_ext chime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679fabfb",
   "metadata": {},
   "source": [
    "# Bayesian search on an XGBoost classifier\n",
    "\n",
    "Kaggle Playground Series - Season 3, Episode 7\n",
    "\n",
    "https://www.kaggle.com/competitions/playground-series-s3e7/overvie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977c5f6",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f6ea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>67.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42095</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42096</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42097</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42098</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42099</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "id                                                                             \n",
       "0                 2               0                     0                  2   \n",
       "1                 2               0                     1                  2   \n",
       "2                 2               0                     0                  1   \n",
       "3                 1               0                     0                  2   \n",
       "4                 2               0                     1                  0   \n",
       "...             ...             ...                   ...                ...   \n",
       "42095             3               0                     0                  4   \n",
       "42096             2               0                     0                  3   \n",
       "42097             2               0                     0                  2   \n",
       "42098             1               0                     0                  3   \n",
       "42099             2               0                     1                  1   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "id                                                                         \n",
       "0                      1                           0                   0   \n",
       "1                      0                           0                   0   \n",
       "2                      0                           0                   0   \n",
       "3                      1                           0                   0   \n",
       "4                      0                           0                   0   \n",
       "...                  ...                         ...                 ...   \n",
       "42095                  0                           0                   1   \n",
       "42096                  0                           0                   0   \n",
       "42097                  2                           0                   0   \n",
       "42098                  0                           0                   0   \n",
       "42099                  0                           0                   1   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "id                                                            \n",
       "0              9          2018              1            14   \n",
       "1            117          2018              7            29   \n",
       "2            315          2018             12             2   \n",
       "3             32          2018             12             1   \n",
       "4            258          2018             10            16   \n",
       "...          ...           ...            ...           ...   \n",
       "42095        160          2018             12            30   \n",
       "42096         34          2017              9            23   \n",
       "42097        292          2018              7            21   \n",
       "42098          5          2018             11             9   \n",
       "42099         40          2017             10            26   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "id                                                                         \n",
       "0                        1               1                            11   \n",
       "1                        0               0                             0   \n",
       "2                        0               0                             0   \n",
       "3                        1               0                             0   \n",
       "4                        0               0                             0   \n",
       "...                    ...             ...                           ...   \n",
       "42095                    1               0                             0   \n",
       "42096                    0               0                             0   \n",
       "42097                    0               0                             0   \n",
       "42098                    0               0                             0   \n",
       "42099                    0               0                             0   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "id                                                                \n",
       "0                                         0               67.50   \n",
       "1                                         0               72.25   \n",
       "2                                         0               52.00   \n",
       "3                                         0               56.00   \n",
       "4                                         0              100.00   \n",
       "...                                     ...                 ...   \n",
       "42095                                     0              140.00   \n",
       "42096                                     0              224.67   \n",
       "42097                                     0               96.00   \n",
       "42098                                     0              120.00   \n",
       "42099                                     0               65.00   \n",
       "\n",
       "       no_of_special_requests  booking_status  \n",
       "id                                             \n",
       "0                           0               0  \n",
       "1                           0               0  \n",
       "2                           0               0  \n",
       "3                           0               0  \n",
       "4                           0               1  \n",
       "...                       ...             ...  \n",
       "42095                       2               1  \n",
       "42096                       0               0  \n",
       "42097                       0               0  \n",
       "42098                       0               0  \n",
       "42099                       0               0  \n",
       "\n",
       "[42100 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv', index_col='id'); train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da75d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='booking_status')\n",
    "y_train = train.booking_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "619417f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>1.294624</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-1.170469</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>-2.330398</td>\n",
       "      <td>-0.214091</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>5.766758</td>\n",
       "      <td>33.699120</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.998052</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>0.161740</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>-0.209778</td>\n",
       "      <td>1.473487</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.870153</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.979466</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>2.604122</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>1.557404</td>\n",
       "      <td>-1.564154</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-1.415406</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.753925</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>1.294624</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-0.886758</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>1.557404</td>\n",
       "      <td>-1.676659</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-1.307702</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>-1.680084</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>1.901012</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.850531</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.122955</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42095</th>\n",
       "      <td>2.056005</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>1.122386</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>0.685890</td>\n",
       "      <td>0.692156</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>1.557404</td>\n",
       "      <td>1.585992</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>1.842849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42096</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>0.421768</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-0.862087</td>\n",
       "      <td>-2.441040</td>\n",
       "      <td>0.497095</td>\n",
       "      <td>0.798456</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>3.233919</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42097</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>2.996268</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>2.320411</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>-0.209778</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.230659</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42098</th>\n",
       "      <td>-1.753925</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>0.421768</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-1.219810</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>1.203968</td>\n",
       "      <td>-0.776617</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>0.415567</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42099</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>-0.979466</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>0.685890</td>\n",
       "      <td>-0.788076</td>\n",
       "      <td>-2.441040</td>\n",
       "      <td>0.850531</td>\n",
       "      <td>1.135971</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-1.065367</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42100 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "id                                                                             \n",
       "0          0.151040       -0.313454             -0.998814          -0.278849   \n",
       "1          0.151040       -0.313454              0.130259          -0.278849   \n",
       "2          0.151040       -0.313454             -0.998814          -0.979466   \n",
       "3         -1.753925       -0.313454             -0.998814          -0.278849   \n",
       "4          0.151040       -0.313454              0.130259          -1.680084   \n",
       "...             ...             ...                   ...                ...   \n",
       "42095      2.056005       -0.313454             -0.998814           1.122386   \n",
       "42096      0.151040       -0.313454             -0.998814           0.421768   \n",
       "42097      0.151040       -0.313454             -0.998814          -0.278849   \n",
       "42098     -1.753925       -0.313454             -0.998814           0.421768   \n",
       "42099      0.151040       -0.313454              0.130259          -0.979466   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "id                                                                         \n",
       "0               1.294624                   -0.160945           -0.515173   \n",
       "1              -0.407020                   -0.160945           -0.515173   \n",
       "2              -0.407020                   -0.160945           -0.515173   \n",
       "3               1.294624                   -0.160945           -0.515173   \n",
       "4              -0.407020                   -0.160945           -0.515173   \n",
       "...                  ...                         ...                 ...   \n",
       "42095          -0.407020                   -0.160945            0.685890   \n",
       "42096          -0.407020                   -0.160945           -0.515173   \n",
       "42097           2.996268                   -0.160945           -0.515173   \n",
       "42098          -0.407020                   -0.160945           -0.515173   \n",
       "42099          -0.407020                   -0.160945            0.685890   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "id                                                            \n",
       "0      -1.170469      0.409661      -2.330398     -0.214091   \n",
       "1       0.161740      0.409661      -0.209778      1.473487   \n",
       "2       2.604122      0.409661       1.557404     -1.564154   \n",
       "3      -0.886758      0.409661       1.557404     -1.676659   \n",
       "4       1.901012      0.409661       0.850531      0.010919   \n",
       "...          ...           ...            ...           ...   \n",
       "42095   0.692156      0.409661       1.557404      1.585992   \n",
       "42096  -0.862087     -2.441040       0.497095      0.798456   \n",
       "42097   2.320411      0.409661      -0.209778      0.573445   \n",
       "42098  -1.219810      0.409661       1.203968     -0.776617   \n",
       "42099  -0.788076     -2.441040       0.850531      1.135971   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "id                                                                         \n",
       "0                 0.428551        5.766758                     33.699120   \n",
       "1                -1.149928       -0.173408                     -0.060506   \n",
       "2                -1.149928       -0.173408                     -0.060506   \n",
       "3                 0.428551       -0.173408                     -0.060506   \n",
       "4                -1.149928       -0.173408                     -0.060506   \n",
       "...                    ...             ...                           ...   \n",
       "42095             0.428551       -0.173408                     -0.060506   \n",
       "42096            -1.149928       -0.173408                     -0.060506   \n",
       "42097            -1.149928       -0.173408                     -0.060506   \n",
       "42098            -1.149928       -0.173408                     -0.060506   \n",
       "42099            -1.149928       -0.173408                     -0.060506   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "id                                                                \n",
       "0                                 -0.101479           -0.998052   \n",
       "1                                 -0.101479           -0.870153   \n",
       "2                                 -0.101479           -1.415406   \n",
       "3                                 -0.101479           -1.307702   \n",
       "4                                 -0.101479           -0.122955   \n",
       "...                                     ...                 ...   \n",
       "42095                             -0.101479            0.954088   \n",
       "42096                             -0.101479            3.233919   \n",
       "42097                             -0.101479           -0.230659   \n",
       "42098                             -0.101479            0.415567   \n",
       "42099                             -0.101479           -1.065367   \n",
       "\n",
       "       no_of_special_requests  \n",
       "id                             \n",
       "0                   -0.737691  \n",
       "1                   -0.737691  \n",
       "2                   -0.737691  \n",
       "3                   -0.737691  \n",
       "4                   -0.737691  \n",
       "...                       ...  \n",
       "42095                1.842849  \n",
       "42096               -0.737691  \n",
       "42097               -0.737691  \n",
       "42098               -0.737691  \n",
       "42099               -0.737691  \n",
       "\n",
       "[42100 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), \n",
    "                       columns=X_train.columns, \n",
    "                       index=X_train.index)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f2e9c",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82e453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8a288",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 25, 50, 75, 100, 150, 250, 500, 700, 750, 1000],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.5, 1],\n",
    "    'reg_alpha': [1e-4, 5e-4, 7e-4, 0.001, 0.005, 0.007, 0.01, 0.02],\n",
    "    'reg_lambda': [0.05, 0.07, 0.1, 0.15, 0.2, 0.3, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "157fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_estimators': Integer(1, 10000, prior='log-uniform', base=10),\n",
    "    'max_depth': Integer(1, 10, prior='uniform'),\n",
    "    'learning_rate': Real(1e-3, 10, prior='log-uniform', base=10),\n",
    "    'reg_alpha': Real(1e-4, 20, prior='log-uniform', base=10),\n",
    "    'reg_lambda': Real(5e-4, 20, prior='log-uniform', base=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d962d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_clf = XGBClassifier(random_state=8,\n",
    "                         max_leaves=0,\n",
    "                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c684e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BayesSearchCV(estimator=xgboost_clf,\n",
    "                       search_spaces=space,\n",
    "                       n_iter=200, \n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=1,\n",
    "                       n_points=1, \n",
    "                       refit=True,\n",
    "                       cv=5,\n",
    "                       verbose=2,\n",
    "                       random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42cfcbdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0018401978299561485, max_depth=5, n_estimators=2, reg_alpha=0.8752908273535527, reg_lambda=0.0005789554753222284; total time=   0.1s\n",
      "[CV] END learning_rate=0.0018401978299561485, max_depth=5, n_estimators=2, reg_alpha=0.8752908273535527, reg_lambda=0.0005789554753222284; total time=   0.0s\n",
      "[CV] END learning_rate=0.0018401978299561485, max_depth=5, n_estimators=2, reg_alpha=0.8752908273535527, reg_lambda=0.0005789554753222284; total time=   0.0s\n",
      "[CV] END learning_rate=0.0018401978299561485, max_depth=5, n_estimators=2, reg_alpha=0.8752908273535527, reg_lambda=0.0005789554753222284; total time=   0.0s\n",
      "[CV] END learning_rate=0.0018401978299561485, max_depth=5, n_estimators=2, reg_alpha=0.8752908273535527, reg_lambda=0.0005789554753222284; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04775037471896593, max_depth=2, n_estimators=1, reg_alpha=0.006682738577394307, reg_lambda=0.0021224106657136725; total time=   0.0s\n",
      "[CV] END learning_rate=0.04775037471896593, max_depth=2, n_estimators=1, reg_alpha=0.006682738577394307, reg_lambda=0.0021224106657136725; total time=   0.0s\n",
      "[CV] END learning_rate=0.04775037471896593, max_depth=2, n_estimators=1, reg_alpha=0.006682738577394307, reg_lambda=0.0021224106657136725; total time=   0.0s\n",
      "[CV] END learning_rate=0.04775037471896593, max_depth=2, n_estimators=1, reg_alpha=0.006682738577394307, reg_lambda=0.0021224106657136725; total time=   0.0s\n",
      "[CV] END learning_rate=0.04775037471896593, max_depth=2, n_estimators=1, reg_alpha=0.006682738577394307, reg_lambda=0.0021224106657136725; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0109886644672866, max_depth=6, n_estimators=1, reg_alpha=0.0012652366015419188, reg_lambda=0.002917107565842082; total time=   0.0s\n",
      "[CV] END learning_rate=0.0109886644672866, max_depth=6, n_estimators=1, reg_alpha=0.0012652366015419188, reg_lambda=0.002917107565842082; total time=   0.0s\n",
      "[CV] END learning_rate=0.0109886644672866, max_depth=6, n_estimators=1, reg_alpha=0.0012652366015419188, reg_lambda=0.002917107565842082; total time=   0.1s\n",
      "[CV] END learning_rate=0.0109886644672866, max_depth=6, n_estimators=1, reg_alpha=0.0012652366015419188, reg_lambda=0.002917107565842082; total time=   0.0s\n",
      "[CV] END learning_rate=0.0109886644672866, max_depth=6, n_estimators=1, reg_alpha=0.0012652366015419188, reg_lambda=0.002917107565842082; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.15849471956708447, max_depth=2, n_estimators=2000, reg_alpha=2.479062495333811, reg_lambda=5.478305695440019; total time=   7.8s\n",
      "[CV] END learning_rate=0.15849471956708447, max_depth=2, n_estimators=2000, reg_alpha=2.479062495333811, reg_lambda=5.478305695440019; total time=   8.1s\n",
      "[CV] END learning_rate=0.15849471956708447, max_depth=2, n_estimators=2000, reg_alpha=2.479062495333811, reg_lambda=5.478305695440019; total time=   6.8s\n",
      "[CV] END learning_rate=0.15849471956708447, max_depth=2, n_estimators=2000, reg_alpha=2.479062495333811, reg_lambda=5.478305695440019; total time=   6.9s\n",
      "[CV] END learning_rate=0.15849471956708447, max_depth=2, n_estimators=2000, reg_alpha=2.479062495333811, reg_lambda=5.478305695440019; total time=   7.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=3.469823215251468, max_depth=8, n_estimators=45, reg_alpha=0.0007583542707431017, reg_lambda=14.01195141659305; total time=   1.1s\n",
      "[CV] END learning_rate=3.469823215251468, max_depth=8, n_estimators=45, reg_alpha=0.0007583542707431017, reg_lambda=14.01195141659305; total time=   1.3s\n",
      "[CV] END learning_rate=3.469823215251468, max_depth=8, n_estimators=45, reg_alpha=0.0007583542707431017, reg_lambda=14.01195141659305; total time=   1.3s\n",
      "[CV] END learning_rate=3.469823215251468, max_depth=8, n_estimators=45, reg_alpha=0.0007583542707431017, reg_lambda=14.01195141659305; total time=   1.3s\n",
      "[CV] END learning_rate=3.469823215251468, max_depth=8, n_estimators=45, reg_alpha=0.0007583542707431017, reg_lambda=14.01195141659305; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001108843124402785, max_depth=3, n_estimators=60, reg_alpha=0.051017924203600365, reg_lambda=0.011472144668532604; total time=   0.3s\n",
      "[CV] END learning_rate=0.001108843124402785, max_depth=3, n_estimators=60, reg_alpha=0.051017924203600365, reg_lambda=0.011472144668532604; total time=   0.3s\n",
      "[CV] END learning_rate=0.001108843124402785, max_depth=3, n_estimators=60, reg_alpha=0.051017924203600365, reg_lambda=0.011472144668532604; total time=   0.3s\n",
      "[CV] END learning_rate=0.001108843124402785, max_depth=3, n_estimators=60, reg_alpha=0.051017924203600365, reg_lambda=0.011472144668532604; total time=   0.3s\n",
      "[CV] END learning_rate=0.001108843124402785, max_depth=3, n_estimators=60, reg_alpha=0.051017924203600365, reg_lambda=0.011472144668532604; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=3.0325150317188085, max_depth=2, n_estimators=11, reg_alpha=3.7936360351306697, reg_lambda=0.030831180890043944; total time=   0.0s\n",
      "[CV] END learning_rate=3.0325150317188085, max_depth=2, n_estimators=11, reg_alpha=3.7936360351306697, reg_lambda=0.030831180890043944; total time=   0.1s\n",
      "[CV] END learning_rate=3.0325150317188085, max_depth=2, n_estimators=11, reg_alpha=3.7936360351306697, reg_lambda=0.030831180890043944; total time=   0.1s\n",
      "[CV] END learning_rate=3.0325150317188085, max_depth=2, n_estimators=11, reg_alpha=3.7936360351306697, reg_lambda=0.030831180890043944; total time=   0.1s\n",
      "[CV] END learning_rate=3.0325150317188085, max_depth=2, n_estimators=11, reg_alpha=3.7936360351306697, reg_lambda=0.030831180890043944; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.40183793368741527, max_depth=9, n_estimators=157, reg_alpha=6.155427409520027, reg_lambda=0.08279950221443577; total time=   2.6s\n",
      "[CV] END learning_rate=0.40183793368741527, max_depth=9, n_estimators=157, reg_alpha=6.155427409520027, reg_lambda=0.08279950221443577; total time=   2.6s\n",
      "[CV] END learning_rate=0.40183793368741527, max_depth=9, n_estimators=157, reg_alpha=6.155427409520027, reg_lambda=0.08279950221443577; total time=   2.5s\n",
      "[CV] END learning_rate=0.40183793368741527, max_depth=9, n_estimators=157, reg_alpha=6.155427409520027, reg_lambda=0.08279950221443577; total time=   2.6s\n",
      "[CV] END learning_rate=0.40183793368741527, max_depth=9, n_estimators=157, reg_alpha=6.155427409520027, reg_lambda=0.08279950221443577; total time=   2.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.053460814116019335, max_depth=2, n_estimators=1304, reg_alpha=0.00011696876200918045, reg_lambda=0.009716172932797825; total time=   4.6s\n",
      "[CV] END learning_rate=0.053460814116019335, max_depth=2, n_estimators=1304, reg_alpha=0.00011696876200918045, reg_lambda=0.009716172932797825; total time=   4.5s\n",
      "[CV] END learning_rate=0.053460814116019335, max_depth=2, n_estimators=1304, reg_alpha=0.00011696876200918045, reg_lambda=0.009716172932797825; total time=   4.5s\n",
      "[CV] END learning_rate=0.053460814116019335, max_depth=2, n_estimators=1304, reg_alpha=0.00011696876200918045, reg_lambda=0.009716172932797825; total time=   4.5s\n",
      "[CV] END learning_rate=0.053460814116019335, max_depth=2, n_estimators=1304, reg_alpha=0.00011696876200918045, reg_lambda=0.009716172932797825; total time=   4.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.03046369014395708, max_depth=9, n_estimators=9994, reg_alpha=8.197970878616989, reg_lambda=5.219314646512801; total time=  54.0s\n",
      "[CV] END learning_rate=0.03046369014395708, max_depth=9, n_estimators=9994, reg_alpha=8.197970878616989, reg_lambda=5.219314646512801; total time=  49.9s\n",
      "[CV] END learning_rate=0.03046369014395708, max_depth=9, n_estimators=9994, reg_alpha=8.197970878616989, reg_lambda=5.219314646512801; total time=  44.3s\n",
      "[CV] END learning_rate=0.03046369014395708, max_depth=9, n_estimators=9994, reg_alpha=8.197970878616989, reg_lambda=5.219314646512801; total time=  52.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.03046369014395708, max_depth=9, n_estimators=9994, reg_alpha=8.197970878616989, reg_lambda=5.219314646512801; total time=  49.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.17338109101824278, max_depth=10, n_estimators=273, reg_alpha=20.0, reg_lambda=0.044855813036894676; total time=   3.7s\n",
      "[CV] END learning_rate=0.17338109101824278, max_depth=10, n_estimators=273, reg_alpha=20.0, reg_lambda=0.044855813036894676; total time=   3.9s\n",
      "[CV] END learning_rate=0.17338109101824278, max_depth=10, n_estimators=273, reg_alpha=20.0, reg_lambda=0.044855813036894676; total time=   3.4s\n",
      "[CV] END learning_rate=0.17338109101824278, max_depth=10, n_estimators=273, reg_alpha=20.0, reg_lambda=0.044855813036894676; total time=   3.6s\n",
      "[CV] END learning_rate=0.17338109101824278, max_depth=10, n_estimators=273, reg_alpha=20.0, reg_lambda=0.044855813036894676; total time=   3.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001312688557856141, max_depth=9, n_estimators=1, reg_alpha=0.0002105016476500929, reg_lambda=0.0019361673053942148; total time=   0.0s\n",
      "[CV] END learning_rate=0.001312688557856141, max_depth=9, n_estimators=1, reg_alpha=0.0002105016476500929, reg_lambda=0.0019361673053942148; total time=   0.0s\n",
      "[CV] END learning_rate=0.001312688557856141, max_depth=9, n_estimators=1, reg_alpha=0.0002105016476500929, reg_lambda=0.0019361673053942148; total time=   0.1s\n",
      "[CV] END learning_rate=0.001312688557856141, max_depth=9, n_estimators=1, reg_alpha=0.0002105016476500929, reg_lambda=0.0019361673053942148; total time=   0.0s\n",
      "[CV] END learning_rate=0.001312688557856141, max_depth=9, n_estimators=1, reg_alpha=0.0002105016476500929, reg_lambda=0.0019361673053942148; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=3628, reg_alpha=0.00018270765003816644, reg_lambda=0.006231678712519676; total time=  16.9s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=3628, reg_alpha=0.00018270765003816644, reg_lambda=0.006231678712519676; total time=  18.4s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=3628, reg_alpha=0.00018270765003816644, reg_lambda=0.006231678712519676; total time=  20.1s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=3628, reg_alpha=0.00018270765003816644, reg_lambda=0.006231678712519676; total time=  24.6s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=3628, reg_alpha=0.00018270765003816644, reg_lambda=0.006231678712519676; total time=  29.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.09789544520912571, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.5s\n",
      "[CV] END learning_rate=0.09789544520912571, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.4s\n",
      "[CV] END learning_rate=0.09789544520912571, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.3s\n",
      "[CV] END learning_rate=0.09789544520912571, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.2s\n",
      "[CV] END learning_rate=0.09789544520912571, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.9min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0861869807366713, max_depth=4, n_estimators=2383, reg_alpha=20.0, reg_lambda=20.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.0861869807366713, max_depth=4, n_estimators=2383, reg_alpha=20.0, reg_lambda=20.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.0861869807366713, max_depth=4, n_estimators=2383, reg_alpha=20.0, reg_lambda=20.0; total time=   7.3s\n",
      "[CV] END learning_rate=0.0861869807366713, max_depth=4, n_estimators=2383, reg_alpha=20.0, reg_lambda=20.0; total time=   7.2s\n",
      "[CV] END learning_rate=0.0861869807366713, max_depth=4, n_estimators=2383, reg_alpha=20.0, reg_lambda=20.0; total time=   7.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.006149069528464854, max_depth=10, n_estimators=264, reg_alpha=0.011063265877131877, reg_lambda=14.227349912211318; total time=   5.3s\n",
      "[CV] END learning_rate=0.006149069528464854, max_depth=10, n_estimators=264, reg_alpha=0.011063265877131877, reg_lambda=14.227349912211318; total time=   5.1s\n",
      "[CV] END learning_rate=0.006149069528464854, max_depth=10, n_estimators=264, reg_alpha=0.011063265877131877, reg_lambda=14.227349912211318; total time=   5.2s\n",
      "[CV] END learning_rate=0.006149069528464854, max_depth=10, n_estimators=264, reg_alpha=0.011063265877131877, reg_lambda=14.227349912211318; total time=   5.4s\n",
      "[CV] END learning_rate=0.006149069528464854, max_depth=10, n_estimators=264, reg_alpha=0.011063265877131877, reg_lambda=14.227349912211318; total time=   5.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11406073617062368, max_depth=1, n_estimators=9952, reg_alpha=0.005500234293111392, reg_lambda=1.3910190299334282; total time=  21.4s\n",
      "[CV] END learning_rate=0.11406073617062368, max_depth=1, n_estimators=9952, reg_alpha=0.005500234293111392, reg_lambda=1.3910190299334282; total time=  21.1s\n",
      "[CV] END learning_rate=0.11406073617062368, max_depth=1, n_estimators=9952, reg_alpha=0.005500234293111392, reg_lambda=1.3910190299334282; total time=  21.0s\n",
      "[CV] END learning_rate=0.11406073617062368, max_depth=1, n_estimators=9952, reg_alpha=0.005500234293111392, reg_lambda=1.3910190299334282; total time=  21.1s\n",
      "[CV] END learning_rate=0.11406073617062368, max_depth=1, n_estimators=9952, reg_alpha=0.005500234293111392, reg_lambda=1.3910190299334282; total time=  21.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.29473758065131167, max_depth=8, n_estimators=1022, reg_alpha=4.554483058040028, reg_lambda=4.235513833088474; total time=   9.2s\n",
      "[CV] END learning_rate=0.29473758065131167, max_depth=8, n_estimators=1022, reg_alpha=4.554483058040028, reg_lambda=4.235513833088474; total time=   9.1s\n",
      "[CV] END learning_rate=0.29473758065131167, max_depth=8, n_estimators=1022, reg_alpha=4.554483058040028, reg_lambda=4.235513833088474; total time=   8.4s\n",
      "[CV] END learning_rate=0.29473758065131167, max_depth=8, n_estimators=1022, reg_alpha=4.554483058040028, reg_lambda=4.235513833088474; total time=   7.4s\n",
      "[CV] END learning_rate=0.29473758065131167, max_depth=8, n_estimators=1022, reg_alpha=4.554483058040028, reg_lambda=4.235513833088474; total time=   9.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1934, reg_alpha=20.0, reg_lambda=20.0; total time=  33.4s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1934, reg_alpha=20.0, reg_lambda=20.0; total time=  33.8s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1934, reg_alpha=20.0, reg_lambda=20.0; total time=  33.5s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1934, reg_alpha=20.0, reg_lambda=20.0; total time=  33.5s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1934, reg_alpha=20.0, reg_lambda=20.0; total time=  33.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.005342327153309056, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.8min\n",
      "[CV] END learning_rate=0.005342327153309056, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.7min\n",
      "[CV] END learning_rate=0.005342327153309056, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.005342327153309056, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.7min\n",
      "[CV] END learning_rate=0.005342327153309056, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.06739009531158872, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.06739009531158872, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.06739009531158872, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.06739009531158872, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.06739009531158872, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.1s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.0s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.5s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.3s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.020356949670801462, max_depth=10, n_estimators=15, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.020356949670801462, max_depth=10, n_estimators=15, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.020356949670801462, max_depth=10, n_estimators=15, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.020356949670801462, max_depth=10, n_estimators=15, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.020356949670801462, max_depth=10, n_estimators=15, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0061714091119037485, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  59.2s\n",
      "[CV] END learning_rate=0.0061714091119037485, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.0061714091119037485, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  59.6s\n",
      "[CV] END learning_rate=0.0061714091119037485, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  57.5s\n",
      "[CV] END learning_rate=0.0061714091119037485, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  58.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.07038318770992195, max_depth=7, n_estimators=1069, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.5s\n",
      "[CV] END learning_rate=0.07038318770992195, max_depth=7, n_estimators=1069, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.5s\n",
      "[CV] END learning_rate=0.07038318770992195, max_depth=7, n_estimators=1069, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.3s\n",
      "[CV] END learning_rate=0.07038318770992195, max_depth=7, n_estimators=1069, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.3s\n",
      "[CV] END learning_rate=0.07038318770992195, max_depth=7, n_estimators=1069, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.18678250947767022, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.18678250947767022, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.18678250947767022, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.18678250947767022, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.18678250947767022, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.14840290025473143, max_depth=4, n_estimators=630, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.14840290025473143, max_depth=4, n_estimators=630, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.14840290025473143, max_depth=4, n_estimators=630, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.14840290025473143, max_depth=4, n_estimators=630, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.14840290025473143, max_depth=4, n_estimators=630, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.10918581670683591, max_depth=6, n_estimators=523, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.10918581670683591, max_depth=6, n_estimators=523, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.3s\n",
      "[CV] END learning_rate=0.10918581670683591, max_depth=6, n_estimators=523, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.1s\n",
      "[CV] END learning_rate=0.10918581670683591, max_depth=6, n_estimators=523, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.10918581670683591, max_depth=6, n_estimators=523, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.00545767384071966, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.00545767384071966, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.00545767384071966, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.00545767384071966, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.00545767384071966, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.9min\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.9min\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.014935073130077891, max_depth=6, n_estimators=590, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.014935073130077891, max_depth=6, n_estimators=590, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.014935073130077891, max_depth=6, n_estimators=590, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.014935073130077891, max_depth=6, n_estimators=590, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.014935073130077891, max_depth=6, n_estimators=590, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.18975763455583003, max_depth=10, n_estimators=49, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.18975763455583003, max_depth=10, n_estimators=49, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.18975763455583003, max_depth=10, n_estimators=49, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.18975763455583003, max_depth=10, n_estimators=49, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.9s\n",
      "[CV] END learning_rate=0.18975763455583003, max_depth=10, n_estimators=49, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.019649201265171518, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.019649201265171518, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.019649201265171518, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.019649201265171518, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.019649201265171518, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11341309261758745, max_depth=8, n_estimators=158, reg_alpha=20.0, reg_lambda=20.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.11341309261758745, max_depth=8, n_estimators=158, reg_alpha=20.0, reg_lambda=20.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.11341309261758745, max_depth=8, n_estimators=158, reg_alpha=20.0, reg_lambda=20.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.11341309261758745, max_depth=8, n_estimators=158, reg_alpha=20.0, reg_lambda=20.0; total time=   2.1s\n",
      "[CV] END learning_rate=0.11341309261758745, max_depth=8, n_estimators=158, reg_alpha=20.0, reg_lambda=20.0; total time=   2.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.03172974651630391, max_depth=10, n_estimators=1140, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.5s\n",
      "[CV] END learning_rate=0.03172974651630391, max_depth=10, n_estimators=1140, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.5s\n",
      "[CV] END learning_rate=0.03172974651630391, max_depth=10, n_estimators=1140, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.6s\n",
      "[CV] END learning_rate=0.03172974651630391, max_depth=10, n_estimators=1140, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.5s\n",
      "[CV] END learning_rate=0.03172974651630391, max_depth=10, n_estimators=1140, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.19148196465122763, max_depth=4, n_estimators=2765, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.6s\n",
      "[CV] END learning_rate=0.19148196465122763, max_depth=4, n_estimators=2765, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.7s\n",
      "[CV] END learning_rate=0.19148196465122763, max_depth=4, n_estimators=2765, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.7s\n",
      "[CV] END learning_rate=0.19148196465122763, max_depth=4, n_estimators=2765, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.5s\n",
      "[CV] END learning_rate=0.19148196465122763, max_depth=4, n_estimators=2765, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0027529225658900957, max_depth=7, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.0027529225658900957, max_depth=7, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.0027529225658900957, max_depth=7, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.0027529225658900957, max_depth=7, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.0027529225658900957, max_depth=7, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=1, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0077502720401618356, max_depth=10, n_estimators=2, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.0077502720401618356, max_depth=10, n_estimators=2, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.0077502720401618356, max_depth=10, n_estimators=2, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.0077502720401618356, max_depth=10, n_estimators=2, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.0077502720401618356, max_depth=10, n_estimators=2, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.004130402667847527, max_depth=7, n_estimators=22, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.004130402667847527, max_depth=7, n_estimators=22, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.004130402667847527, max_depth=7, n_estimators=22, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.004130402667847527, max_depth=7, n_estimators=22, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.004130402667847527, max_depth=7, n_estimators=22, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.010035976181534198, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.0min\n",
      "[CV] END learning_rate=0.010035976181534198, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.0min\n",
      "[CV] END learning_rate=0.010035976181534198, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.0min\n",
      "[CV] END learning_rate=0.010035976181534198, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.0min\n",
      "[CV] END learning_rate=0.010035976181534198, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.16756949187037434, max_depth=10, n_estimators=60, reg_alpha=0.0001, reg_lambda=0.0005; total time=   1.1s\n",
      "[CV] END learning_rate=0.16756949187037434, max_depth=10, n_estimators=60, reg_alpha=0.0001, reg_lambda=0.0005; total time=   1.2s\n",
      "[CV] END learning_rate=0.16756949187037434, max_depth=10, n_estimators=60, reg_alpha=0.0001, reg_lambda=0.0005; total time=   1.3s\n",
      "[CV] END learning_rate=0.16756949187037434, max_depth=10, n_estimators=60, reg_alpha=0.0001, reg_lambda=0.0005; total time=   1.1s\n",
      "[CV] END learning_rate=0.16756949187037434, max_depth=10, n_estimators=60, reg_alpha=0.0001, reg_lambda=0.0005; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.14811776228149856, max_depth=3, n_estimators=1770, reg_alpha=0.0001, reg_lambda=0.0005; total time=   8.3s\n",
      "[CV] END learning_rate=0.14811776228149856, max_depth=3, n_estimators=1770, reg_alpha=0.0001, reg_lambda=0.0005; total time=   8.5s\n",
      "[CV] END learning_rate=0.14811776228149856, max_depth=3, n_estimators=1770, reg_alpha=0.0001, reg_lambda=0.0005; total time=   8.6s\n",
      "[CV] END learning_rate=0.14811776228149856, max_depth=3, n_estimators=1770, reg_alpha=0.0001, reg_lambda=0.0005; total time=   8.3s\n",
      "[CV] END learning_rate=0.14811776228149856, max_depth=3, n_estimators=1770, reg_alpha=0.0001, reg_lambda=0.0005; total time=   8.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.001, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.001, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.001, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.001, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04313574619127561, max_depth=4, n_estimators=133, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.9s\n",
      "[CV] END learning_rate=0.04313574619127561, max_depth=4, n_estimators=133, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.9s\n",
      "[CV] END learning_rate=0.04313574619127561, max_depth=4, n_estimators=133, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.9s\n",
      "[CV] END learning_rate=0.04313574619127561, max_depth=4, n_estimators=133, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.9s\n",
      "[CV] END learning_rate=0.04313574619127561, max_depth=4, n_estimators=133, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.01813456223998776, max_depth=8, n_estimators=2158, reg_alpha=20.0, reg_lambda=20.0; total time=  26.7s\n",
      "[CV] END learning_rate=0.01813456223998776, max_depth=8, n_estimators=2158, reg_alpha=20.0, reg_lambda=20.0; total time=  27.5s\n",
      "[CV] END learning_rate=0.01813456223998776, max_depth=8, n_estimators=2158, reg_alpha=20.0, reg_lambda=20.0; total time=  27.2s\n",
      "[CV] END learning_rate=0.01813456223998776, max_depth=8, n_estimators=2158, reg_alpha=20.0, reg_lambda=20.0; total time=  27.0s\n",
      "[CV] END learning_rate=0.01813456223998776, max_depth=8, n_estimators=2158, reg_alpha=20.0, reg_lambda=20.0; total time=  27.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.7650466579461475, max_depth=1, n_estimators=10000, reg_alpha=5.088988619256869, reg_lambda=0.0005; total time=  21.4s\n",
      "[CV] END learning_rate=0.7650466579461475, max_depth=1, n_estimators=10000, reg_alpha=5.088988619256869, reg_lambda=0.0005; total time=  21.7s\n",
      "[CV] END learning_rate=0.7650466579461475, max_depth=1, n_estimators=10000, reg_alpha=5.088988619256869, reg_lambda=0.0005; total time=  21.8s\n",
      "[CV] END learning_rate=0.7650466579461475, max_depth=1, n_estimators=10000, reg_alpha=5.088988619256869, reg_lambda=0.0005; total time=  21.5s\n",
      "[CV] END learning_rate=0.7650466579461475, max_depth=1, n_estimators=10000, reg_alpha=5.088988619256869, reg_lambda=0.0005; total time=  21.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=13, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=13, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=13, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=13, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=13, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.25754217657164025, max_depth=1, n_estimators=1555, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.25754217657164025, max_depth=1, n_estimators=1555, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.25754217657164025, max_depth=1, n_estimators=1555, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.4s\n",
      "[CV] END learning_rate=0.25754217657164025, max_depth=1, n_estimators=1555, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.25754217657164025, max_depth=1, n_estimators=1555, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.42784671354059395, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  20.8s\n",
      "[CV] END learning_rate=0.42784671354059395, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  20.8s\n",
      "[CV] END learning_rate=0.42784671354059395, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  20.7s\n",
      "[CV] END learning_rate=0.42784671354059395, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  20.6s\n",
      "[CV] END learning_rate=0.42784671354059395, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  20.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.003033377232405915, max_depth=4, n_estimators=2399, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.7s\n",
      "[CV] END learning_rate=0.003033377232405915, max_depth=4, n_estimators=2399, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.6s\n",
      "[CV] END learning_rate=0.003033377232405915, max_depth=4, n_estimators=2399, reg_alpha=0.0001, reg_lambda=20.0; total time=  15.0s\n",
      "[CV] END learning_rate=0.003033377232405915, max_depth=4, n_estimators=2399, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.7s\n",
      "[CV] END learning_rate=0.003033377232405915, max_depth=4, n_estimators=2399, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.2282962144199754, max_depth=10, n_estimators=218, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.2282962144199754, max_depth=10, n_estimators=218, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.2282962144199754, max_depth=10, n_estimators=218, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.2282962144199754, max_depth=10, n_estimators=218, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.6s\n",
      "[CV] END learning_rate=0.2282962144199754, max_depth=10, n_estimators=218, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.014596090701271647, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  56.2s\n",
      "[CV] END learning_rate=0.014596090701271647, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.2min\n",
      "[CV] END learning_rate=0.014596090701271647, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  57.7s\n",
      "[CV] END learning_rate=0.014596090701271647, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.014596090701271647, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 1.1min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.008196895645610212, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.0s\n",
      "[CV] END learning_rate=0.008196895645610212, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  24.6s\n",
      "[CV] END learning_rate=0.008196895645610212, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.2s\n",
      "[CV] END learning_rate=0.008196895645610212, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.1s\n",
      "[CV] END learning_rate=0.008196895645610212, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.16906346252299517, max_depth=5, n_estimators=1170, reg_alpha=20.0, reg_lambda=20.0; total time=   4.2s\n",
      "[CV] END learning_rate=0.16906346252299517, max_depth=5, n_estimators=1170, reg_alpha=20.0, reg_lambda=20.0; total time=   4.1s\n",
      "[CV] END learning_rate=0.16906346252299517, max_depth=5, n_estimators=1170, reg_alpha=20.0, reg_lambda=20.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.16906346252299517, max_depth=5, n_estimators=1170, reg_alpha=20.0, reg_lambda=20.0; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.16906346252299517, max_depth=5, n_estimators=1170, reg_alpha=20.0, reg_lambda=20.0; total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.06963711592468892, max_depth=9, n_estimators=1699, reg_alpha=20.0, reg_lambda=20.0; total time=  12.4s\n",
      "[CV] END learning_rate=0.06963711592468892, max_depth=9, n_estimators=1699, reg_alpha=20.0, reg_lambda=20.0; total time=  12.1s\n",
      "[CV] END learning_rate=0.06963711592468892, max_depth=9, n_estimators=1699, reg_alpha=20.0, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.06963711592468892, max_depth=9, n_estimators=1699, reg_alpha=20.0, reg_lambda=20.0; total time=  10.5s\n",
      "[CV] END learning_rate=0.06963711592468892, max_depth=9, n_estimators=1699, reg_alpha=20.0, reg_lambda=20.0; total time=  10.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1660275397471232, max_depth=8, n_estimators=317, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.1s\n",
      "[CV] END learning_rate=0.1660275397471232, max_depth=8, n_estimators=317, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.1s\n",
      "[CV] END learning_rate=0.1660275397471232, max_depth=8, n_estimators=317, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.3s\n",
      "[CV] END learning_rate=0.1660275397471232, max_depth=8, n_estimators=317, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.1s\n",
      "[CV] END learning_rate=0.1660275397471232, max_depth=8, n_estimators=317, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.043068819355897715, max_depth=10, n_estimators=286, reg_alpha=20.0, reg_lambda=20.0; total time=   4.9s\n",
      "[CV] END learning_rate=0.043068819355897715, max_depth=10, n_estimators=286, reg_alpha=20.0, reg_lambda=20.0; total time=   4.9s\n",
      "[CV] END learning_rate=0.043068819355897715, max_depth=10, n_estimators=286, reg_alpha=20.0, reg_lambda=20.0; total time=   4.9s\n",
      "[CV] END learning_rate=0.043068819355897715, max_depth=10, n_estimators=286, reg_alpha=20.0, reg_lambda=20.0; total time=   4.9s\n",
      "[CV] END learning_rate=0.043068819355897715, max_depth=10, n_estimators=286, reg_alpha=20.0, reg_lambda=20.0; total time=   4.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=5.718549649667721, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.0s\n",
      "[CV] END learning_rate=5.718549649667721, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.5s\n",
      "[CV] END learning_rate=5.718549649667721, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.7s\n",
      "[CV] END learning_rate=5.718549649667721, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.6s\n",
      "[CV] END learning_rate=5.718549649667721, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.9454616635021323, max_depth=10, n_estimators=2951, reg_alpha=0.0001, reg_lambda=20.0; total time=  50.9s\n",
      "[CV] END learning_rate=0.9454616635021323, max_depth=10, n_estimators=2951, reg_alpha=0.0001, reg_lambda=20.0; total time=  51.1s\n",
      "[CV] END learning_rate=0.9454616635021323, max_depth=10, n_estimators=2951, reg_alpha=0.0001, reg_lambda=20.0; total time=  51.0s\n",
      "[CV] END learning_rate=0.9454616635021323, max_depth=10, n_estimators=2951, reg_alpha=0.0001, reg_lambda=20.0; total time=  51.1s\n",
      "[CV] END learning_rate=0.9454616635021323, max_depth=10, n_estimators=2951, reg_alpha=0.0001, reg_lambda=20.0; total time=  50.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04238397090553021, max_depth=5, n_estimators=3260, reg_alpha=0.0001, reg_lambda=20.0; total time=  24.0s\n",
      "[CV] END learning_rate=0.04238397090553021, max_depth=5, n_estimators=3260, reg_alpha=0.0001, reg_lambda=20.0; total time=  24.3s\n",
      "[CV] END learning_rate=0.04238397090553021, max_depth=5, n_estimators=3260, reg_alpha=0.0001, reg_lambda=20.0; total time=  24.1s\n",
      "[CV] END learning_rate=0.04238397090553021, max_depth=5, n_estimators=3260, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.0s\n",
      "[CV] END learning_rate=0.04238397090553021, max_depth=5, n_estimators=3260, reg_alpha=0.0001, reg_lambda=20.0; total time=  24.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.9035085654285926, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.9035085654285926, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.9035085654285926, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.9035085654285926, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=0.9035085654285926, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=20.0; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0017004932617870523, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.8min\n",
      "[CV] END learning_rate=0.0017004932617870523, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.0017004932617870523, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.0017004932617870523, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.0017004932617870523, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0017158382318527754, max_depth=5, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.0017158382318527754, max_depth=5, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.0017158382318527754, max_depth=5, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.0017158382318527754, max_depth=5, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.3min\n",
      "[CV] END learning_rate=0.0017158382318527754, max_depth=5, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.3min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.028181108839379757, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.5s\n",
      "[CV] END learning_rate=0.028181108839379757, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.4s\n",
      "[CV] END learning_rate=0.028181108839379757, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.3s\n",
      "[CV] END learning_rate=0.028181108839379757, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.6s\n",
      "[CV] END learning_rate=0.028181108839379757, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.7184685639739852, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.7184685639739852, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.7184685639739852, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.7184685639739852, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.1min\n",
      "[CV] END learning_rate=0.7184685639739852, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.040394664989858775, max_depth=8, n_estimators=1223, reg_alpha=0.0001, reg_lambda=0.0005; total time=  15.9s\n",
      "[CV] END learning_rate=0.040394664989858775, max_depth=8, n_estimators=1223, reg_alpha=0.0001, reg_lambda=0.0005; total time=  15.9s\n",
      "[CV] END learning_rate=0.040394664989858775, max_depth=8, n_estimators=1223, reg_alpha=0.0001, reg_lambda=0.0005; total time=  16.1s\n",
      "[CV] END learning_rate=0.040394664989858775, max_depth=8, n_estimators=1223, reg_alpha=0.0001, reg_lambda=0.0005; total time=  16.9s\n",
      "[CV] END learning_rate=0.040394664989858775, max_depth=8, n_estimators=1223, reg_alpha=0.0001, reg_lambda=0.0005; total time=  15.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04577712414837843, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.04577712414837843, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.8min\n",
      "[CV] END learning_rate=0.04577712414837843, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.04577712414837843, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.04577712414837843, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.47109087598161237, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.5s\n",
      "[CV] END learning_rate=0.47109087598161237, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.1s\n",
      "[CV] END learning_rate=0.47109087598161237, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.5s\n",
      "[CV] END learning_rate=0.47109087598161237, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.3s\n",
      "[CV] END learning_rate=0.47109087598161237, max_depth=1, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  21.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.3284284938389702, max_depth=10, n_estimators=18, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.3284284938389702, max_depth=10, n_estimators=18, reg_alpha=20.0, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.3284284938389702, max_depth=10, n_estimators=18, reg_alpha=20.0, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.3284284938389702, max_depth=10, n_estimators=18, reg_alpha=20.0, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.3284284938389702, max_depth=10, n_estimators=18, reg_alpha=20.0, reg_lambda=20.0; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.013495839395711872, max_depth=10, n_estimators=962, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.4s\n",
      "[CV] END learning_rate=0.013495839395711872, max_depth=10, n_estimators=962, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.5s\n",
      "[CV] END learning_rate=0.013495839395711872, max_depth=10, n_estimators=962, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.4s\n",
      "[CV] END learning_rate=0.013495839395711872, max_depth=10, n_estimators=962, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.6s\n",
      "[CV] END learning_rate=0.013495839395711872, max_depth=10, n_estimators=962, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04573043934956196, max_depth=4, n_estimators=5791, reg_alpha=20.0, reg_lambda=0.0005; total time=  16.0s\n",
      "[CV] END learning_rate=0.04573043934956196, max_depth=4, n_estimators=5791, reg_alpha=20.0, reg_lambda=0.0005; total time=  15.8s\n",
      "[CV] END learning_rate=0.04573043934956196, max_depth=4, n_estimators=5791, reg_alpha=20.0, reg_lambda=0.0005; total time=  15.6s\n",
      "[CV] END learning_rate=0.04573043934956196, max_depth=4, n_estimators=5791, reg_alpha=20.0, reg_lambda=0.0005; total time=  15.5s\n",
      "[CV] END learning_rate=0.04573043934956196, max_depth=4, n_estimators=5791, reg_alpha=20.0, reg_lambda=0.0005; total time=  15.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.7154404625657926, max_depth=10, n_estimators=75, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.3s\n",
      "[CV] END learning_rate=0.7154404625657926, max_depth=10, n_estimators=75, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.4s\n",
      "[CV] END learning_rate=0.7154404625657926, max_depth=10, n_estimators=75, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.4s\n",
      "[CV] END learning_rate=0.7154404625657926, max_depth=10, n_estimators=75, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.3s\n",
      "[CV] END learning_rate=0.7154404625657926, max_depth=10, n_estimators=75, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.3488937007950088, max_depth=4, n_estimators=499, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.7s\n",
      "[CV] END learning_rate=0.3488937007950088, max_depth=4, n_estimators=499, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.8s\n",
      "[CV] END learning_rate=0.3488937007950088, max_depth=4, n_estimators=499, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.7s\n",
      "[CV] END learning_rate=0.3488937007950088, max_depth=4, n_estimators=499, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.7s\n",
      "[CV] END learning_rate=0.3488937007950088, max_depth=4, n_estimators=499, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.08998536076495872, max_depth=10, n_estimators=205, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.6s\n",
      "[CV] END learning_rate=0.08998536076495872, max_depth=10, n_estimators=205, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.08998536076495872, max_depth=10, n_estimators=205, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.08998536076495872, max_depth=10, n_estimators=205, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.08998536076495872, max_depth=10, n_estimators=205, reg_alpha=0.0001, reg_lambda=20.0; total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.018554995142759406, max_depth=3, n_estimators=818, reg_alpha=20.0, reg_lambda=20.0; total time=   4.2s\n",
      "[CV] END learning_rate=0.018554995142759406, max_depth=3, n_estimators=818, reg_alpha=20.0, reg_lambda=20.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.018554995142759406, max_depth=3, n_estimators=818, reg_alpha=20.0, reg_lambda=20.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.018554995142759406, max_depth=3, n_estimators=818, reg_alpha=20.0, reg_lambda=20.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.018554995142759406, max_depth=3, n_estimators=818, reg_alpha=20.0, reg_lambda=20.0; total time=   3.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0041669697398410595, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.0041669697398410595, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.0041669697398410595, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.0041669697398410595, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.0041669697398410595, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.22247428823405024, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.22247428823405024, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.8s\n",
      "[CV] END learning_rate=0.22247428823405024, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.7s\n",
      "[CV] END learning_rate=0.22247428823405024, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.8s\n",
      "[CV] END learning_rate=0.22247428823405024, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.002739365231054363, max_depth=2, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.25809019114503556; total time=  34.7s\n",
      "[CV] END learning_rate=0.002739365231054363, max_depth=2, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.25809019114503556; total time=  33.3s\n",
      "[CV] END learning_rate=0.002739365231054363, max_depth=2, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.25809019114503556; total time=  33.0s\n",
      "[CV] END learning_rate=0.002739365231054363, max_depth=2, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.25809019114503556; total time=  33.3s\n",
      "[CV] END learning_rate=0.002739365231054363, max_depth=2, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.25809019114503556; total time=  33.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=11, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=11, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=11, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=11, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, max_depth=7, n_estimators=11, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=0.040801417148340006, reg_lambda=11.900382907428853; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=0.040801417148340006, reg_lambda=11.900382907428853; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=0.040801417148340006, reg_lambda=11.900382907428853; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=0.040801417148340006, reg_lambda=11.900382907428853; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=0.040801417148340006, reg_lambda=11.900382907428853; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=4.1312731903365965, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=4.1312731903365965, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=4.1312731903365965, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=4.1312731903365965, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=4.1312731903365965, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.01948938170499613, max_depth=10, n_estimators=2867, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.1s\n",
      "[CV] END learning_rate=0.01948938170499613, max_depth=10, n_estimators=2867, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.3s\n",
      "[CV] END learning_rate=0.01948938170499613, max_depth=10, n_estimators=2867, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.0s\n",
      "[CV] END learning_rate=0.01948938170499613, max_depth=10, n_estimators=2867, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.4s\n",
      "[CV] END learning_rate=0.01948938170499613, max_depth=10, n_estimators=2867, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.4570517411845413, max_depth=10, n_estimators=352, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.9s\n",
      "[CV] END learning_rate=0.4570517411845413, max_depth=10, n_estimators=352, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.9s\n",
      "[CV] END learning_rate=0.4570517411845413, max_depth=10, n_estimators=352, reg_alpha=20.0, reg_lambda=0.0005; total time=   2.1s\n",
      "[CV] END learning_rate=0.4570517411845413, max_depth=10, n_estimators=352, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.8s\n",
      "[CV] END learning_rate=0.4570517411845413, max_depth=10, n_estimators=352, reg_alpha=20.0, reg_lambda=0.0005; total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.007976470863263863, max_depth=7, n_estimators=997, reg_alpha=20.0, reg_lambda=0.0005; total time=  11.3s\n",
      "[CV] END learning_rate=0.007976470863263863, max_depth=7, n_estimators=997, reg_alpha=20.0, reg_lambda=0.0005; total time=  11.4s\n",
      "[CV] END learning_rate=0.007976470863263863, max_depth=7, n_estimators=997, reg_alpha=20.0, reg_lambda=0.0005; total time=  11.2s\n",
      "[CV] END learning_rate=0.007976470863263863, max_depth=7, n_estimators=997, reg_alpha=20.0, reg_lambda=0.0005; total time=  11.3s\n",
      "[CV] END learning_rate=0.007976470863263863, max_depth=7, n_estimators=997, reg_alpha=20.0, reg_lambda=0.0005; total time=  11.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04859118090742695, max_depth=6, n_estimators=1539, reg_alpha=20.0, reg_lambda=20.0; total time=   9.5s\n",
      "[CV] END learning_rate=0.04859118090742695, max_depth=6, n_estimators=1539, reg_alpha=20.0, reg_lambda=20.0; total time=   8.8s\n",
      "[CV] END learning_rate=0.04859118090742695, max_depth=6, n_estimators=1539, reg_alpha=20.0, reg_lambda=20.0; total time=   8.9s\n",
      "[CV] END learning_rate=0.04859118090742695, max_depth=6, n_estimators=1539, reg_alpha=20.0, reg_lambda=20.0; total time=   9.1s\n",
      "[CV] END learning_rate=0.04859118090742695, max_depth=6, n_estimators=1539, reg_alpha=20.0, reg_lambda=20.0; total time=   9.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1904290200815168, max_depth=3, n_estimators=1130, reg_alpha=20.0, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.1904290200815168, max_depth=3, n_estimators=1130, reg_alpha=20.0, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.1904290200815168, max_depth=3, n_estimators=1130, reg_alpha=20.0, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.1904290200815168, max_depth=3, n_estimators=1130, reg_alpha=20.0, reg_lambda=20.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.1904290200815168, max_depth=3, n_estimators=1130, reg_alpha=20.0, reg_lambda=20.0; total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.5213002762216784, max_depth=10, n_estimators=99, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.5213002762216784, max_depth=10, n_estimators=99, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.5213002762216784, max_depth=10, n_estimators=99, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.5213002762216784, max_depth=10, n_estimators=99, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.5213002762216784, max_depth=10, n_estimators=99, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.12165529713647782, max_depth=4, n_estimators=2045, reg_alpha=0.0001, reg_lambda=0.0005; total time=  12.4s\n",
      "[CV] END learning_rate=0.12165529713647782, max_depth=4, n_estimators=2045, reg_alpha=0.0001, reg_lambda=0.0005; total time=  12.4s\n",
      "[CV] END learning_rate=0.12165529713647782, max_depth=4, n_estimators=2045, reg_alpha=0.0001, reg_lambda=0.0005; total time=  12.6s\n",
      "[CV] END learning_rate=0.12165529713647782, max_depth=4, n_estimators=2045, reg_alpha=0.0001, reg_lambda=0.0005; total time=  12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.12165529713647782, max_depth=4, n_estimators=2045, reg_alpha=0.0001, reg_lambda=0.0005; total time=  12.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.010532113750520794, max_depth=8, n_estimators=71, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.0s\n",
      "[CV] END learning_rate=0.010532113750520794, max_depth=8, n_estimators=71, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.010532113750520794, max_depth=8, n_estimators=71, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.1s\n",
      "[CV] END learning_rate=0.010532113750520794, max_depth=8, n_estimators=71, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.2s\n",
      "[CV] END learning_rate=0.010532113750520794, max_depth=8, n_estimators=71, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.46565290212189875, max_depth=2, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.0s\n",
      "[CV] END learning_rate=0.46565290212189875, max_depth=2, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.3s\n",
      "[CV] END learning_rate=0.46565290212189875, max_depth=2, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.4s\n",
      "[CV] END learning_rate=0.46565290212189875, max_depth=2, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.3s\n",
      "[CV] END learning_rate=0.46565290212189875, max_depth=2, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1047298113212015, max_depth=8, n_estimators=961, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.1047298113212015, max_depth=8, n_estimators=961, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.1047298113212015, max_depth=8, n_estimators=961, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.9s\n",
      "[CV] END learning_rate=0.1047298113212015, max_depth=8, n_estimators=961, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.9s\n",
      "[CV] END learning_rate=0.1047298113212015, max_depth=8, n_estimators=961, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001621148638881471, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.001621148638881471, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.001621148638881471, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.001621148638881471, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.001621148638881471, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.06215286585444832, max_depth=4, n_estimators=1795, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.06215286585444832, max_depth=4, n_estimators=1795, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.06215286585444832, max_depth=4, n_estimators=1795, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.1s\n",
      "[CV] END learning_rate=0.06215286585444832, max_depth=4, n_estimators=1795, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.8s\n",
      "[CV] END learning_rate=0.06215286585444832, max_depth=4, n_estimators=1795, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.007292275047604279, max_depth=3, n_estimators=34, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.007292275047604279, max_depth=3, n_estimators=34, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.007292275047604279, max_depth=3, n_estimators=34, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.007292275047604279, max_depth=3, n_estimators=34, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "[CV] END learning_rate=0.007292275047604279, max_depth=3, n_estimators=34, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11145896464579017, max_depth=10, n_estimators=302, reg_alpha=20.0, reg_lambda=20.0; total time=   4.9s\n",
      "[CV] END learning_rate=0.11145896464579017, max_depth=10, n_estimators=302, reg_alpha=20.0, reg_lambda=20.0; total time=   5.0s\n",
      "[CV] END learning_rate=0.11145896464579017, max_depth=10, n_estimators=302, reg_alpha=20.0, reg_lambda=20.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.11145896464579017, max_depth=10, n_estimators=302, reg_alpha=20.0, reg_lambda=20.0; total time=   5.0s\n",
      "[CV] END learning_rate=0.11145896464579017, max_depth=10, n_estimators=302, reg_alpha=20.0, reg_lambda=20.0; total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.03812770924983707, max_depth=4, n_estimators=1763, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.8s\n",
      "[CV] END learning_rate=0.03812770924983707, max_depth=4, n_estimators=1763, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.0s\n",
      "[CV] END learning_rate=0.03812770924983707, max_depth=4, n_estimators=1763, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.03812770924983707, max_depth=4, n_estimators=1763, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.03812770924983707, max_depth=4, n_estimators=1763, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.25871356463167405, max_depth=5, n_estimators=947, reg_alpha=0.0001, reg_lambda=0.0005; total time=   7.4s\n",
      "[CV] END learning_rate=0.25871356463167405, max_depth=5, n_estimators=947, reg_alpha=0.0001, reg_lambda=0.0005; total time=   7.2s\n",
      "[CV] END learning_rate=0.25871356463167405, max_depth=5, n_estimators=947, reg_alpha=0.0001, reg_lambda=0.0005; total time=   7.3s\n",
      "[CV] END learning_rate=0.25871356463167405, max_depth=5, n_estimators=947, reg_alpha=0.0001, reg_lambda=0.0005; total time=   7.3s\n",
      "[CV] END learning_rate=0.25871356463167405, max_depth=5, n_estimators=947, reg_alpha=0.0001, reg_lambda=0.0005; total time=   7.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001906036448084584, max_depth=8, n_estimators=232, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.001906036448084584, max_depth=8, n_estimators=232, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.8s\n",
      "[CV] END learning_rate=0.001906036448084584, max_depth=8, n_estimators=232, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "[CV] END learning_rate=0.001906036448084584, max_depth=8, n_estimators=232, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.6s\n",
      "[CV] END learning_rate=0.001906036448084584, max_depth=8, n_estimators=232, reg_alpha=0.0001, reg_lambda=0.0005; total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.005768921618010274, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.005768921618010274, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.005768921618010274, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.005768921618010274, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.005768921618010274, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.2348072523278025, max_depth=6, n_estimators=46, reg_alpha=20.0, reg_lambda=20.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.2348072523278025, max_depth=6, n_estimators=46, reg_alpha=20.0, reg_lambda=20.0; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2348072523278025, max_depth=6, n_estimators=46, reg_alpha=20.0, reg_lambda=20.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.2348072523278025, max_depth=6, n_estimators=46, reg_alpha=20.0, reg_lambda=20.0; total time=   0.5s\n",
      "[CV] END learning_rate=0.2348072523278025, max_depth=6, n_estimators=46, reg_alpha=20.0, reg_lambda=20.0; total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.01187494864821934, max_depth=9, n_estimators=3205, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.4s\n",
      "[CV] END learning_rate=0.01187494864821934, max_depth=9, n_estimators=3205, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.8s\n",
      "[CV] END learning_rate=0.01187494864821934, max_depth=9, n_estimators=3205, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.9s\n",
      "[CV] END learning_rate=0.01187494864821934, max_depth=9, n_estimators=3205, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.2s\n",
      "[CV] END learning_rate=0.01187494864821934, max_depth=9, n_estimators=3205, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.5464246143828948, max_depth=2, n_estimators=1428, reg_alpha=20.0, reg_lambda=20.0; total time=   3.3s\n",
      "[CV] END learning_rate=0.5464246143828948, max_depth=2, n_estimators=1428, reg_alpha=20.0, reg_lambda=20.0; total time=   3.3s\n",
      "[CV] END learning_rate=0.5464246143828948, max_depth=2, n_estimators=1428, reg_alpha=20.0, reg_lambda=20.0; total time=   3.2s\n",
      "[CV] END learning_rate=0.5464246143828948, max_depth=2, n_estimators=1428, reg_alpha=20.0, reg_lambda=20.0; total time=   3.3s\n",
      "[CV] END learning_rate=0.5464246143828948, max_depth=2, n_estimators=1428, reg_alpha=20.0, reg_lambda=20.0; total time=   3.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.01060810092448071, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.9s\n",
      "[CV] END learning_rate=0.01060810092448071, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.1s\n",
      "[CV] END learning_rate=0.01060810092448071, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.5s\n",
      "[CV] END learning_rate=0.01060810092448071, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.5s\n",
      "[CV] END learning_rate=0.01060810092448071, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.06136069888841554, max_depth=8, n_estimators=98, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.4s\n",
      "[CV] END learning_rate=0.06136069888841554, max_depth=8, n_estimators=98, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.5s\n",
      "[CV] END learning_rate=0.06136069888841554, max_depth=8, n_estimators=98, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.5s\n",
      "[CV] END learning_rate=0.06136069888841554, max_depth=8, n_estimators=98, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.4s\n",
      "[CV] END learning_rate=0.06136069888841554, max_depth=8, n_estimators=98, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.008893562367065913, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.5min\n",
      "[CV] END learning_rate=0.008893562367065913, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.5min\n",
      "[CV] END learning_rate=0.008893562367065913, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.5min\n",
      "[CV] END learning_rate=0.008893562367065913, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.5min\n",
      "[CV] END learning_rate=0.008893562367065913, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.10209356021356719, max_depth=3, n_estimators=370, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.10209356021356719, max_depth=3, n_estimators=370, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.10209356021356719, max_depth=3, n_estimators=370, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.10209356021356719, max_depth=3, n_estimators=370, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.10209356021356719, max_depth=3, n_estimators=370, reg_alpha=0.0001, reg_lambda=20.0; total time=   1.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.061451576356628144, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.1s\n",
      "[CV] END learning_rate=0.061451576356628144, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.4s\n",
      "[CV] END learning_rate=0.061451576356628144, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.2s\n",
      "[CV] END learning_rate=0.061451576356628144, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  45.7s\n",
      "[CV] END learning_rate=0.061451576356628144, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.10954487615166304, max_depth=3, n_estimators=4054, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.8s\n",
      "[CV] END learning_rate=0.10954487615166304, max_depth=3, n_estimators=4054, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.7s\n",
      "[CV] END learning_rate=0.10954487615166304, max_depth=3, n_estimators=4054, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.8s\n",
      "[CV] END learning_rate=0.10954487615166304, max_depth=3, n_estimators=4054, reg_alpha=0.0001, reg_lambda=20.0; total time=  18.9s\n",
      "[CV] END learning_rate=0.10954487615166304, max_depth=3, n_estimators=4054, reg_alpha=0.0001, reg_lambda=20.0; total time=  19.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.056346990256108405, max_depth=3, n_estimators=3819, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.8s\n",
      "[CV] END learning_rate=0.056346990256108405, max_depth=3, n_estimators=3819, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.9s\n",
      "[CV] END learning_rate=0.056346990256108405, max_depth=3, n_estimators=3819, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.6s\n",
      "[CV] END learning_rate=0.056346990256108405, max_depth=3, n_estimators=3819, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.6s\n",
      "[CV] END learning_rate=0.056346990256108405, max_depth=3, n_estimators=3819, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.02305826026714414, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.02305826026714414, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.7s\n",
      "[CV] END learning_rate=0.02305826026714414, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.2s\n",
      "[CV] END learning_rate=0.02305826026714414, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.1s\n",
      "[CV] END learning_rate=0.02305826026714414, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.035864352779377086, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.5s\n",
      "[CV] END learning_rate=0.035864352779377086, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.035864352779377086, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.9s\n",
      "[CV] END learning_rate=0.035864352779377086, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.0min\n",
      "[CV] END learning_rate=0.035864352779377086, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  60.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=1.20833706925557, max_depth=10, n_estimators=70, reg_alpha=20.0, reg_lambda=20.0; total time=   1.2s\n",
      "[CV] END learning_rate=1.20833706925557, max_depth=10, n_estimators=70, reg_alpha=20.0, reg_lambda=20.0; total time=   1.2s\n",
      "[CV] END learning_rate=1.20833706925557, max_depth=10, n_estimators=70, reg_alpha=20.0, reg_lambda=20.0; total time=   1.3s\n",
      "[CV] END learning_rate=1.20833706925557, max_depth=10, n_estimators=70, reg_alpha=20.0, reg_lambda=20.0; total time=   1.1s\n",
      "[CV] END learning_rate=1.20833706925557, max_depth=10, n_estimators=70, reg_alpha=20.0, reg_lambda=20.0; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.12602506893729334, max_depth=3, n_estimators=3648, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.9s\n",
      "[CV] END learning_rate=0.12602506893729334, max_depth=3, n_estimators=3648, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.9s\n",
      "[CV] END learning_rate=0.12602506893729334, max_depth=3, n_estimators=3648, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.6s\n",
      "[CV] END learning_rate=0.12602506893729334, max_depth=3, n_estimators=3648, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.8s\n",
      "[CV] END learning_rate=0.12602506893729334, max_depth=3, n_estimators=3648, reg_alpha=0.0001, reg_lambda=20.0; total time=  16.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.023750051711832268, max_depth=10, n_estimators=2333, reg_alpha=20.0, reg_lambda=20.0; total time=  27.2s\n",
      "[CV] END learning_rate=0.023750051711832268, max_depth=10, n_estimators=2333, reg_alpha=20.0, reg_lambda=20.0; total time=  32.4s\n",
      "[CV] END learning_rate=0.023750051711832268, max_depth=10, n_estimators=2333, reg_alpha=20.0, reg_lambda=20.0; total time=  29.3s\n",
      "[CV] END learning_rate=0.023750051711832268, max_depth=10, n_estimators=2333, reg_alpha=20.0, reg_lambda=20.0; total time=  27.7s\n",
      "[CV] END learning_rate=0.023750051711832268, max_depth=10, n_estimators=2333, reg_alpha=20.0, reg_lambda=20.0; total time=  31.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.016724440835378263, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.3s\n",
      "[CV] END learning_rate=0.016724440835378263, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.0s\n",
      "[CV] END learning_rate=0.016724440835378263, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.8s\n",
      "[CV] END learning_rate=0.016724440835378263, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.0s\n",
      "[CV] END learning_rate=0.016724440835378263, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.49709215461905376, max_depth=6, n_estimators=281, reg_alpha=20.0, reg_lambda=20.0; total time=   1.2s\n",
      "[CV] END learning_rate=0.49709215461905376, max_depth=6, n_estimators=281, reg_alpha=20.0, reg_lambda=20.0; total time=   1.6s\n",
      "[CV] END learning_rate=0.49709215461905376, max_depth=6, n_estimators=281, reg_alpha=20.0, reg_lambda=20.0; total time=   1.5s\n",
      "[CV] END learning_rate=0.49709215461905376, max_depth=6, n_estimators=281, reg_alpha=20.0, reg_lambda=20.0; total time=   1.5s\n",
      "[CV] END learning_rate=0.49709215461905376, max_depth=6, n_estimators=281, reg_alpha=20.0, reg_lambda=20.0; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.6604325115445134, max_depth=10, n_estimators=262, reg_alpha=20.0, reg_lambda=20.0; total time=   1.8s\n",
      "[CV] END learning_rate=0.6604325115445134, max_depth=10, n_estimators=262, reg_alpha=20.0, reg_lambda=20.0; total time=   1.7s\n",
      "[CV] END learning_rate=0.6604325115445134, max_depth=10, n_estimators=262, reg_alpha=20.0, reg_lambda=20.0; total time=   1.9s\n",
      "[CV] END learning_rate=0.6604325115445134, max_depth=10, n_estimators=262, reg_alpha=20.0, reg_lambda=20.0; total time=   1.7s\n",
      "[CV] END learning_rate=0.6604325115445134, max_depth=10, n_estimators=262, reg_alpha=20.0, reg_lambda=20.0; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.42437192462170453, max_depth=5, n_estimators=53, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.42437192462170453, max_depth=5, n_estimators=53, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.42437192462170453, max_depth=5, n_estimators=53, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.42437192462170453, max_depth=5, n_estimators=53, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.42437192462170453, max_depth=5, n_estimators=53, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0960403011043298, max_depth=6, n_estimators=920, reg_alpha=0.0001, reg_lambda=20.0; total time=   8.3s\n",
      "[CV] END learning_rate=0.0960403011043298, max_depth=6, n_estimators=920, reg_alpha=0.0001, reg_lambda=20.0; total time=   8.4s\n",
      "[CV] END learning_rate=0.0960403011043298, max_depth=6, n_estimators=920, reg_alpha=0.0001, reg_lambda=20.0; total time=   8.4s\n",
      "[CV] END learning_rate=0.0960403011043298, max_depth=6, n_estimators=920, reg_alpha=0.0001, reg_lambda=20.0; total time=   8.4s\n",
      "[CV] END learning_rate=0.0960403011043298, max_depth=6, n_estimators=920, reg_alpha=0.0001, reg_lambda=20.0; total time=   8.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.03473614665251809, max_depth=3, n_estimators=6275, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.9s\n",
      "[CV] END learning_rate=0.03473614665251809, max_depth=3, n_estimators=6275, reg_alpha=0.0001, reg_lambda=20.0; total time=  29.1s\n",
      "[CV] END learning_rate=0.03473614665251809, max_depth=3, n_estimators=6275, reg_alpha=0.0001, reg_lambda=20.0; total time=  29.4s\n",
      "[CV] END learning_rate=0.03473614665251809, max_depth=3, n_estimators=6275, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.9s\n",
      "[CV] END learning_rate=0.03473614665251809, max_depth=3, n_estimators=6275, reg_alpha=0.0001, reg_lambda=20.0; total time=  29.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1439759840097225, max_depth=3, n_estimators=3736, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.8s\n",
      "[CV] END learning_rate=0.1439759840097225, max_depth=3, n_estimators=3736, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.5s\n",
      "[CV] END learning_rate=0.1439759840097225, max_depth=3, n_estimators=3736, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.4s\n",
      "[CV] END learning_rate=0.1439759840097225, max_depth=3, n_estimators=3736, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.3s\n",
      "[CV] END learning_rate=0.1439759840097225, max_depth=3, n_estimators=3736, reg_alpha=0.0001, reg_lambda=20.0; total time=  17.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.23649740183108672, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.23649740183108672, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.23649740183108672, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.23649740183108672, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.23649740183108672, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.4174359112131632, max_depth=7, n_estimators=23, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.4174359112131632, max_depth=7, n_estimators=23, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.4174359112131632, max_depth=7, n_estimators=23, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "[CV] END learning_rate=0.4174359112131632, max_depth=7, n_estimators=23, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.4174359112131632, max_depth=7, n_estimators=23, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.3923284264075118, max_depth=4, n_estimators=7, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.3923284264075118, max_depth=4, n_estimators=7, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.3923284264075118, max_depth=4, n_estimators=7, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.3923284264075118, max_depth=4, n_estimators=7, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.1s\n",
      "[CV] END learning_rate=0.3923284264075118, max_depth=4, n_estimators=7, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.014685021460302561, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.7s\n",
      "[CV] END learning_rate=0.014685021460302561, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.6s\n",
      "[CV] END learning_rate=0.014685021460302561, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  60.0s\n",
      "[CV] END learning_rate=0.014685021460302561, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  59.3s\n",
      "[CV] END learning_rate=0.014685021460302561, max_depth=4, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  60.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.05500115063151968, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.05500115063151968, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.05500115063151968, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.05500115063151968, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.05500115063151968, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.003661423420188471, max_depth=8, n_estimators=3291, reg_alpha=0.0001, reg_lambda=0.0005; total time=  43.3s\n",
      "[CV] END learning_rate=0.003661423420188471, max_depth=8, n_estimators=3291, reg_alpha=0.0001, reg_lambda=0.0005; total time=  43.2s\n",
      "[CV] END learning_rate=0.003661423420188471, max_depth=8, n_estimators=3291, reg_alpha=0.0001, reg_lambda=0.0005; total time=  43.4s\n",
      "[CV] END learning_rate=0.003661423420188471, max_depth=8, n_estimators=3291, reg_alpha=0.0001, reg_lambda=0.0005; total time=  43.4s\n",
      "[CV] END learning_rate=0.003661423420188471, max_depth=8, n_estimators=3291, reg_alpha=0.0001, reg_lambda=0.0005; total time=  42.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.003234487579116399, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.003234487579116399, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.003234487579116399, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.003234487579116399, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.003234487579116399, max_depth=7, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.025552033135007802, max_depth=8, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.025552033135007802, max_depth=8, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.025552033135007802, max_depth=8, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.025552033135007802, max_depth=8, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.025552033135007802, max_depth=8, n_estimators=1, reg_alpha=0.0001, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.026440526553723583, max_depth=4, n_estimators=4275, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.7s\n",
      "[CV] END learning_rate=0.026440526553723583, max_depth=4, n_estimators=4275, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.7s\n",
      "[CV] END learning_rate=0.026440526553723583, max_depth=4, n_estimators=4275, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.8s\n",
      "[CV] END learning_rate=0.026440526553723583, max_depth=4, n_estimators=4275, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.026440526553723583, max_depth=4, n_estimators=4275, reg_alpha=0.0001, reg_lambda=20.0; total time=  25.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.01741662583654266, max_depth=9, n_estimators=5977, reg_alpha=20.0, reg_lambda=20.0; total time=  41.3s\n",
      "[CV] END learning_rate=0.01741662583654266, max_depth=9, n_estimators=5977, reg_alpha=20.0, reg_lambda=20.0; total time=  45.7s\n",
      "[CV] END learning_rate=0.01741662583654266, max_depth=9, n_estimators=5977, reg_alpha=20.0, reg_lambda=20.0; total time=  42.0s\n",
      "[CV] END learning_rate=0.01741662583654266, max_depth=9, n_estimators=5977, reg_alpha=20.0, reg_lambda=20.0; total time=  40.7s\n",
      "[CV] END learning_rate=0.01741662583654266, max_depth=9, n_estimators=5977, reg_alpha=20.0, reg_lambda=20.0; total time=  42.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.002724463936529419, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.002724463936529419, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.002724463936529419, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.002724463936529419, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "[CV] END learning_rate=0.002724463936529419, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0059945528511225095, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.3s\n",
      "[CV] END learning_rate=0.0059945528511225095, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.9s\n",
      "[CV] END learning_rate=0.0059945528511225095, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.2s\n",
      "[CV] END learning_rate=0.0059945528511225095, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  47.7s\n",
      "[CV] END learning_rate=0.0059945528511225095, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.6105217515325987, max_depth=5, n_estimators=127, reg_alpha=16.426735530455744, reg_lambda=0.0008187408574226817; total time=   0.8s\n",
      "[CV] END learning_rate=0.6105217515325987, max_depth=5, n_estimators=127, reg_alpha=16.426735530455744, reg_lambda=0.0008187408574226817; total time=   0.8s\n",
      "[CV] END learning_rate=0.6105217515325987, max_depth=5, n_estimators=127, reg_alpha=16.426735530455744, reg_lambda=0.0008187408574226817; total time=   0.8s\n",
      "[CV] END learning_rate=0.6105217515325987, max_depth=5, n_estimators=127, reg_alpha=16.426735530455744, reg_lambda=0.0008187408574226817; total time=   0.8s\n",
      "[CV] END learning_rate=0.6105217515325987, max_depth=5, n_estimators=127, reg_alpha=16.426735530455744, reg_lambda=0.0008187408574226817; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04622025291292083, max_depth=4, n_estimators=4676, reg_alpha=0.0001, reg_lambda=20.0; total time=  27.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.04622025291292083, max_depth=4, n_estimators=4676, reg_alpha=0.0001, reg_lambda=20.0; total time=  27.8s\n",
      "[CV] END learning_rate=0.04622025291292083, max_depth=4, n_estimators=4676, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.1s\n",
      "[CV] END learning_rate=0.04622025291292083, max_depth=4, n_estimators=4676, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.0s\n",
      "[CV] END learning_rate=0.04622025291292083, max_depth=4, n_estimators=4676, reg_alpha=0.0001, reg_lambda=20.0; total time=  28.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04519689167888599, max_depth=3, n_estimators=4777, reg_alpha=0.0001, reg_lambda=20.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.04519689167888599, max_depth=3, n_estimators=4777, reg_alpha=0.0001, reg_lambda=20.0; total time=  22.3s\n",
      "[CV] END learning_rate=0.04519689167888599, max_depth=3, n_estimators=4777, reg_alpha=0.0001, reg_lambda=20.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.04519689167888599, max_depth=3, n_estimators=4777, reg_alpha=0.0001, reg_lambda=20.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.04519689167888599, max_depth=3, n_estimators=4777, reg_alpha=0.0001, reg_lambda=20.0; total time=  22.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.09184570698598905, max_depth=6, n_estimators=26, reg_alpha=0.0002520066379231514, reg_lambda=2.4965616656368694; total time=   0.3s\n",
      "[CV] END learning_rate=0.09184570698598905, max_depth=6, n_estimators=26, reg_alpha=0.0002520066379231514, reg_lambda=2.4965616656368694; total time=   0.3s\n",
      "[CV] END learning_rate=0.09184570698598905, max_depth=6, n_estimators=26, reg_alpha=0.0002520066379231514, reg_lambda=2.4965616656368694; total time=   0.4s\n",
      "[CV] END learning_rate=0.09184570698598905, max_depth=6, n_estimators=26, reg_alpha=0.0002520066379231514, reg_lambda=2.4965616656368694; total time=   0.3s\n",
      "[CV] END learning_rate=0.09184570698598905, max_depth=6, n_estimators=26, reg_alpha=0.0002520066379231514, reg_lambda=2.4965616656368694; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.9min\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 2.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.6155360331969678, max_depth=7, n_estimators=19, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.6155360331969678, max_depth=7, n_estimators=19, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.6155360331969678, max_depth=7, n_estimators=19, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.6155360331969678, max_depth=7, n_estimators=19, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "[CV] END learning_rate=0.6155360331969678, max_depth=7, n_estimators=19, reg_alpha=20.0, reg_lambda=20.0; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0064967343788981426, max_depth=7, n_estimators=4631, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.4s\n",
      "[CV] END learning_rate=0.0064967343788981426, max_depth=7, n_estimators=4631, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.4s\n",
      "[CV] END learning_rate=0.0064967343788981426, max_depth=7, n_estimators=4631, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.7s\n",
      "[CV] END learning_rate=0.0064967343788981426, max_depth=7, n_estimators=4631, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.1s\n",
      "[CV] END learning_rate=0.0064967343788981426, max_depth=7, n_estimators=4631, reg_alpha=0.0001, reg_lambda=20.0; total time=  49.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1, reg_alpha=0.01189719983532607, reg_lambda=0.03760649067886379; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1, reg_alpha=0.01189719983532607, reg_lambda=0.03760649067886379; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1, reg_alpha=0.01189719983532607, reg_lambda=0.03760649067886379; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1, reg_alpha=0.01189719983532607, reg_lambda=0.03760649067886379; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=10, n_estimators=1, reg_alpha=0.01189719983532607, reg_lambda=0.03760649067886379; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.006191593598722178, max_depth=8, n_estimators=8599, reg_alpha=13.271006796081917, reg_lambda=0.0009971914431338505; total time= 1.5min\n",
      "[CV] END learning_rate=0.006191593598722178, max_depth=8, n_estimators=8599, reg_alpha=13.271006796081917, reg_lambda=0.0009971914431338505; total time= 1.6min\n",
      "[CV] END learning_rate=0.006191593598722178, max_depth=8, n_estimators=8599, reg_alpha=13.271006796081917, reg_lambda=0.0009971914431338505; total time= 1.5min\n",
      "[CV] END learning_rate=0.006191593598722178, max_depth=8, n_estimators=8599, reg_alpha=13.271006796081917, reg_lambda=0.0009971914431338505; total time= 1.6min\n",
      "[CV] END learning_rate=0.006191593598722178, max_depth=8, n_estimators=8599, reg_alpha=13.271006796081917, reg_lambda=0.0009971914431338505; total time= 1.6min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.8651450688102253, max_depth=8, n_estimators=183, reg_alpha=9.693138681542024, reg_lambda=0.002751708195207124; total time=   2.5s\n",
      "[CV] END learning_rate=0.8651450688102253, max_depth=8, n_estimators=183, reg_alpha=9.693138681542024, reg_lambda=0.002751708195207124; total time=   2.5s\n",
      "[CV] END learning_rate=0.8651450688102253, max_depth=8, n_estimators=183, reg_alpha=9.693138681542024, reg_lambda=0.002751708195207124; total time=   2.6s\n",
      "[CV] END learning_rate=0.8651450688102253, max_depth=8, n_estimators=183, reg_alpha=9.693138681542024, reg_lambda=0.002751708195207124; total time=   2.4s\n",
      "[CV] END learning_rate=0.8651450688102253, max_depth=8, n_estimators=183, reg_alpha=9.693138681542024, reg_lambda=0.002751708195207124; total time=   2.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.009308275109757307, max_depth=9, n_estimators=3725, reg_alpha=20.0, reg_lambda=20.0; total time=  53.1s\n",
      "[CV] END learning_rate=0.009308275109757307, max_depth=9, n_estimators=3725, reg_alpha=20.0, reg_lambda=20.0; total time=  53.9s\n",
      "[CV] END learning_rate=0.009308275109757307, max_depth=9, n_estimators=3725, reg_alpha=20.0, reg_lambda=20.0; total time=  53.5s\n",
      "[CV] END learning_rate=0.009308275109757307, max_depth=9, n_estimators=3725, reg_alpha=20.0, reg_lambda=20.0; total time=  53.5s\n",
      "[CV] END learning_rate=0.009308275109757307, max_depth=9, n_estimators=3725, reg_alpha=20.0, reg_lambda=20.0; total time=  57.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.028730421143083086, max_depth=7, n_estimators=196, reg_alpha=0.0003254558856672032, reg_lambda=10.537300115156375; total time=   2.4s\n",
      "[CV] END learning_rate=0.028730421143083086, max_depth=7, n_estimators=196, reg_alpha=0.0003254558856672032, reg_lambda=10.537300115156375; total time=   2.4s\n",
      "[CV] END learning_rate=0.028730421143083086, max_depth=7, n_estimators=196, reg_alpha=0.0003254558856672032, reg_lambda=10.537300115156375; total time=   2.3s\n",
      "[CV] END learning_rate=0.028730421143083086, max_depth=7, n_estimators=196, reg_alpha=0.0003254558856672032, reg_lambda=10.537300115156375; total time=   2.4s\n",
      "[CV] END learning_rate=0.028730421143083086, max_depth=7, n_estimators=196, reg_alpha=0.0003254558856672032, reg_lambda=10.537300115156375; total time=   2.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.2503310282076033, max_depth=10, n_estimators=1, reg_alpha=0.006743695627366958, reg_lambda=0.006432396496594842; total time=   0.0s\n",
      "[CV] END learning_rate=0.2503310282076033, max_depth=10, n_estimators=1, reg_alpha=0.006743695627366958, reg_lambda=0.006432396496594842; total time=   0.0s\n",
      "[CV] END learning_rate=0.2503310282076033, max_depth=10, n_estimators=1, reg_alpha=0.006743695627366958, reg_lambda=0.006432396496594842; total time=   0.0s\n",
      "[CV] END learning_rate=0.2503310282076033, max_depth=10, n_estimators=1, reg_alpha=0.006743695627366958, reg_lambda=0.006432396496594842; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.2503310282076033, max_depth=10, n_estimators=1, reg_alpha=0.006743695627366958, reg_lambda=0.006432396496594842; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11803065668300206, max_depth=6, n_estimators=474, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.11803065668300206, max_depth=6, n_estimators=474, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.11803065668300206, max_depth=6, n_estimators=474, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.11803065668300206, max_depth=6, n_estimators=474, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.4s\n",
      "[CV] END learning_rate=0.11803065668300206, max_depth=6, n_estimators=474, reg_alpha=0.0001, reg_lambda=20.0; total time=   4.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.004456747844578129, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.004456747844578129, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.004456747844578129, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.004456747844578129, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.004456747844578129, max_depth=7, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.026265863593612482, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.6s\n",
      "[CV] END learning_rate=0.026265863593612482, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.3s\n",
      "[CV] END learning_rate=0.026265863593612482, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.1s\n",
      "[CV] END learning_rate=0.026265863593612482, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.5s\n",
      "[CV] END learning_rate=0.026265863593612482, max_depth=3, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time=  46.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.011562498568010145, max_depth=4, n_estimators=3262, reg_alpha=0.00013468036479010194, reg_lambda=0.0006134463505339201; total time=  19.9s\n",
      "[CV] END learning_rate=0.011562498568010145, max_depth=4, n_estimators=3262, reg_alpha=0.00013468036479010194, reg_lambda=0.0006134463505339201; total time=  19.8s\n",
      "[CV] END learning_rate=0.011562498568010145, max_depth=4, n_estimators=3262, reg_alpha=0.00013468036479010194, reg_lambda=0.0006134463505339201; total time=  19.7s\n",
      "[CV] END learning_rate=0.011562498568010145, max_depth=4, n_estimators=3262, reg_alpha=0.00013468036479010194, reg_lambda=0.0006134463505339201; total time=  19.8s\n",
      "[CV] END learning_rate=0.011562498568010145, max_depth=4, n_estimators=3262, reg_alpha=0.00013468036479010194, reg_lambda=0.0006134463505339201; total time=  19.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.006848303001878274, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.006848303001878274, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.006848303001878274, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.006848303001878274, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "[CV] END learning_rate=0.006848303001878274, max_depth=6, n_estimators=10000, reg_alpha=0.0001, reg_lambda=0.0005; total time= 1.5min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.13640208452847505, max_depth=3, n_estimators=2721, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.7s\n",
      "[CV] END learning_rate=0.13640208452847505, max_depth=3, n_estimators=2721, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.5s\n",
      "[CV] END learning_rate=0.13640208452847505, max_depth=3, n_estimators=2721, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.7s\n",
      "[CV] END learning_rate=0.13640208452847505, max_depth=3, n_estimators=2721, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.7s\n",
      "[CV] END learning_rate=0.13640208452847505, max_depth=3, n_estimators=2721, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.13340258876069908, max_depth=3, n_estimators=2583, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.13340258876069908, max_depth=3, n_estimators=2583, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.13340258876069908, max_depth=3, n_estimators=2583, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.13340258876069908, max_depth=3, n_estimators=2583, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.13340258876069908, max_depth=3, n_estimators=2583, reg_alpha=0.0001, reg_lambda=20.0; total time=  12.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0015813533952699194, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0015813533952699194, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0015813533952699194, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0015813533952699194, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0015813533952699194, max_depth=8, n_estimators=10000, reg_alpha=0.0001, reg_lambda=20.0; total time= 2.1min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.018512725343652014, max_depth=4, n_estimators=5680, reg_alpha=0.0001, reg_lambda=20.0; total time=  33.9s\n",
      "[CV] END learning_rate=0.018512725343652014, max_depth=4, n_estimators=5680, reg_alpha=0.0001, reg_lambda=20.0; total time=  43.6s\n",
      "[CV] END learning_rate=0.018512725343652014, max_depth=4, n_estimators=5680, reg_alpha=0.0001, reg_lambda=20.0; total time=  33.9s\n",
      "[CV] END learning_rate=0.018512725343652014, max_depth=4, n_estimators=5680, reg_alpha=0.0001, reg_lambda=20.0; total time=  34.4s\n",
      "[CV] END learning_rate=0.018512725343652014, max_depth=4, n_estimators=5680, reg_alpha=0.0001, reg_lambda=20.0; total time=  33.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.08843713089652125, max_depth=7, n_estimators=485, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.08843713089652125, max_depth=7, n_estimators=485, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.08843713089652125, max_depth=7, n_estimators=485, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.08843713089652125, max_depth=7, n_estimators=485, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.2s\n",
      "[CV] END learning_rate=0.08843713089652125, max_depth=7, n_estimators=485, reg_alpha=0.0001, reg_lambda=20.0; total time=   5.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11666497887302257, max_depth=3, n_estimators=1990, reg_alpha=0.11710872590617336, reg_lambda=0.0005; total time=   9.4s\n",
      "[CV] END learning_rate=0.11666497887302257, max_depth=3, n_estimators=1990, reg_alpha=0.11710872590617336, reg_lambda=0.0005; total time=   9.4s\n",
      "[CV] END learning_rate=0.11666497887302257, max_depth=3, n_estimators=1990, reg_alpha=0.11710872590617336, reg_lambda=0.0005; total time=   9.4s\n",
      "[CV] END learning_rate=0.11666497887302257, max_depth=3, n_estimators=1990, reg_alpha=0.11710872590617336, reg_lambda=0.0005; total time=   9.2s\n",
      "[CV] END learning_rate=0.11666497887302257, max_depth=3, n_estimators=1990, reg_alpha=0.11710872590617336, reg_lambda=0.0005; total time=   9.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11305691004110621, max_depth=3, n_estimators=2549, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.8s\n",
      "[CV] END learning_rate=0.11305691004110621, max_depth=3, n_estimators=2549, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.8s\n",
      "[CV] END learning_rate=0.11305691004110621, max_depth=3, n_estimators=2549, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.7s\n",
      "[CV] END learning_rate=0.11305691004110621, max_depth=3, n_estimators=2549, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.8s\n",
      "[CV] END learning_rate=0.11305691004110621, max_depth=3, n_estimators=2549, reg_alpha=0.0001, reg_lambda=20.0; total time=  11.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.003091269607047954, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.003091269607047954, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.003091269607047954, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.003091269607047954, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 2.7min\n",
      "[CV] END learning_rate=0.003091269607047954, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time= 2.7min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.017877497273485143, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  28.8s\n",
      "[CV] END learning_rate=0.017877497273485143, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  30.2s\n",
      "[CV] END learning_rate=0.017877497273485143, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  29.7s\n",
      "[CV] END learning_rate=0.017877497273485143, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  29.4s\n",
      "[CV] END learning_rate=0.017877497273485143, max_depth=3, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  28.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.002979420969843482, max_depth=4, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.0min\n",
      "[CV] END learning_rate=0.002979420969843482, max_depth=4, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.0min\n",
      "[CV] END learning_rate=0.002979420969843482, max_depth=4, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.0min\n",
      "[CV] END learning_rate=0.002979420969843482, max_depth=4, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.0min\n",
      "[CV] END learning_rate=0.002979420969843482, max_depth=4, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 1.0min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.001, max_depth=8, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=8, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=8, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=8, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, max_depth=8, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.052681601240292995, max_depth=4, n_estimators=6082, reg_alpha=0.0001, reg_lambda=20.0; total time=  36.4s\n",
      "[CV] END learning_rate=0.052681601240292995, max_depth=4, n_estimators=6082, reg_alpha=0.0001, reg_lambda=20.0; total time=  36.5s\n",
      "[CV] END learning_rate=0.052681601240292995, max_depth=4, n_estimators=6082, reg_alpha=0.0001, reg_lambda=20.0; total time=  36.3s\n",
      "[CV] END learning_rate=0.052681601240292995, max_depth=4, n_estimators=6082, reg_alpha=0.0001, reg_lambda=20.0; total time=  36.1s\n",
      "[CV] END learning_rate=0.052681601240292995, max_depth=4, n_estimators=6082, reg_alpha=0.0001, reg_lambda=20.0; total time=  36.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.11770164275067549, max_depth=2, n_estimators=2528, reg_alpha=20.0, reg_lambda=0.0005; total time=   6.5s\n",
      "[CV] END learning_rate=0.11770164275067549, max_depth=2, n_estimators=2528, reg_alpha=20.0, reg_lambda=0.0005; total time=   6.3s\n",
      "[CV] END learning_rate=0.11770164275067549, max_depth=2, n_estimators=2528, reg_alpha=20.0, reg_lambda=0.0005; total time=   6.3s\n",
      "[CV] END learning_rate=0.11770164275067549, max_depth=2, n_estimators=2528, reg_alpha=20.0, reg_lambda=0.0005; total time=   6.4s\n",
      "[CV] END learning_rate=0.11770164275067549, max_depth=2, n_estimators=2528, reg_alpha=20.0, reg_lambda=0.0005; total time=   6.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0029340206671827984, max_depth=10, n_estimators=691, reg_alpha=0.0007892695247128279, reg_lambda=0.44196222107237326; total time=  13.7s\n",
      "[CV] END learning_rate=0.0029340206671827984, max_depth=10, n_estimators=691, reg_alpha=0.0007892695247128279, reg_lambda=0.44196222107237326; total time=  13.7s\n",
      "[CV] END learning_rate=0.0029340206671827984, max_depth=10, n_estimators=691, reg_alpha=0.0007892695247128279, reg_lambda=0.44196222107237326; total time=  13.5s\n",
      "[CV] END learning_rate=0.0029340206671827984, max_depth=10, n_estimators=691, reg_alpha=0.0007892695247128279, reg_lambda=0.44196222107237326; total time=  13.5s\n",
      "[CV] END learning_rate=0.0029340206671827984, max_depth=10, n_estimators=691, reg_alpha=0.0007892695247128279, reg_lambda=0.44196222107237326; total time=  13.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1307172905017973, max_depth=3, n_estimators=2276, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.1307172905017973, max_depth=3, n_estimators=2276, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.8s\n",
      "[CV] END learning_rate=0.1307172905017973, max_depth=3, n_estimators=2276, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.1307172905017973, max_depth=3, n_estimators=2276, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.1307172905017973, max_depth=3, n_estimators=2276, reg_alpha=0.0001, reg_lambda=20.0; total time=  10.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1302394649343181, max_depth=4, n_estimators=2392, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.5s\n",
      "[CV] END learning_rate=0.1302394649343181, max_depth=4, n_estimators=2392, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.6s\n",
      "[CV] END learning_rate=0.1302394649343181, max_depth=4, n_estimators=2392, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.6s\n",
      "[CV] END learning_rate=0.1302394649343181, max_depth=4, n_estimators=2392, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.6s\n",
      "[CV] END learning_rate=0.1302394649343181, max_depth=4, n_estimators=2392, reg_alpha=0.0001, reg_lambda=20.0; total time=  14.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=1.071410493602398, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.5s\n",
      "[CV] END learning_rate=1.071410493602398, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.0s\n",
      "[CV] END learning_rate=1.071410493602398, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.1s\n",
      "[CV] END learning_rate=1.071410493602398, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.0s\n",
      "[CV] END learning_rate=1.071410493602398, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.38430089259120576, max_depth=6, n_estimators=46, reg_alpha=0.07064844669088606, reg_lambda=0.0005; total time=   0.5s\n",
      "[CV] END learning_rate=0.38430089259120576, max_depth=6, n_estimators=46, reg_alpha=0.07064844669088606, reg_lambda=0.0005; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.38430089259120576, max_depth=6, n_estimators=46, reg_alpha=0.07064844669088606, reg_lambda=0.0005; total time=   0.5s\n",
      "[CV] END learning_rate=0.38430089259120576, max_depth=6, n_estimators=46, reg_alpha=0.07064844669088606, reg_lambda=0.0005; total time=   0.5s\n",
      "[CV] END learning_rate=0.38430089259120576, max_depth=6, n_estimators=46, reg_alpha=0.07064844669088606, reg_lambda=0.0005; total time=   0.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0039024967956519255, max_depth=8, n_estimators=10000, reg_alpha=0.047501678521344154, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0039024967956519255, max_depth=8, n_estimators=10000, reg_alpha=0.047501678521344154, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0039024967956519255, max_depth=8, n_estimators=10000, reg_alpha=0.047501678521344154, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0039024967956519255, max_depth=8, n_estimators=10000, reg_alpha=0.047501678521344154, reg_lambda=20.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.0039024967956519255, max_depth=8, n_estimators=10000, reg_alpha=0.047501678521344154, reg_lambda=20.0; total time= 2.1min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.028102567938316732, max_depth=4, n_estimators=10000, reg_alpha=0.04685604958306441, reg_lambda=20.0; total time=  59.3s\n",
      "[CV] END learning_rate=0.028102567938316732, max_depth=4, n_estimators=10000, reg_alpha=0.04685604958306441, reg_lambda=20.0; total time=  59.7s\n",
      "[CV] END learning_rate=0.028102567938316732, max_depth=4, n_estimators=10000, reg_alpha=0.04685604958306441, reg_lambda=20.0; total time=  59.3s\n",
      "[CV] END learning_rate=0.028102567938316732, max_depth=4, n_estimators=10000, reg_alpha=0.04685604958306441, reg_lambda=20.0; total time=  59.0s\n",
      "[CV] END learning_rate=0.028102567938316732, max_depth=4, n_estimators=10000, reg_alpha=0.04685604958306441, reg_lambda=20.0; total time=  59.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.13756087300203787, max_depth=3, n_estimators=1244, reg_alpha=0.0001, reg_lambda=0.08830330161512794; total time=   5.9s\n",
      "[CV] END learning_rate=0.13756087300203787, max_depth=3, n_estimators=1244, reg_alpha=0.0001, reg_lambda=0.08830330161512794; total time=   6.0s\n",
      "[CV] END learning_rate=0.13756087300203787, max_depth=3, n_estimators=1244, reg_alpha=0.0001, reg_lambda=0.08830330161512794; total time=   5.9s\n",
      "[CV] END learning_rate=0.13756087300203787, max_depth=3, n_estimators=1244, reg_alpha=0.0001, reg_lambda=0.08830330161512794; total time=   5.9s\n",
      "[CV] END learning_rate=0.13756087300203787, max_depth=3, n_estimators=1244, reg_alpha=0.0001, reg_lambda=0.08830330161512794; total time=   5.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.20609122980687494, max_depth=2, n_estimators=3866, reg_alpha=0.03782789985547297, reg_lambda=20.0; total time=  13.5s\n",
      "[CV] END learning_rate=0.20609122980687494, max_depth=2, n_estimators=3866, reg_alpha=0.03782789985547297, reg_lambda=20.0; total time=  13.1s\n",
      "[CV] END learning_rate=0.20609122980687494, max_depth=2, n_estimators=3866, reg_alpha=0.03782789985547297, reg_lambda=20.0; total time=  13.6s\n",
      "[CV] END learning_rate=0.20609122980687494, max_depth=2, n_estimators=3866, reg_alpha=0.03782789985547297, reg_lambda=20.0; total time=  13.7s\n",
      "[CV] END learning_rate=0.20609122980687494, max_depth=2, n_estimators=3866, reg_alpha=0.03782789985547297, reg_lambda=20.0; total time=  13.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.10196661464601253, max_depth=7, n_estimators=986, reg_alpha=0.07423226221077668, reg_lambda=20.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.10196661464601253, max_depth=7, n_estimators=986, reg_alpha=0.07423226221077668, reg_lambda=20.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.10196661464601253, max_depth=7, n_estimators=986, reg_alpha=0.07423226221077668, reg_lambda=20.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.10196661464601253, max_depth=7, n_estimators=986, reg_alpha=0.07423226221077668, reg_lambda=20.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.10196661464601253, max_depth=7, n_estimators=986, reg_alpha=0.07423226221077668, reg_lambda=20.0; total time=  10.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.14223880232154404, max_depth=3, n_estimators=5161, reg_alpha=0.05385354883346568, reg_lambda=20.0; total time=  23.9s\n",
      "[CV] END learning_rate=0.14223880232154404, max_depth=3, n_estimators=5161, reg_alpha=0.05385354883346568, reg_lambda=20.0; total time=  23.9s\n",
      "[CV] END learning_rate=0.14223880232154404, max_depth=3, n_estimators=5161, reg_alpha=0.05385354883346568, reg_lambda=20.0; total time=  23.6s\n",
      "[CV] END learning_rate=0.14223880232154404, max_depth=3, n_estimators=5161, reg_alpha=0.05385354883346568, reg_lambda=20.0; total time=  23.5s\n",
      "[CV] END learning_rate=0.14223880232154404, max_depth=3, n_estimators=5161, reg_alpha=0.05385354883346568, reg_lambda=20.0; total time=  23.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.16651455980337884, max_depth=3, n_estimators=2207, reg_alpha=0.005292799328304982, reg_lambda=20.0; total time=  10.2s\n",
      "[CV] END learning_rate=0.16651455980337884, max_depth=3, n_estimators=2207, reg_alpha=0.005292799328304982, reg_lambda=20.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.16651455980337884, max_depth=3, n_estimators=2207, reg_alpha=0.005292799328304982, reg_lambda=20.0; total time=  10.2s\n",
      "[CV] END learning_rate=0.16651455980337884, max_depth=3, n_estimators=2207, reg_alpha=0.005292799328304982, reg_lambda=20.0; total time=  10.1s\n",
      "[CV] END learning_rate=0.16651455980337884, max_depth=3, n_estimators=2207, reg_alpha=0.005292799328304982, reg_lambda=20.0; total time=  10.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04716662552854071, max_depth=10, n_estimators=1218, reg_alpha=20.0, reg_lambda=0.0005; total time=  12.9s\n",
      "[CV] END learning_rate=0.04716662552854071, max_depth=10, n_estimators=1218, reg_alpha=20.0, reg_lambda=0.0005; total time=  13.9s\n",
      "[CV] END learning_rate=0.04716662552854071, max_depth=10, n_estimators=1218, reg_alpha=20.0, reg_lambda=0.0005; total time=  12.6s\n",
      "[CV] END learning_rate=0.04716662552854071, max_depth=10, n_estimators=1218, reg_alpha=20.0, reg_lambda=0.0005; total time=  13.9s\n",
      "[CV] END learning_rate=0.04716662552854071, max_depth=10, n_estimators=1218, reg_alpha=20.0, reg_lambda=0.0005; total time=  12.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=1.3470948867349555, max_depth=10, n_estimators=873, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.1s\n",
      "[CV] END learning_rate=1.3470948867349555, max_depth=10, n_estimators=873, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.3s\n",
      "[CV] END learning_rate=1.3470948867349555, max_depth=10, n_estimators=873, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.6s\n",
      "[CV] END learning_rate=1.3470948867349555, max_depth=10, n_estimators=873, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.0s\n",
      "[CV] END learning_rate=1.3470948867349555, max_depth=10, n_estimators=873, reg_alpha=20.0, reg_lambda=0.0005; total time=   3.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.009034524563039895, max_depth=7, n_estimators=10000, reg_alpha=0.1895903139899111, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.009034524563039895, max_depth=7, n_estimators=10000, reg_alpha=0.1895903139899111, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.009034524563039895, max_depth=7, n_estimators=10000, reg_alpha=0.1895903139899111, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.009034524563039895, max_depth=7, n_estimators=10000, reg_alpha=0.1895903139899111, reg_lambda=20.0; total time= 1.8min\n",
      "[CV] END learning_rate=0.009034524563039895, max_depth=7, n_estimators=10000, reg_alpha=0.1895903139899111, reg_lambda=20.0; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.012029402041042905, max_depth=5, n_estimators=10000, reg_alpha=0.02335261407871724, reg_lambda=20.0; total time= 1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.012029402041042905, max_depth=5, n_estimators=10000, reg_alpha=0.02335261407871724, reg_lambda=20.0; total time= 1.2min\n",
      "[CV] END learning_rate=0.012029402041042905, max_depth=5, n_estimators=10000, reg_alpha=0.02335261407871724, reg_lambda=20.0; total time= 1.2min\n",
      "[CV] END learning_rate=0.012029402041042905, max_depth=5, n_estimators=10000, reg_alpha=0.02335261407871724, reg_lambda=20.0; total time= 1.2min\n",
      "[CV] END learning_rate=0.012029402041042905, max_depth=5, n_estimators=10000, reg_alpha=0.02335261407871724, reg_lambda=20.0; total time= 1.2min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=10.0, max_depth=10, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.032781004674055175, max_depth=8, n_estimators=1628, reg_alpha=0.030734819099557054, reg_lambda=20.0; total time=  21.6s\n",
      "[CV] END learning_rate=0.032781004674055175, max_depth=8, n_estimators=1628, reg_alpha=0.030734819099557054, reg_lambda=20.0; total time=  20.1s\n",
      "[CV] END learning_rate=0.032781004674055175, max_depth=8, n_estimators=1628, reg_alpha=0.030734819099557054, reg_lambda=20.0; total time=  20.1s\n",
      "[CV] END learning_rate=0.032781004674055175, max_depth=8, n_estimators=1628, reg_alpha=0.030734819099557054, reg_lambda=20.0; total time=  20.1s\n",
      "[CV] END learning_rate=0.032781004674055175, max_depth=8, n_estimators=1628, reg_alpha=0.030734819099557054, reg_lambda=20.0; total time=  20.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.16308955193857824, max_depth=3, n_estimators=2711, reg_alpha=0.0039641164730466905, reg_lambda=20.0; total time=  13.0s\n",
      "[CV] END learning_rate=0.16308955193857824, max_depth=3, n_estimators=2711, reg_alpha=0.0039641164730466905, reg_lambda=20.0; total time=  13.0s\n",
      "[CV] END learning_rate=0.16308955193857824, max_depth=3, n_estimators=2711, reg_alpha=0.0039641164730466905, reg_lambda=20.0; total time=  12.7s\n",
      "[CV] END learning_rate=0.16308955193857824, max_depth=3, n_estimators=2711, reg_alpha=0.0039641164730466905, reg_lambda=20.0; total time=  12.7s\n",
      "[CV] END learning_rate=0.16308955193857824, max_depth=3, n_estimators=2711, reg_alpha=0.0039641164730466905, reg_lambda=20.0; total time=  12.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.002343465966312287, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.002343465966312287, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.002343465966312287, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.5min\n",
      "[CV] END learning_rate=0.002343465966312287, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.4min\n",
      "[CV] END learning_rate=0.002343465966312287, max_depth=9, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time= 2.4min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.07084637218464346, max_depth=4, n_estimators=5276, reg_alpha=0.0010448589400416555, reg_lambda=20.0; total time=  32.4s\n",
      "[CV] END learning_rate=0.07084637218464346, max_depth=4, n_estimators=5276, reg_alpha=0.0010448589400416555, reg_lambda=20.0; total time=  32.3s\n",
      "[CV] END learning_rate=0.07084637218464346, max_depth=4, n_estimators=5276, reg_alpha=0.0010448589400416555, reg_lambda=20.0; total time=  31.5s\n",
      "[CV] END learning_rate=0.07084637218464346, max_depth=4, n_estimators=5276, reg_alpha=0.0010448589400416555, reg_lambda=20.0; total time=  31.9s\n",
      "[CV] END learning_rate=0.07084637218464346, max_depth=4, n_estimators=5276, reg_alpha=0.0010448589400416555, reg_lambda=20.0; total time=  32.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.4912323739857657, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.3s\n",
      "[CV] END learning_rate=0.4912323739857657, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.1s\n",
      "[CV] END learning_rate=0.4912323739857657, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.3s\n",
      "[CV] END learning_rate=0.4912323739857657, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.2s\n",
      "[CV] END learning_rate=0.4912323739857657, max_depth=1, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.5832557145463401, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.5s\n",
      "[CV] END learning_rate=0.5832557145463401, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.7s\n",
      "[CV] END learning_rate=0.5832557145463401, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.7s\n",
      "[CV] END learning_rate=0.5832557145463401, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  20.5s\n",
      "[CV] END learning_rate=0.5832557145463401, max_depth=5, n_estimators=10000, reg_alpha=20.0, reg_lambda=0.0005; total time=  21.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.5223160361357437, max_depth=2, n_estimators=4625, reg_alpha=0.08076375874975976, reg_lambda=0.0005; total time=  15.9s\n",
      "[CV] END learning_rate=0.5223160361357437, max_depth=2, n_estimators=4625, reg_alpha=0.08076375874975976, reg_lambda=0.0005; total time=  15.8s\n",
      "[CV] END learning_rate=0.5223160361357437, max_depth=2, n_estimators=4625, reg_alpha=0.08076375874975976, reg_lambda=0.0005; total time=  15.7s\n",
      "[CV] END learning_rate=0.5223160361357437, max_depth=2, n_estimators=4625, reg_alpha=0.08076375874975976, reg_lambda=0.0005; total time=  15.5s\n",
      "[CV] END learning_rate=0.5223160361357437, max_depth=2, n_estimators=4625, reg_alpha=0.08076375874975976, reg_lambda=0.0005; total time=  15.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=1.3943964029294387, max_depth=10, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=1.3943964029294387, max_depth=10, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=1.3943964029294387, max_depth=10, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=1.3943964029294387, max_depth=10, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "[CV] END learning_rate=1.3943964029294387, max_depth=10, n_estimators=1, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.04158328586073251, max_depth=3, n_estimators=7176, reg_alpha=0.0001, reg_lambda=0.0005; total time=  33.7s\n",
      "[CV] END learning_rate=0.04158328586073251, max_depth=3, n_estimators=7176, reg_alpha=0.0001, reg_lambda=0.0005; total time=  33.7s\n",
      "[CV] END learning_rate=0.04158328586073251, max_depth=3, n_estimators=7176, reg_alpha=0.0001, reg_lambda=0.0005; total time=  33.5s\n",
      "[CV] END learning_rate=0.04158328586073251, max_depth=3, n_estimators=7176, reg_alpha=0.0001, reg_lambda=0.0005; total time=  34.1s\n",
      "[CV] END learning_rate=0.04158328586073251, max_depth=3, n_estimators=7176, reg_alpha=0.0001, reg_lambda=0.0005; total time=  33.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.41407680255355167, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.3s\n",
      "[CV] END learning_rate=0.41407680255355167, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.41407680255355167, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  22.5s\n",
      "[CV] END learning_rate=0.41407680255355167, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.8s\n",
      "[CV] END learning_rate=0.41407680255355167, max_depth=10, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  21.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.0013060002662700417, max_depth=7, n_estimators=10000, reg_alpha=0.0518096327279438, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.0013060002662700417, max_depth=7, n_estimators=10000, reg_alpha=0.0518096327279438, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.0013060002662700417, max_depth=7, n_estimators=10000, reg_alpha=0.0518096327279438, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.0013060002662700417, max_depth=7, n_estimators=10000, reg_alpha=0.0518096327279438, reg_lambda=0.0005; total time= 1.9min\n",
      "[CV] END learning_rate=0.0013060002662700417, max_depth=7, n_estimators=10000, reg_alpha=0.0518096327279438, reg_lambda=0.0005; total time= 1.8min\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.023741325597139668, max_depth=4, n_estimators=1779, reg_alpha=0.18860322082441477, reg_lambda=0.0005; total time=  11.0s\n",
      "[CV] END learning_rate=0.023741325597139668, max_depth=4, n_estimators=1779, reg_alpha=0.18860322082441477, reg_lambda=0.0005; total time=  10.8s\n",
      "[CV] END learning_rate=0.023741325597139668, max_depth=4, n_estimators=1779, reg_alpha=0.18860322082441477, reg_lambda=0.0005; total time=  10.9s\n",
      "[CV] END learning_rate=0.023741325597139668, max_depth=4, n_estimators=1779, reg_alpha=0.18860322082441477, reg_lambda=0.0005; total time=  10.8s\n",
      "[CV] END learning_rate=0.023741325597139668, max_depth=4, n_estimators=1779, reg_alpha=0.18860322082441477, reg_lambda=0.0005; total time=  10.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.2616645414774299, max_depth=6, n_estimators=42, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.2616645414774299, max_depth=6, n_estimators=42, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.2616645414774299, max_depth=6, n_estimators=42, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.2616645414774299, max_depth=6, n_estimators=42, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "[CV] END learning_rate=0.2616645414774299, max_depth=6, n_estimators=42, reg_alpha=0.0001, reg_lambda=20.0; total time=   0.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.15360562044525164, max_depth=2, n_estimators=2272, reg_alpha=0.005198466305204398, reg_lambda=20.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.15360562044525164, max_depth=2, n_estimators=2272, reg_alpha=0.005198466305204398, reg_lambda=20.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.15360562044525164, max_depth=2, n_estimators=2272, reg_alpha=0.005198466305204398, reg_lambda=20.0; total time=   7.7s\n",
      "[CV] END learning_rate=0.15360562044525164, max_depth=2, n_estimators=2272, reg_alpha=0.005198466305204398, reg_lambda=20.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.15360562044525164, max_depth=2, n_estimators=2272, reg_alpha=0.005198466305204398, reg_lambda=20.0; total time=   7.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.013792480234303127, max_depth=7, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.013792480234303127, max_depth=7, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.013792480234303127, max_depth=7, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.013792480234303127, max_depth=7, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "[CV] END learning_rate=0.013792480234303127, max_depth=7, n_estimators=1, reg_alpha=20.0, reg_lambda=0.0005; total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.02164991303063641, max_depth=6, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  34.5s\n",
      "[CV] END learning_rate=0.02164991303063641, max_depth=6, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  33.8s\n",
      "[CV] END learning_rate=0.02164991303063641, max_depth=6, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  32.4s\n",
      "[CV] END learning_rate=0.02164991303063641, max_depth=6, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  33.9s\n",
      "[CV] END learning_rate=0.02164991303063641, max_depth=6, n_estimators=10000, reg_alpha=20.0, reg_lambda=20.0; total time=  33.6s\n",
      "CPU times: user 1d 10h 16min 9s, sys: 17min 44s, total: 1d 10h 33min 53s\n",
      "Wall time: 8h 45min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe5b6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.13640208452847505),\n",
       "             ('max_depth', 3),\n",
       "             ('n_estimators', 2721),\n",
       "             ('reg_alpha', 0.0001),\n",
       "             ('reg_lambda', 20.0)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b960fa3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992162077303021"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caa340b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df0510b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot.line(y='mean_test_score', yerr='std_test_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1403d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_index_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4ebeb",
   "metadata": {},
   "source": [
    "N estimators and lambda are larger than I expected, though it could be over fitting.\n",
    "Another round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94f84096",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_2 = {\n",
    "    'n_estimators': Integer(2000, 4000, prior='log-uniform', base=10),\n",
    "    'max_depth': Integer(2, 4, prior='uniform'),\n",
    "    'learning_rate': Real(0.05, 0.2, prior='log-uniform', base=10),\n",
    "    'reg_lambda': Real(5, 100, prior='log-uniform', base=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faea9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_clf_2 = XGBClassifier(random_state=8,\n",
    "                         max_leaves=0,\n",
    "                         n_jobs=-1,\n",
    "                           reg_alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d029ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_2 = BayesSearchCV(estimator=xgboost_clf_2,\n",
    "                       search_spaces=space_2,\n",
    "                       n_iter=50, \n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=1,\n",
    "                       n_points=1, \n",
    "                       refit=True,\n",
    "                       cv=5,\n",
    "                       verbose=1,\n",
    "                       random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efae248c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "CPU times: user 4h 1min 42s, sys: 2min 3s, total: 4h 3min 46s\n",
      "Wall time: 1h 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "search_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2392f2e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.19115369742768948),\n",
       "             ('max_depth', 3),\n",
       "             ('n_estimators', 3950),\n",
       "             ('reg_lambda', 96.48423464920053)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01e2864d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993944218192285"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15c8ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2 = pd.DataFrame(search_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4920b466",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABh30lEQVR4nO3deXxTddY/8E+SNmmbrrSlC5S27DtqWQuICwMi4jI6g+iDiqLiAjI4+oigMo4j6jMyuAyMy7jgOAM/BXRGUWBEEES2AoIUsdCWli6UFrrvyf39kd6bpE3T3Oy9+bxfr760SZrcXtLk5HzPOV+VIAgCiIiIiLo5ta8PgIiIiMgdGNQQERGRIjCoISIiIkVgUENERESKwKCGiIiIFIFBDRERESkCgxoiIiJSBAY1REREpAhBvj4AbzIajSguLkZERARUKpWvD4eIiIgcIAgCampqkJycDLW683xMQAU1xcXFSElJ8fVhEBERkRMKCwvRu3fvTq8PqKAmIiICgOmkREZG+vhoiIiIyBHV1dVISUmR3sc7E1BBjbjkFBkZyaCGiIiom+mqdISFwkRERKQIDGqIiIhIERjUEBERkSIEVE0NERGZ2mNbW1thMBh8fShEAACNRoOgoCCXx60wqCEiCiDNzc0oKSlBfX29rw+FyEpYWBiSkpKg1Wqdvg8GNUREAcJoNCIvLw8ajQbJycnQarUcREo+JwgCmpubceHCBeTl5WHAgAF2B+zZw6CGiChANDc3w2g0IiUlBWFhYb4+HCJJaGgogoODcfbsWTQ3NyMkJMSp+2GhMBFRgHH2UzCRJ7njeclnNhERESkCgxoiIiJSBAY1REREpAgMaoiIiDzggw8+QHR0tFvvc+fOnVCpVKisrHTr/SoFgxoiIiJyi5aWFp8+PoMaIjvqm1uR9tSXSHvqS9Q3t/r6cIjcThAE1De3+uRLEASHj/Oqq67CwoULsXjxYsTExCAhIQFvv/026urqMG/ePERERKBfv3746quvpJ/Jzs7G9ddfj/DwcCQkJGDu3LkoLy+Xrv/6668xadIkREdHIzY2FjfccAPOnDkjXZ+fnw+VSoVNmzbh6quvRlhYGEaNGoUffvihy+PduXMn5s2bh6qqKqhUKqhUKqxYsQKAqbX+ySefRK9evaDX6zFu3Djs3LlT+tmzZ89i1qxZiImJgV6vx7Bhw7Blyxbk5+fj6quvBgDExMRApVLhnnvu6fJYPv30U4wYMQKhoaGIjY3F1KlTUVdXJ13/3nvvYdiwYdDpdEhKSsKjjz4qXVdQUICbbroJ4eHhiIyMxG9/+1ucP39eun7FihW47LLL8N5776Fv377Q6XQQBAFVVVV44IEH0LNnT0RGRuKaa67Bjz/+2OWxuopzaoiIAlhDiwFDn93qk8fOfn46wrSOvw19+OGHePLJJ3HgwAFs2LABDz30ED777DPccsstePrpp/GXv/wFc+fORUFBAaqqqjBlyhTcf//9WLVqFRoaGvC///u/+O1vf4sdO3YAAOrq6rBkyRKMGDECdXV1ePbZZ3HLLbfg6NGjVu3Fy5Ytw5///GcMGDAAy5Ytw5w5c3D69GkEBXV+7JmZmVi9ejWeffZZnDp1CgAQHh4OAJg3bx7y8/Oxfv16JCcnY/Pmzbjuuutw/PhxDBgwAI888giam5vx3XffQa/XIzs7G+Hh4UhJScHGjRtx66234tSpU4iMjERoaKjdc1ZSUoI5c+bglVdewS233IKamhrs3r1bCijXrl2LJUuW4KWXXsKMGTNQVVWF77//HoAp4L355puh1+uxa9cutLa24uGHH8bs2bOtgrDTp0/j//2//4eNGzdCo9EAAGbOnIkePXpgy5YtiIqKwltvvYVrr70Wv/zyC3r06OHwv7lcKkFOqNzNVVdXIyoqClVVVYiMjPT14VA3UN/cKr3gy30BJvI3jY2NyMvLQ3p6ujTczPI57m1y/qauuuoqGAwG7N69GwBgMBgQFRWFX//611i3bh0AoLS0FElJSfjhhx+wZcsW7N+/H1u3mn+3c+fOISUlBadOncLAgQM7PMaFCxfQs2dPHD9+HMOHD0d+fj7S09Px7rvv4r777jMdc3Y2hg0bhpMnT2Lw4MF2j/mDDz7A4sWLrepfzpw5gwEDBuDcuXNITk6WLp86dSrGjh2LF198ESNHjsStt96K5557rsN97ty5E1dffTUuXbrkUL3O4cOHkZGRgfz8fKSmpna4vlevXpg3bx5eeOGFDtdt374dM2bMQF5eHlJSUqx+/wMHDmDMmDFYsWIFXnzxRRQVFSE+Ph4AsGPHDtxyyy0oKyuDTqeT7q9///548skn8cADD9g8VlvPT5Gj7998hSYiskPpgW1osAbZz0/32WPLMXLkSOn/NRoNYmNjMWLECOmyhIQEAEBZWRmysrLw7bffStkRS2fOnMHAgQNx5swZPPPMM9i3bx/Ky8thNBoBmJZchg8fbvNxk5KSpMfoKqix5fDhwxAEoUNQ1dTUhNjYWADAokWL8NBDD2Hbtm2YOnUqbr31VqtjkGPUqFG49tprMWLECEyfPh3Tpk3DbbfdhpiYGJSVlaG4uBjXXnutzZ89efIkUlJSpIAGAIYOHYro6GicPHkSY8aMAQCkpqZKAQ0AZGVloba2Vvp9RA0NDVbLe56grL9OIiKSRaVSdZtALTg42Op7lUpldZm4j5XRaITRaMSsWbPw8ssvd7gfMTCZNWsWUlJS8M477yA5ORlGoxHDhw9Hc3Nzp49r+RjOMBqN0Gg0yMrKkpZqRGIANn/+fEyfPh1ffvkltm3bhpUrV+LVV1/FwoULZT+eRqPB9u3bsXfvXmzbtg1vvPEGli1bhv379yMuLs7uzwqCYHNvsPaX6/X6Dr9jUlKS1RKVyN3dYO11j2cyERGRDFdccQU2btyItLQ0m7UvFRUVOHnyJN566y1MnjwZALBnzx63HoNWq4XBYLC67PLLL4fBYEBZWZn0uLakpKRgwYIFWLBgAZYuXYp33nkHCxculHawbn+/9qhUKkycOBETJ07Es88+i9TUVGzevBlLlixBWloavvnmG6kA2dLQoUNRUFCAwsJCq+WnqqoqDBkypNPHu+KKK1BaWoqgoCCkpaU5fJzuwO4nUhx2LBHRI488gosXL2LOnDk4cOAAcnNzsW3bNtx7770wGAyIiYlBbGws3n77bZw+fRo7duzAkiVL3HoMaWlpqK2txTfffIPy8nLU19dj4MCBuPPOO3HXXXdh06ZNyMvLw8GDB/Hyyy9jy5YtAIDFixdj69atyMvLw+HDh7Fjxw4piEhNTYVKpcIXX3yBCxcuoLa21u4x7N+/Hy+++CIOHTqEgoICbNq0CRcuXJDub8WKFXj11Vfx+uuvIycnB4cPH8Ybb7wBwFTnM3LkSNx55504fPgwDhw4gLvuugtTpkzB6NGjO33MqVOnYsKECbj55puxdetW5OfnY+/evVi+fDkOHTrkjlPbKQY1RERewGDbu5KTk/H999/DYDBg+vTpGD58OB577DFERUVBrVZDrVZj/fr1yMrKwvDhw/G73/0O//d//+fWY8jMzMSCBQswe/ZsxMfH45VXXgEAvP/++7jrrrvw+OOPY9CgQbjxxhuxf/9+KRtiMBjwyCOPYMiQIbjuuuswaNAgrFmzBoCpsPcPf/gDnnrqKSQkJFi1X9sSGRmJ7777Dtdffz0GDhyI5cuX49VXX8WMGTMAAHfffTdWr16NNWvWYNiwYbjhhhuQk5MDwJTh+eyzzxATE4Mrr7wSU6dORd++fbFhwwa7j6lSqbBlyxZceeWVuPfeezFw4EDcfvvtyM/Pl+qePIXdT6Q47izsVHqRaHfkrn8TR+/H24/nSfa6S4h8zR3dT8zUELlIyZ/Alfy7EZHyMKghIlIgBqSeN2PGDISHh9v8evHFF71yDAUFBZ0eQ5g+HFv3H4fBGDALMux+ou7FH1L4REQA8O6776KhocHmdZ6cmmspOTkZR48e7XC5wSgg53wN4hOSvHIc/oLvCERewGCM/JHBKOBEcRUAYFhyFDTqjjNJqHO9evXy9SEgKCgI/fv373C5wSigKazKB0fkW3xlJSIKMAHUH6JISg1G3fG8ZE0NEVGAECfj1tfXe/2xDUYBx85V4ti5yoCq8SDHic/L9pOj5WCmhshPcImKPE2j0SA6OhplZWUAAF1IKIRW05YAjY2NHv3EbzAKXnsspXPkXDp6vg1GAafLagAA/XtG+OTfRRAE1NfXo6ysDNHR0R22j5CDr5pERC7qTgFpYmIiANOGjEZBQFllIwAgqD4Eahv7/LiLNx9L6Rw5l46eb3/6d4mOjpaen87y37886ja60wu6pe563ESuUKlUSEpKQs+ePVFd34gHNu8GAHyxcBJCPfg30NDcigc27/HKY/lCQ3MrbnjDO7+fI+fS0fPtrn8XV3//4OBglzI0ImU9q4iIyCEajQY6nQ5FNaaNEXUhIQjx4BuxUd3qtcfyBW/+fo48lqPH467j9pd/XxYKE5Hf4MC47on/bsrWnf59GdSQ3+hOfzi+xPNERGQbgxoiIiJSBAY1REREnWBmtHthUENEXsE3B/ImPt8CE4MaIiIiUgQGNURERKQIDGr8CNOlREREzmNQQ0RERIrAoIaIiIgUgUENERERKQKDGiIiIlIEBjVE5BIWuBORv2BQQ0RE5AX8AOB5DGqIiIhIERjUEBF1I/y0T9Q5BjVERESkCAxqyCv46ZKIiDyNQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ2RAnHYIREFIgY1REREpAhOBTVr1qxBeno6QkJCkJGRgd27d9u9/V//+lcMGTIEoaGhGDRoENatW9fhNhs3bsTQoUOh0+kwdOhQbN682eXHJSIiosAhO6jZsGEDFi9ejGXLluHIkSOYPHkyZsyYgYKCApu3X7t2LZYuXYoVK1bgxIkT+MMf/oBHHnkE//nPf6Tb/PDDD5g9ezbmzp2LH3/8EXPnzsVvf/tb7N+/3+nHJSIiosAiO6hZtWoV7rvvPsyfPx9DhgzB6tWrkZKSgrVr19q8/UcffYQHH3wQs2fPRt++fXH77bfjvvvuw8svvyzdZvXq1fjVr36FpUuXYvDgwVi6dCmuvfZarF692unHJSIiZWLNGHVGVlDT3NyMrKwsTJs2zeryadOmYe/evTZ/pqmpCSEhIVaXhYaG4sCBA2hpaQFgytS0v8/p06dL9+nM44qPXV1dbfVFREREyiQrqCkvL4fBYEBCQoLV5QkJCSgtLbX5M9OnT8e7776LrKwsCIKAQ4cO4b333kNLSwvKy8sBAKWlpXbv05nHBYCVK1ciKipK+kpJSZHz6xJRN8VP8kSByalCYZVKZfW9IAgdLhM988wzmDFjBsaPH4/g4GDcdNNNuOeeewAAGo1G1n3KeVwAWLp0KaqqqqSvwsLCLn83MuMbAxERdSeygpq4uDhoNJoO2ZGysrIOWRRRaGgo3nvvPdTX1yM/Px8FBQVIS0tDREQE4uLiAACJiYl279OZxwUAnU6HyMhIqy8iIiJSJllBjVarRUZGBrZv3251+fbt25GZmWn3Z4ODg9G7d29oNBqsX78eN9xwA9Rq08NPmDChw31u27ZNuk9XHpeIiIgCQ5DcH1iyZAnmzp2L0aNHY8KECXj77bdRUFCABQsWADAt+RQVFUmzaH755RccOHAA48aNw6VLl7Bq1Sr89NNP+PDDD6X7fOyxx3DllVfi5Zdfxk033YTPP/8c//3vf7Fnzx6HH5eI5KlvbsXQZ7cCALKfn44wreyXAyIivyL7VWz27NmoqKjA888/j5KSEgwfPhxbtmxBamoqAKCkpMRqdozBYMCrr76KU6dOITg4GFdffTX27t2LtLQ06TaZmZlYv349li9fjmeeeQb9+vXDhg0bMG7cOIcfl4iIiAKbUx/NHn74YTz88MM2r/vggw+svh8yZAiOHDnS5X3edtttuO2225x+3EDBT9dERES2ce8nIiIiUgQGNURERKQIDGqIyCFHCyp9fQhERHYxqCGiTl2qa5b+/z/Hin14JN1fq8Ho60MgUjwGNUTUqR/PVUr/v+3E+YB6YxYEAYfyL2LxhqPSZUaj4NR9GYwCnt78k/R9VUOLq4dHRDYwqFEgbm9gVu3im4ezb2JKccRiyamirhn7ci/67mC8pLnViM+OFOGmv36P2/72A7adOC9dt/zzn2CQ+ZwwGgUs23wcXxwrkS67VN9s5yeIyFnsBybFOXOhVvr/3/ztB6z9nwwM7xUl+34u1jVj8XrzOII739mPuzJTMWN4EkKCNXZ+Ujl+LKy0+v6LY8WYNCDONwfjYRfrmvHP/Wex7oezKKtpAgBog9SYNTIJGw8XAQA+O1KMVoOAv8y+DMGarj8TCoKA57/IxvqDhVCrADEeqqoPvEyNZTDY0GzgOAoPamwx4OfSaun7v+08A12wBkFqFTTtvuQG6f6OzypSlNwLtZj3/kHp+8JLDfj12r14btZQ3DG2j90NUC0dyr+Ihf86gpKqRumyI4WVOLKhEn/84iR+OzoFd47rg5QeYW7/HfxFq8GI40XVVpd99VMpnr9pOLRBykryPvv5T/jPjyVoajUtr8VH6HDX+FTcMa4PQrUaKagJ0qjwxbESNLca8cYdl0MX1HlwKwgCXvr6Z3ywNx8qFfCnW4Zj6SbTElSgZGoEQcDhgkr858diq5qsz48W4d5JfX14ZMpxuqwWBRfr8cv5WuScr8Gp8zU4W1FvFay8vuO0Q/e1J6cc04YleupQvYJBDfkNy6WyvafLMXWovD+usxV1uOOd/SivNb9hXD04Ht/+fAHLNv+EQ/mX8Kdbhtv9hGg0Cnh7dy7+b+spGIwC0mLDkF9RDwBYdE1/fJJ1DiVVjfjbrjN467szuHpQT/xmdO8O99NqMKKspgklVQ0ormzE2Yo6q9+zO3xK/bm0Bg0tBun7uHAtymub8f3pclw9uKcPj8z9Ps0yBS0jekXh3klpmDkiWQrcLJ+Xb9x+OR7bcBTbss/jgXVZeGtuRqdZu9e+ycFbu3IBAH+6eQRuuixZCmoqu1GmxpmBnz+XVuPfR02BTOHFhg7Xi5kwct2Nb35v8/LIkCBUN5qeu7/JML1GGQQBRqOAVqMAoyCg1SCgxWDEt6cuAAAe+CgL8yel44nrBtkN2G3ZnXNB+v+6Jt+9xvn/KysFjB/OmOs17v8oC4uvHYiF1/SHWt11dqXwYj3mvL0PpdWN6Bevx5kLpiDizTmX4x/7CvDK1lPYfKQIPxVVYe3/XIH+PSM63MfFumYs+X9HsbPtD/ymy5KxfOYQjPnTNwCABVf1w6JrB2DHz2X4aN9Z7M4px46fy7Dj5zLpPua8vQ/nq5tQVtOIzrK6d793EO/dMwYJkSEOnxtfOFJwyer76cMS8fH+Avznx2LFBTUT+8Xid78aiIzUGLvZvCmD4vH+PWMw/8ND2PXLBcx7/yDevXs02v/I33adwer/5gAAnr1hKO4Y18cqOLrUjYIauW5883ucLjMvAYdpNZg+LBHThiXgoX8cBmBafiL3CNNqMDAhAoMSIjAgIRyDEiMwMCEC4ToNhj23DQDwh5uGdRpkWAatAPDunjzsy6vA67dfjr7x4V0+fu6FWrzw5Umr18HTZbWIj/DN65uycsjkE4LgnjXZnafMfxSCAPzlv7/gng8O4mKd/VR9UWUD5ryzD8VVjegbr8d794yRrlOpVHhwSj/86/7x6BmhQ05ZLW5883t8frTI6j6yzl7C9a/txs5TF6ALUuOlX4/A6tmXQa+zfiEI0qgxbVgiPrpvHL79/VWYPykdkaHm2/x4rgql1aaAJlijQu+YUIxN64GZI8xZpxPF1bjpze/xU1GVU+fJW7LOWgc1M4abfodt2efR2NL935QsO7meun4wRqf1cGh5cmL/OHx471iE64LwQ24F5v59P2oazUHKP/adxUtf/QwAePK6Qbh3UnqH+6j0k+UnT9RTnC6rhVajxrShCXjzjsuRtfxX+MvsyzBlYLx0m3oGNS6xfM3d/HAmPntkIl6+bSTmT+6LyQPikRAZ4vBSu6U377gcMWHB+KmoGje8sQefHCrs9PW9urEFf/oyG9NXf4cdP5chyOLD56iUaNmP7S7M1JDLvv6p1OX7MBoF7PrFnL588ZbheP6LbHz3ywXc8PpuvHnnFbiiT0yHnyutasQd7+zDuUsNSIsNw7/uH4+IkI5P67HpPbDlscl4bP0RfH+6Ao+tP4rZY1Kk6+95/yAMRgF94/T4651XYEhSZJfHnB6nx/IbhuKhq/oh44X/AgBeu/0ypMbqkRwVgrhwnZRlqm9uxZfHTeepb7weuRfq8Ju//YDXbr/Mb9ewD7cbtndZSjSSo0JQXNWInacu4Lrh7j/uJotgqbiywWZGzV3yys1Lgumxelk/Oza9B/4xfxzu+vt+HC6oxL0fHJKue3GLKaBZdE1/PHxVf5s/7+3lp6YWA85W1ON0Wa3p60ItzpTVWhXVu8Lyje+p6wZhzrhURIUGd3r7QO/KdJVlps+dGd9rBvfE6MeuxO82HMUPuRV44tNj2J1TjmUzB0u3MRgF/OtAAf689RQq2j5wXj0oHr+fPggzX9/jtmNxFjM15DJxPRZwPmvzU3GVVS3MzZf3wuaHJyI9To/iqkbMfusHfPB9ntX9X6hpwh3v7MPZinqk9AjFP+8fb/cPPC5ch3X3jsOia/pDpQI2HCyUrjMYBdx8WTL+vXCSQwGNpVCtee35V0MTcFlKNHpGhnS6bPbP+eMweUAcGloMePAfWXj7uzNuy3a5S3ltEwou1lstq6jVKswcmQTA1AXlCW9YFDROXfUdfvvWD/jn/gKPdAv9VGwugnZkibO9y1Ki8a8HxqOHXosTxdYF1fdPTsfvfjWw05+tbPB8pqas2lzknvHCfzHjtd1Y+K8jeO2bHHx5rAQ/l9agxWB+3rkyvuB8tblGZs64PnYDGkCZmRrLbiNPK7VoYHB30X5iVAj+MX8cnpg+CBq1Cv/+sRi3rv1Buv43f/sBSzcdR0VdM/rG6/H+vDF4f95YpMfJ+2DgKQxqyGWWL+jtX9wd9c3Jsg6XDUmKxL8fnYjrRySixSBgxX+y8fgnx6Tr531wELnldegVHYp/3T8eydGhXT6ORq3CkmmD8P49YxAdZn7h/eNNw/CX2ZchXOf55GVkaDDev2cM/md8HwiC6ZP9UxuPo7nVfwbbHW5beurXbk191qhkAKZ/L3d/2j5ccAkf7M2XvlepgAN5F/H05uMY86f/4oF1h7DleIlVNscV7lj+G5YchQ0PjEd8hE66bM7YFDx9/RC76f9LdZ7P1Lz5rTlANAqmwtEr+kTjt6N74+nrB+O9e0bjq8cmSbcprupY0OuoXIuslyOt7koLak4UV2He++Zsnbueo52x7Mr0BI1ahUeu7o9PFkxASo9QnLtkfm78XFqDiJAgPHPDUGxdfCWuHuRf9XVcfiKX1DS2WKXxt504j7HpsbLvx7LIzFJESDD+escVeP/7fLy45aTVUlfuhTokRYXgX/ePR+8Yea3VVw3qiY0PTcC1r34HALg1o7dTa9DOCtKo8cebhqN/fDie/yIbGw4VIq/cPUsB7iAuPV2WEmVV9DmiVxT69AhDwcV6fHOyTApyXNXYYsDvP/nRqrj6v0uuxPbsMnx2pAg/l9ZgW/Z5bMs+77bA86ci93yyHpAQgXX3jsGM10yp92VdBDQAUOnhicJl1Y34/Kg5m7briavQp0dYh+OyDExzL9RhYIK8LKVI7nNXSUHNieIq3Pnufqsp0ZuOFOE+D7asl1Y7H4DKcUWfGHy5aDKWbjwmLZ/PHpOCJ6cPQmy4rouf9g1masgl7d8YtmaXyl5KOV/diON2PjWrVCrcOykdGx6cgESL5aX4CB3+ef949Il1blZMUlTXmR1PUqlUuGdiOv5+9xjotRocyL/U9Q95yeG2zqf2BX8qlQqzRpmWoP7zo/uWoFZt/wW5F+qsMh5JUaFYMKUfvl58JbYuvhIPXdUPyVEhqG0yvxE7my1qbjXi1Pkal49blGpRk+PIUpan59R8sDffamkpPkLXZaCVe6HO7vX25Mn8WaXU1PxUZApoKutbMLK3ecDnO9/loanVc4FbSaVnMzWWIkOC8cptI6Xvn5s11G8DGoBBDbmofQq/8GIDskvkfQL+ti1LM6KLqb8ZqTH49KEJ0vfv3zPab9ZxXXH14J7Y+HAmkqLMAdvyz37Cp1nnUHix3uv1Ni0GI4617fl0uY0uhhtGmrIzO3+5gOpG1zMOWWcv4Z3dpnkuf7hxqM3bDEqMwP9eNxh7/vcarLvX3N32Y6FzS0i/nK/x6XJfVX2Lx/5da5ta8dG+s7J/zjLjKv9n62XdXgmZmp+KqvA/fzcFNJelROOduzKk60qrG7Exq8jOT7umtNp7QQ0Ar2axXcWghlxyzEaG5avj8rqhvmkLaq4eFN/FLYEeeq30/47MUOguBidGYsOD46XvNx0uwu8/+RGTX/kWE1buwKJ/HcE/9p1Fzvkajwc5J0uq0dhiRFRoMNJsdAUNToxA/57haG41YrvFvkjOaGwx4IlPfoQgAL++oheu6mJ9Xq1WYXRaD+n7Q2edy27Zywx6Q6tRQE2TZ7IV6w8UoKaxVXbA70onlNyAqLsHNZYBzeV9orHuvrGICLEujl6z8zRaPLQBbKmHa2q6MwY1XqDkDSaPW+ziLNpyvMThN97GFgP25JQDMA02C2RxFind+ZPTkZEag2CNCqXVjfj3j8VY/tlP+NVfvsOkl7/16HGIRcKX94m2uZSiUqlwg5u6oP689RRyy+uQEKnDczcMc/pY5Tpm43nrbZUeKBZuMRjx3p48AMC8iWmyftbZTE1tU6vszEF3fh20XHK6vE80Prx3LCLbBTSxei3OXWrA5iOeydZ4ulC4O2NQQ06ramiRthAQaYPUyC2vwy/nHfvUty+3Ag0tBiRGhmBwoudmknQ3S341EBsfysSx56bjn/ePw+KpAzCxfyxCgtUen0YrFgnbmgskEpegdueUOz1I7lD+Rfz9e9Mb8Eu/HomoMPttwLb8eK7SqWWkY+d8P/jwogfqar44VoziqkbEheswqy3wdNSl+pYuB13aIreeBgBa2sbzdzfZJdVSUXBnAQ0A3NMWUK759rTVkEd3MBgFbjNhB4MactqJthR+Soy54HZif1Pn05fHSxy6D7GV+5ohPbvVuq23hGo1yOwXh8VTB+Lj+eNx7LnpeP32y6TrPTHZVywSthfU9O8ZjiFJkWg1CvivjXb8rjQ0G/DEp8cgCMBtGb2d3nahscUoeympscWAU6XuKxJ2lruLhQVBkPaamjcxDTondpJ3Zgkq18muve64BHXvBwelgGZdJwENANw+JgUxYcHIr6i32sjTHS7UNCluZ213YlDjIiUvLXVFrKcZmmxuA53etgnlVw4ENYIgSK3c1ypsLyFP0Qapce0Q87k6kHfRzq3lK6tuxLlLDVCrgFEp9gu3xSWoLQ4GsJZe/yYHeeV1SIwMwTM32C4OdtTBfHnn4OfSGrQaBav6LF+45ERWxJ7vcsrxc2kNwrQa/M+4VKfuw7J931FnnPgZoHsuQVU3tEoBTfsaGkt6XRDmTza1dL+547RbgxBX5gkFAgY15LTjbSn84cnmN7+rBsUjWKNCTlktcrpomT11vgZFlQ3QBamR2S/Oo8eqJJYZLcutJdxBzNIMTIiw+6INALPalqCcCazWtXXnrLx1RJfTZ7tyUObji/U0w5Kdm8niLu5eRnxr1xkAwJyxfZxaygOcC1DOONkKXtfk2UzNBYslmho3dOkBwMjeUV0GNKK7Jpi2ijhzoc6pwL8z3mzn7o4Y1JDTxLT/sF7mN4fI0GBM6m8KUL7qYk8ocelpYv84q60GyHE7T11wazeUVE+T2vnSk6hPbBhG9Y7qdDdyewQB+E1Gb7dMIz2Yf1HWiP9jUjDu46DGjZma4+eqsPdMBTRqlc0NNB112onlJ2e7pjy9U/f/O2TeBqV97Z+z7s5McyigAUyDQ++daPq3eHPHaYefo11l/4srmamxh0ENOaWyvhkFF00vFEPb7ZU0Y4RjyxLi0tM1XHpyWklVo8NF2Y4Qu4ns1dNYcnaicEKkDstdXHYCTDVH1Y2tsgbpSRnGLuYieZo7a2re+s6UpblxVDJ6ObBdSGfkBigGo+B011SdB5efmluNVnu7FV50T1DTp4e8c3vPxDRE6IJw6nwNtmW7vvEvwOWnrjCoIaeIWZq02DBEtls+mDY0AUFqFX4urUFuJy+SF+uapaUOyxoRku+bn12bFSNqbjVKdVJX9Il26GeuH+FYh82J4iqs3HJS+v4PNw5zedkJMA8HdLSupr65FTllpgDI98tP7glqCi/WSx8g7p/s2mj+c5caZBWfF1c2oKnV6NSmip6sqfnqpxKrDXILXAhq6izmCaXI3I4lKjRY6oR6/ZvTbsmqcvnJPgY15BQxhT+id3SH66LDtJjQz9QF1dkS1M5TZRAEU5bH19sVdHc7nOg+siW7pBrNrUbEhAU7PLgtOTq00wDoQk0T3t2di+tWf4eZr+/BR/sKpOuuHOiemUQZbctkjtb1ZBdXwyiYMkU97ezo7g3u2tTy3d25MAqmczrUhUAtKjQYgiBvuwRxuSq1h/ytSjxZU2O5MSrQeVDjSKOH5WaO7T/AOeLeienQazXILqnGzlOu18CVMFNjF4Macoq4PcLITlL44if4r36yvQQlThFmlsZ1hwsuOTVfpL0si6UnOe31M0YkSv/f1GLAl8dKcO8HBzF+5Td44cuT+Lm0BlqNGtOGJbh8jO2JQc3B/IsOfQr+UQzGe0W7/Vjkckem5lJdMza01Y48eKVrWZq+bYGsnLoaMQBKj5e/XYmnMjXHzlXiSEElgjTm53DhRecDAVeXrmL0WsydkAYA+FtbMbcrijl4zy4GNX7E2SFmvnCsi7qE6cMSoVGr8FNRNQraFem1GIz4ru0TC+tpXDMoMQJGAdj1i+vZGmk+jQNFwpamDTUHNVP+byce+edh7Pi5DAajgMtSovHHm4fjwLJrsXr2ZS4fY3sje0chWKPC+eomh5YYxAnYlpsP+oo7gpp/HShAY4sRw3tFIrMtO+qsvm2BiZwOKLEGp68Te7B5ak6NmKW5bpj5eelKYHLWDfU48yenIzRYg+Mu7gzf3GpEeS0H79nDoMaPrPtB/iZ0vlBR24Sitgr84b1sp7t76LUY39e0R8+Wdtmaw2cvoaapFbF6LUbZWL4ix13VtozzjRuWoI5YbI8gh+XO2tWNrUiKCsHDV/XDN49PwWePTMTc8amIDvPMTJiQYA1Gtj2HHFmCEmuG/CKoqXN9U8uP95uW9B64sp/LwyvTncjUiAFQmp8ENeW1TfjiR9PrzZ3j+kiXl9U0OT2o0h1FxnHhOqvjcdb56kYIAqBzooYpUPDM+BHLDg5/nhgpFgn3jdfbbW+cMbxtCapdF5S4rnz14J429xYix13Vtl/Wrl8uuDR2/nx1I4qrGk1D91wINN+9ezT2/O81ePK6wejnpQ1Hx7RtcNlVsXBNY4u0XNLVjvDe0GwwuvzGfqm+Bb1jQnH98MSub9wF8d9LXqbGdD6dydTUeWBDz/UHCtBsMGJU7yiMarfDvLPFwq4sXVl64Mq+Lgcj4ofJBB/Xg/kzBjV+5EyZuUDvJx/vImyPeGxdvTFMH5YIlcpUx1BkMVthZ9vAOE4Rdt3wXlGI1WtR09iKQ/nObe4IAEcLKwGYdgvX64Kcvp/MfrHQeDlQHZvuWLGwGIz3ig5FrMXmob4gdgu5oxZq/qR0BGlcfykX62Jyy+sc+lBV1dAiLYXI3REccH+mpsVgxD/aitHvzkzrcH2+k63nhZfc0w7eMzIEt2X0duk+xCLhpCgGNZ1hUOMnGlsMVn88u9t2rvZHUudTF0FNfIQOY9s+RW8/YW47PltRj2CNCpMGcIqwqzRqFa5qG2C3w4XW7qNtQ/cyZNbT+IOM1B5QqUwD1spqOi+iFOfT+MPSU0zbxN9KF6cKR4UG47djUtxxSOgVHQptkBrNrUYUXeo6OyGOa0iI1DkVCLu7UHjbifMorW5EXLgWM21s5ulMpqbFYHTrjthzxpr/rZzJxhe3tXMnMqjpFIMaP3HmQi0sl9f9Oag5LtUlRHd5W7ELalu29Rvu+L6xDk/mJPvEDjKxo8wZYqbmitRoNxyRd0WFBmNwoqm262Be59mqYzKet54W3dYa7OpO3b8Z3RthWucza5Y0apVFB1TXwwzFpSdnlxnr3Jyp+bCtQHjO2D7QBXWcUH7WianCRZca3FoKkBprzmg505rNTE3XGNT4iZx2U2F/Kq5yS2ra3S7UNKGkqhEqlWPDy65rW+sX3zRF7Hpyn8kD4hCkViH3Qp3TKfbsElNXhqOThP3N2DRza3dn/ClTIxZOu9rxODgxwh2HI+nXU6yr6fp5JHY+ORvU1Luxpia7uBoH8i8iSK3CnZ1s5ulMF5M7Op8sWS7NOrNnVgkzNV1iUOMnxCmnIkEAdue4d7NCdxDrafrFhzuUck6IDMFoG0saDGrcJyIkGOPaOs12OJmtaTEIiNVr0ceJIWr+YGy6qZ15fyd1NZbbelhuwOor0W3LT65+cIl3c22QGKA4slt3rhTUyK+nAdybqRGzNNOHJ3b6hn+2Qn4QUeDEzzhKzpBDkTijJpGFwp1iUOMnbO3fs8sN0yfdTayn6Wzoni0z2o3S7xuvt0rDkuuuGWwabOdsUAMAl8scuudPxrQVC/9cWo2qho51KuLzNi02zOkdrN0ppi1T4+pO3fGR7g1q+ouZGgfauqXOJ2czNW6qqamsb8ZnR4sAAPNsFAiLii41oFVmh6C7NsK0Ja9c/p5tXH7qGoMaP2Hrk9F3ORdk7T7sDceLKgEAI2Sk8Ge0aze9yk0j8slM7CTbn1eBmkbn3ii7Y5GwqGdECNJiwyAI5k05LYl1YLa29fAFMVPjzE7dlq3Q7s/UmGfV2Juh02IwSpkPcclKLnd1P32adQ5NrUYMS47s9DmsDVKj1ShIhbaOcqYOx1FyMzX1za1SYTmXnzrHoMYPNLYYOqRGw7QalNc2S7UO/sLRzidLydGhGGURBImzVch90uL06BunR4tBwB4ni8wd3cTSX4nzamwtQR1rmyQ8yg/qaQDLTI38oOZCjXmirCvt97b0jQuHSmXqyrK3NFZ4sR4tBgGhwRokObkUUu+mvZ/+dcC0TcTdmWmdZhp7x5j2lzt7UV4gUSDz9nKcuVAna/iiGJCF64LYZGEHgxo/kHuhDkYBiAw1v0CN72uqEdh5yj2bFbrD+epGlNU0Qa2C7I3zplmMLL+s3VAscg+xTsmZLqggtcovuoJcMTa98yF8x50Ixj1JXAJzJqgpq/HcmPxQrQa9ok0BgL26mlxp6Unv9ADNOjctP5VUNSImLBg3jkru9DZ92nbXlpN5EQTBpd29u1LVYD9wbI9LT45hUOMHxCLh/hZr0+IMl12/+E9djfjGMKBnhOw20lsuN7/guGNQGHV0TVtr97c/l8lethyUGIFQbcc22O5EDGqOnau0GolfXtuEYrFjz0+Cmhhp+Un+UqG9WTzuYK6r6TxLIe355MLU6Ppmg8vbRIhuH9sHIcGdP39TerRlamQU/pq2VjB6dJikIwXZIrHzKakt6CTb+O7iB8R2bsu16cn9TUHN4YJKm4WPvnBMqkuQ/8bgqb1/yGxMWg9E6IJQUdcs1ZA4qv1I+e6oT48w9IzQocUgSAE4AJxo20SwX3w4wt28XOOsaJeWnzw76sGRDqgzLnY+Aabhc80ubO0hUquA/xlvu41b1CdWfqZGvK0nMyNy2rqL2zI1vaKZqbGHQY0fsJWp6RUTin7xehiMAr4/7R+D+BzdHoF8I1ijxpUWe0HJcbkCghqVSoUxbdmaQxbFwj8V+898GlGMS8tP3srUdL385Or+Xu6oq7l2SE9pyawzKW3LT3KWk8SsjviznuBUpiaKmRp7GNT4AVuZGgCYMtC0nOAPrd2CIJiLhP3ozYGsiV1QO7t4zgiCgE2Hi6TvlVLnNK4tqMmyCGrETI2cMQSeFh1qytQ0thjRILML6IIHa2oAeZmavk5masS9r5ytq7Hs8Ots2J4lcf5SwcV6h5e8xABIXLryBDk7ohezpsYhDGp8rKnVgPy2TwT9271AWO7A7K61Z2edr25CeW0TNGoVhibJKxIm77lqUE+oVMDPpZ2Pua+qb8Gj/zyC5Z/9JF2WrJCUttgBZTnBWszU+Es7NwDodRoEa0y1GnKzNWXVng1qxExNUWWDzYDrYl2zNF+nb5xzmZqwtvotZ9u6Led6jUnrehRBcnQo1CrT412odez8iTNqUjw4kFLOjujiHlTJrKmxi0GNj0mdTyFBiI+wnjkxNr0HQoLVKK1uxKnzXe/F4kniG8PAhAi7BXnkWz30WrtbHezPrcCM177Dl8dLEGRRANldh+61NyghApEhQVZvluW1zX4XjKtUKqmuRu5UYUfflJ3VQ6+VlsdsLUGJl/WKDnW6uFwMauqc3CqhttH8c448d7VBamnZxtG6GnGasCenbBdVNjg0hFAQBJRUMlPjCAY1PpbTFqkPSIjo8McZEqyRWrt9vQSVXWxK4Y/o5T9vDGSbrS0oWgxGvLrtFOa8sw/FVY1Iiw3Dx/eP88HReZZarcLotmyNpYEJ/tfd1UPa/8nxRgBBEDza0i2yV1cjbY/g5NA9AFL3pNylN1GtE8FQWpy8YuGzHl5+EgNHR4bwVTe0SttKsKbGPgY1PpbTloEZmGD7BUKcvuvr1u6f2uoS/CmFT7aJu3aLCi/W4zd/+wFv7DgNowDcltEbXyyarNiCb7G125I/1dOIpP2fZCw/1Ta1Oh0IyCHW1dhaHpG2R4hzvvNJytR4Majp08N0vI7s51TV0CIFm54qFBbb4R3ZkkKsp4kJC/a74NzfMKjxMbFIuH9P27vtThlkeoM6mH/RqT9kdzkhdpD44ZsDWRuUEGGVov712r04WliJiJAgvDHncvz5N6P8prXZE8bYyNT4Y3F7D738nbq9kaUB7M+qEQMdVzI1ocFiTY3ry0+OShXbuh3ogCpoy+bEhevcPrVZJBZZO9IBJQ7eYz1N1xjU+NgvZfYzNWmxYejTIwwtBgE/nKnw5qFZuVTfgiC1CoMSbQdf5D9UKhWmWOyvVddkwOjUGHz12GTMsjN1VSlG9IpCSLD1S5s/tXOLnKmpOV/t2XZukb0OKHfMqAnTiTU13svUpPZwfPlJ3E5BDIQ8Qcx0ORLUFLOd22EManyoqdUg/YEN6CRTo1KpLLqgfLtlwqBEFgl3F5Z1NY9e3Q/rHxiP3h6ct+FPtEFqq4xikMY/g/EeetPyk5yaGk93PonETE1eeR0MFtOpm1uNKLxkyhr0d2FGjVhT42ympsaZ5SdpAF/Xy0/i63KqB4uExUyNI8tP5kwNi4S7wqDGh8QXjIiQICREdr7brvipe+cp37Z2++OnXbJtYv9Y6f8fvrp/wG1NkWGxBDU4IQK6IP8LxmOcyNR4evCeKDk6FLogNZoNRpy7ZM5sFFysh8EoIFzXsVtTDldbup3pmkqNNQURl+pbUN3FTvbi8lMfj2ZqzIFjaxeTlTl4z3GB9UrnZ8R6mgE9w+22JU7oFwutRo1zlxqk2Qm+MKJXtM8em+RRSou2szJSzW3t/rLfU3vObJVw3kuZGo1aJRWyWnbn5JWLk4T1Lj3HzIXCzg7fk/9z4bogxIWbznlBF6+j4uwwTy4/JUWFIDRYgxZD1xtnFjNT4zAGNT5k7nyynxoP0wZJHR17crreMsGR9Gp9cyvSnvoSaU996XAKWKndMqQ8oyyyisNl7ijvLeLyk7ygxjuZGsBcM5Nbbn49cdf2CGFiobCTNTXOzrfp42BdjRhkiB1TnqBWqyyWoOy/ZouD95ip6RqDGh8SZ9T0d6CLQFyC2p1jv7X7UP5FzHlnv/R9tZs2wwzWqDAw0bUXMup+wrRByH9pJvJfmil7Z3ZfsuxYmdAv1s4tfUfK1MjYqdtb3U+A+XXJMlMjZjCc3R5BJD6XnM3UONsJKi5BiYXAtjS2GFDaFjx6MlMDOLYlhdEoWCw/MVPTFQY1PiQGNV1lagBgSlux8MH8S53e5vOjRbjjnf1WhYeFl9yzXDXIT+sSiLrir22w5uF7MmpqvJqpMdd8iNyWqWnrfnJ25o4zy0+ARaamvPPXxXOX6iEIgF6rQWxb272nOLJ5aEVdM5oNRqhUQCKDmi51n49eCtPcakR+24vFgE7auS0N6BmO5KgQFFd1fFETBAF//fY0/rztFwCm4WvfnDR1ShVcbMCYNNePd6gXUvhiVoAoEIiFwnXNBjS1Grr80CAIgtdqagDLTI35DVeqqXFhRg3g+vA9Z5efpKnCdjI1UudTrGt1Q44Qz7G9TI3Y+dQzQofgACv4dwbPkI/kV9Sh1SggQheExMiuo2+VSiVlayw1txrxxKfHpIDm/snpWD37Mun6cw4MmnKEN4IaokASERIETdv+W460ddc2taKhxfPThEXpcXqoVEC1RVaktqkVapXryzLS8D0ngxNnWroBy6nCnb8umoMaz49AsJzc3FlnK2fUyMOgxkd+aSsS7p9gv/PJkuVANcA0yvvu9w7g06xzUKuAP948HMtmDpVeKAH3LT+lx3quYI4oEKnVKkSHtm2V4EBbt5iliQjxToI9JFhjc4uAlB5hLi9Fm2tq5AdpTa0GNLfab4HujBiolFQ3orGTAFEqEvZCUJMWFwa1yhSkXeikXoozauTh8pOPWLZzOyqzfxyC1Cq0tg3DuvOd/cgtr4Neq8Gbd16Bqwd13Miw8GKD08do+cLhjU8tREpma3k1Rq9FRV2zQx1QYj1NfLjO6ZoSufrF6zu0GztbT2P5+x/KvwjAueF7zmyRIIrVa6HXalDXbMC5S/U2663E7tFUD3Y+iXRBGvTpEYb8inqcLqtFTxtZe093Prlr2d9fygeYqfGRnDLH2rktRYYE47KUaOn73PI6JEaG4JMFmTYDGgBdzj+wp7jSHBC5MmiLiGwTd2oWO6DsjVoQO5+8+bdoqzPT1vYIcrvkzBOF5WdqXNkDT6VSoY/YAdXJEpQ3l58Ai7qaToqFxddhdj45hkGNj5g3spT3qWfSgDjp/4ckReCzRybarXcprW5EU6tz6/CWf/SBPsyNyBNiZAzgE2fU9LQzfdzdbGVlXO18AgC9zvmaGlezVGmxnc+qMRgFacm+jwe3SLAkFl3b2hEdMGdq/LWLz98wqPGB5laj1EUgJ1MDADNHJEn/v+7esV22+AkCcO6Sc0tQrmR5iKhrUlAjo6YmPty3mZq+bghqQsVtEloMMBrlbf3ialAj1srYen0rqWpAi0FAsEbltSBCmlXDTI1bsKbGB862dT6F64JkP1F7xZj/0CwHjNlTUFHv1KcrRyYTE5HzYvRipqbr7idx36eeXlx+sp2pcb3WRN+2/CQIQGOrQdZgR1eWnwBzrYyt1zexK6p3TJhVw4Un2WvrbjUYpQyd3CDLX2pcvI1BjQ/8YrH05I1lHWczLl2NEhcF6h8PuV+gPZekmhqHCoXbMjUOjIBwlxi9Fj30Wqk7Kyo0GD3cMJBObOkGTHU1coKami42o+xKqp3lp7MXvVtPA5gDx/PVTahpbLEKpi7UNsEomCa6W2boAu3vRA4GNT4gFgnL6XxyhaPBSXvddfnJH//g/fGYyDGe/LczZ2ocWH7yQaYGAPrG6aWgxjS7xvUPYmq1CmFaDeqbDab9n2S8FLqaqRFrZQovmXYctyQVCXupngYwBYrxETpcqGnCmQt1GGgxjLW0rZ4mITIEai9ljro71tT4gJztEdyhwM70zM40txpRVOl8OzgRdc3RmhpBEMyZGi8HNekWy03pce5rc3Z2/ydXa2qSo0MRrFGhxSBIezyJxNfKPl6ey9W/kz2gxKAmmYP3HMZMjQ/kWAze8wZnMjWFl+ohs36PiGQy79Rtf0mlxmKasDcLhQGgn0Ug09etQU1bsbCXgxqNWoWUmDDkltehsF022pVMjSsZvX499fght6LDHlDSjBofD97rTplmBjVe1mJwvvPJWQUX62E0CrLSl4FQJNyd/lDJ/fzh3z/awUyNOHgvMiRI6hzyFqtMjRuKhEXS/k9N8kZOuFpTA5g6oNoHNYIgeH1GjajTTE01t0iQy6nlpzVr1iA9PR0hISHIyMjA7t277d7+448/xqhRoxAWFoakpCTMmzcPFRUV0vUtLS14/vnn0a9fP4SEhGDUqFH4+uuvre5jxYoVUKlUVl+JiYnOHL5PFVysR4tBgF6rQbIXWvQ0ahWaWo3S4C5H5dnZxZaI3EPcqbumqRUths5H/4tLT7YmznqaZQu3O5efxO5NuQP4XK2pAcyZGMu6wUv1LdJ9p3ixpgYA+vc0fcBtn6mRlp+4RYLDZGdqNmzYgMWLF2PNmjWYOHEi3nrrLcyYMQPZ2dno06dPh9vv2bMHd911F/7yl79g1qxZKCoqwoIFCzB//nxs3rwZALB8+XL84x//wDvvvIPBgwdj69atuOWWW7B3715cfvnl0n0NGzYM//3vf6XvNRrvfmJxB3HAUv+ECK90PiVHhaDwUgPOVtTJ2rZe3EGcuuYPn/jJt5x9DkSGBkOlMrU2X6pvRngnYxrEIuEENw/ec+S4kywCqZQY92UMnF1+cmWbBFFqW82M5TYyYtYmMTIEIcHefW/p19M85dhyexpPb5GgRLIzNatWrcJ9992H+fPnY8iQIVi9ejVSUlKwdu1am7fft28f0tLSsGjRIqSnp2PSpEl48MEHcejQIek2H330EZ5++mlcf/316Nu3Lx566CFMnz4dr776qtV9BQUFITExUfqKj++4a7W/E9OL3up8Ej9xnJXZyZQfAMtPjpA7/p1IDo3Fppb2duoWB+8lRHj/E7vlsnWQxn29JdLyk8xMjTv2vUq1MYDPmxtZtpcYGYJwXRAMRsHqmJipkU/WM7S5uRlZWVmYNm2a1eXTpk3D3r17bf5MZmYmzp07hy1btkAQBJw/fx6ffvopZs40fzpoampCSIj1P1poaCj27NljdVlOTg6Sk5ORnp6O22+/Hbm5uXIO3y+cuSDW03gnqOnd9smqfUFcVxjUEHmH2AFlb6du84wa5ezBJg7gk7tVQo07lp9izW3dIvE10pvt3CKVSiUNNcyzyJJXtD0n2P3kOFlBTXl5OQwGAxISEqwuT0hIQGlpqc2fyczMxMcff4zZs2dDq9UiMTER0dHReOONN6TbTJ8+HatWrUJOTg6MRiO2b9+Ozz//HCUlJdJtxo0bh3Xr1mHr1q145513UFpaiszMTKvanPaamppQXV1t9eVr5kyNd4qEpUyNjA6o5lYjipzcWoGI5BFn1VTamVUjLT/5IFPjKWE6ZzM1rhcK944Jg0plXaRc2Paal+bGuiE5xCF87etqQoLViG4b0khdcyqX2L4WRBCETutDsrOzsWjRIjz77LPIysrC119/jby8PCxYsEC6zWuvvYYBAwZg8ODB0Gq1ePTRRzFv3jyrmpkZM2bg1ltvxYgRIzB16lR8+eWXAIAPP/yw0+NcuXIloqKipK+UlBRnfl23ymvLgAzwUqamjxPLT2I7t7e7LIgCkThV+GJd52/WYvdTgg8KhT1FzNQ0yK2pcUOmJiRYg8R251LM1HhrI8v2xI0tcy9YZ8mTo0K5obAMsoKauLg4aDSaDlmZsrKyDtkb0cqVKzFx4kQ88cQTGDlyJKZPn441a9bgvffekzIx8fHx+Oyzz1BXV4ezZ8/i559/Rnh4ONLT0zs9Fr1ejxEjRiAnJ6fT2yxduhRVVVXSV2FhoZxf1yNaDQLCtBqvpRNTepgep0DGcpJYJOyrP26iQOLITt1i96KcHbr9vR7MPHzP8UyNIAhuqakBOrZtF/hgiwRL4h5Qee2aNHw9o6a7kRXUaLVaZGRkYPv27VaXb9++HZmZmTZ/pr6+Hmq19cOIGRhBsJ7uFhISgl69eqG1tRUbN27ETTfd1OmxNDU14eTJk0hKSur0NjqdDpGRkVZf/qB/z3CvjbxOiTH9gV6qb0G1g2lb8Y/KV3/cZJ+/v1mRPNJWCZ3U1AiCIG1qqKjlJ7H7SUbmpbHF2GFrA2eJG1uKymubbV7uLeLyU277oIb1NLLIXn5asmQJ3n33Xbz33ns4efIkfve736GgoEBaTlq6dCnuuusu6fazZs3Cpk2bsHbtWuTm5uL777/HokWLMHbsWCQnJwMA9u/fj02bNiE3Nxe7d+/GddddB6PRiCeffFK6n9///vfYtWsX8vLysH//ftx2222orq7G3Xff7eo58Dpv1dMAplkQceGmF80CB+tqfLH/CVGgMmdqbH/oqG5sRWOLqc1XTqbG3zlTU1PTZDpH7vhMaKvLKSo0GFE+ql9JjQ1DkFqFhnbnwxvzzJRE9se82bNno6KiAs8//zxKSkowfPhwbNmyBampqQCAkpISFBQUSLe/5557UFNTgzfffBOPP/44oqOjcc011+Dll1+WbtPY2Ijly5cjNzcX4eHhuP766/HRRx8hOjpaus25c+cwZ84clJeXIz4+HuPHj8e+ffukx+1OvFVPI+rTIwzltc04W1GP4b2iury92Pnki9bGQMZ5N4Gpq526LacJhwRrZM918VfmmhoZQU3b0lO4LgjVLi5D2cpE+zI7HaxRIzU2TOqQFSVFM1Mjh1O564cffhgPP/ywzes++OCDDpctXLgQCxcu7PT+pkyZguzsbLuPuX79elnH6M+81c4t6tMjDIcLKh3edVsManyVhrWHb/ykNF3t1C3W0yipSBiwnFPjeHAiDt7TuyOosfH65us6wv49wzsENckMamThgrwPeHP5CTDvOOvIbt2W7dysqSHyvK526j6vwM4nwGKbBBl7P4mZmoiQIJRU2b9tVx+AbGWiff2a179nOLaeOG91GZef5GFQ42WhwRr08nLknSpjVk3BRVM7t16rkWpxiMhzutqpW5wm3DNCOfU0gHlkhKxMTVtNTWfbScgRFRqM6LBgq0nOtrI33swO94vvmMXn8pM8DGq8rG+83mudTyLx04cjQY24O3dqrJ6zEcgvKW0JUtypu6qhBa02NrUsaxu854vNLD1Jmigso6am2qKmxh1SYsJQWW9O+fhDpsZSREiQ237XQMGz5UaP/vMIYvVa6ROAqZJei5Agc5NZ+yetN4hp1pKqBjS3GqEN6rzpTWznduduvETUOXHvJwA260TELRLcvZmlrzmzoaVYUxMe4p63rj49QnG8yDKo8e3rXvtMTfsBgdQ1BjVutOPnsi5vI+7v4U3x4TqEaTWobzbg3KV69LWR4hRJRcKspyHyiiCNGpEhpsJXW8XCYk1NTwXNqAHMNTXi7BmNAxlscZqw2zI1FoXBuiC1z5f49LogJEaGoLTt3zyR9TSyMahxo+dmDUVDiwFV9S2oamhBZdt/L9Y341RpDQBg6lDbk5c9SaVSoU+PMPxcWoOzF+0HNeISla/2PyEKRD30WlQ3ttrcqdvc/aTMTA1gytZEhHQ9H0bc98ldQY1lt1PvmFCvlwbY0jdez6DGBQxq3Gj2mBSbE17rm1sx9NmtAIA0H6U3U9qCmq526+byE8mltBoXX4gO0wIV9R0yNVbThBW2FKELUkOtAoyCqa7GkaDGk5kaX7dzi9Lj9Nh7xrRRc5LC/s29gUFNgHCkA6qp1YDiSrZzk2cw+Olcj7ZZNVXtMjXVDa1oajUVD8crrPtJpVJBrw1CTVOrw8XC1W6vqTG/zqX4SVBjWaLAfZ/kc2qXbup+HOmAKrzYILVzx4cr6wWUyJ9FdzJVWOx8igoNRkiwpsPPdXfSVgkO7v9U6+buJ8uxFeLmv75mWR7AQmH5GNQECEcG8Im7c6fFsZ2byJt6tLV1t6+pOa/QzieR3LZuqabGTZkay9c5WzNifMFy6Z81NfJx+SlAiMtPBRfrO+yOLhI7n3xV90MUqMxbJbQPapTZ+SSSO4DP3TU1lsam9XD7fbbnyBKsZfbI24NalYBBjR/xZM1Br5hQaNQqNLYYUVbThAgbn3SkoCbOP9aWybNY4+I/xK0SKhvaLz+1TRO2yNQo6d9NytQ4uFVCrcU2Ce7mD51PgHX2KEjDxRS5eMYCRLBGjeS2orPO6mryy9vauZmpIfIqcafuyjrbmRqldT6JxJoaRwfw1VhsaElkC4OaANJH6oCyXVeTZ1FTQ0TeIy4/VTZYBzXSFgkK63wSyampMRoF1DZ7bvmJlIFBTQDp07ZZm61ZNU2tBhRXmdq5makh8i5pp+723U9SobBCMzUyamrqmlshlgNGMKihTjCoCSBSW7eNoKbwYj0EwfQJiLtzE3lXTNtO3dXtMjXna8TlJ2VmaqT9nxyoqRGLhIM1Krv711Fg4zMjgNgbwJfXVk+TGhvGdm4iL4sONX2QMFo0JpqmCbcVCiu0+ylM5/jyU41UJBzM1yjqFHN4AUTcrbvARqbmbAXraYh8RRukRoTONF1XVN3YimaFThMW6WXs1F1jMXhPSR1g5F7M1ASQ1LZamYt1zVJrpEja84n1NEQ+Ea233vtIbOeODlPmNGEA0l55dQ5kasTlJ0+0c5NyMKgJIOG6IMS2dVkUXLLO1ogzarjnE5FviFOFRReqld35BFjW1DiSqXHvDt2kTAxqAoy4aVv7DihxRg135ybyjej2QU2tsjufAHNNjSPdT54cvEfKwWdHgEmNDcPRwkqcu9ggXdbUYtHO7aGghmvgRPaJO3WLyhReJAyYa2oaZBYKE3WGmZoAI+0BZbH8dK6yQWrnjtWznZvIF8SdukW2tkhQGjk1NTUe3PeJlIPPDgWylxURd+u2XH4SW7zT4tjOTeQrHWpqxOUnBdfU6HXya2q4/ET2MFMTYMRC4EKL5ScpqGHnE5HPROvbFwoHQE2NNFHYge4nsaWbQQ3ZwaAmwIjLTyVV5qBGnFvDoIbId9pnagJp+cmROTXmlm7W1FDnGNQEmPgIHUKDNVaTSzl4j8j3YtrV1IjLT8ouFDYFNS0GQRo02BmpUJg1NWQHg5oAo1KppN26ReLyU3ocZ9QQ+UpMu+Un8U1eyZmaUK15qGBXHVAsFCZHMKgJQCntgprStiFfqVx+IvKZmLCOnYfRYcHQBSlzmjBg2h5CqzG9DXU1q4aFwuQIBjUBqP3UYEEwpXTZzk3kO+1bugEgQcFLT6JQB/d/YqEwOYJBTQCytRVCWpye7dxEPhQSrLFajgGUvfQkMm9q2cXyU1tQE8lCYbKDQU0Aal9TA3DPJyJ/0L5YWMnt3CJpq4SmzoOaVoMRDS2m61lTQ/YwqAlAtmpnuOcTke9Fh1ovASt5M0uR3oHlJ8uAh8tPZA+DmgDUKzoU6nYrTZxRQ+R7AZmpcWCrhOq2IuGQYDWCNXzbos4x5A1A2iA1kqJCUVRpHsCXxnZuReEGot1T+2LhhACoqRGnCtvbKqFWaudmPQ3Zx6AmQPWOaRfUMFNDCtJdg7rodm3d8QHQ/STW1NgrFDYXCfMti+xjHi9AWRYLR4QEoQfbuYl8LhAzNY7U1NQ2mZafWE9DXWFQE6BSeoRK/9+nB3fnJvIH7QfwxQdAobAjNTXSFgkMaqgLDGoClOVUYbZzE/kHy0yN0qcJixypqRGDGrZzU1cY1AQoq6DGxtwaIvI+y5qaQGjnBoAwXdfD98yZGhYKk30MagJUnxhzINOHmRoiv2CZqQmUoEbcqdteUCPV1DBTQ13gMyRAWRbcddb51F07SIi6K8s5NXEBEtSIy0/2NrSsZU0NOYiZGsLI3lG+PgQigvVE4Z4B0M4NAHqxpdvONgksFCZHMaghdj4R+QnLDS0DZfkp1IFMTQ2H75GDGNQQEfmhQGjnBsw1NQ12C4VNNTXM1FBX+AzpZljnQhQYhiZF+voQvMKhmhoxU8OghrrATA0RkR/qFRPa9Y0UQE5NDbdJoK4wqCEiIp/RW2RqBEGweZvaRtbUkGMY1BARkc+IhcJGAWhqNdq8TQ2Xn8hBDGqIiMhnxL2fANsD+JpaDWhuC3ZYKExdYVBDREQ+o1GrEBJseiuqs7H/k7j0BJg7pYg6w6CGiIh8yt5WCZabWWrUnKlF9jHsJSKiTnljjESoVgPU2W7rltq5ue8TOYCZGiIi8il7A/iqOXiPZGBQQ0REPhWma2vrtlNTw84ncgSDGiIi8il7NTVcfiI5GNQQEZFPWW6VUN/cirSnvkTaU1+ivrnVYpowB+9R1xjUEBGRT4lBja2tEpipITkY1BARkU+F6TpffmKhMMnBoIaIiHxK3P+p3lZLNwuFSQYGNURE5FPiVgm25tRYDt8j6gqDGiIi8im9ruuaGhYKkyMY1BARkU+F2mvp5vITycCghoiIfEpv0dLdHguFSQ4GNURE5FNhHL5HbsKghoiIfEpvZ5sEsVA4gjU15AAGNURE5FPS8L12mRpBEKRMDZefyBEMaoiIyKc6W35qaDHAYBQAcPmJHMNniYvCtEHIf2mmrw+DiKjbMm9oab38VNfW4q1WmbM5RPYwU0NERD4VpjMvPxnbMjOAdZGwSqXyybFR9+JUULNmzRqkp6cjJCQEGRkZ2L17t93bf/zxxxg1ahTCwsKQlJSEefPmoaKiQrq+paUFzz//PPr164eQkBCMGjUKX3/9tcuPS0RE/k/M1ACmJSdRjdTOzSJhcozsoGbDhg1YvHgxli1bhiNHjmDy5MmYMWMGCgoKbN5+z549uOuuu3DffffhxIkT+OSTT3Dw4EHMnz9fus3y5cvx1ltv4Y033kB2djYWLFiAW265BUeOHHH6cf2JuESV/9JMae2YiIhMQoLVEBMxlkFNbdvyE4uEyVGyg5pVq1bhvvvuw/z58zFkyBCsXr0aKSkpWLt2rc3b79u3D2lpaVi0aBHS09MxadIkPPjggzh06JB0m48++ghPP/00rr/+evTt2xcPPfQQpk+fjldffdXpxyUiou5BpVIhLLhjB1QtB++RTLKCmubmZmRlZWHatGlWl0+bNg179+61+TOZmZk4d+4ctmzZAkEQcP78eXz66aeYOdNcXNvU1ISQkBCrnwsNDcWePXucflzxfqurq62+iIjI/4TpOhYLi5kaT3U+MYuuPLKCmvLychgMBiQkJFhdnpCQgNLSUps/k5mZiY8//hizZ8+GVqtFYmIioqOj8cYbb0i3mT59OlatWoWcnBwYjUZs374dn3/+OUpKSpx+XABYuXIloqKipK+UlBQ5vy4REXmJuFWC5aaWYqYmnDU15CCnCoXbV6ELgtBpZXp2djYWLVqEZ599FllZWfj666+Rl5eHBQsWSLd57bXXMGDAAAwePBharRaPPvoo5s2bB43GuoVPzuMCwNKlS1FVVSV9FRYWyv1ViYjIC2zNquHgPZJL1jMlLi4OGo2mQ3akrKysQxZFtHLlSkycOBFPPPEEAGDkyJHQ6/WYPHkyXnjhBSQlJSE+Ph6fffYZGhsbUVFRgeTkZDz11FNIT093+nEBQKfTQafTyfkViYjIB8Q5NDYLhTl4jxwkK1Oj1WqRkZGB7du3W12+fft2ZGZm2vyZ+vp6qNXWDyNmYARBsLo8JCQEvXr1QmtrKzZu3IibbrrJ6cclIqLuw3ZNTeAVCrPOxzWyz9iSJUswd+5cjB49GhMmTMDbb7+NgoICaTlp6dKlKCoqwrp16wAAs2bNwv3334+1a9di+vTpKCkpweLFizF27FgkJycDAPbv34+ioiJcdtllKCoqwooVK2A0GvHkk086/LhERNR96W3s/+TpQmFSHtnPlNmzZ6OiogLPP/88SkpKMHz4cGzZsgWpqakAgJKSEqvZMffccw9qamrw5ptv4vHHH0d0dDSuueYavPzyy9JtGhsbsXz5cuTm5iI8PBzXX389PvroI0RHRzv8uERE1H1JNTU2CoU5fI8c5VT4+/DDD+Phhx+2ed0HH3zQ4bKFCxdi4cKFnd7flClTkJ2d7dLjEhFR9yXt1G2jpiY8gJafyDXc+4mIiHzOvP+TuaZG2iaBy0/kIAY1RETkc3obLd110jYJXH4ixzCoISIinwuzWSjctks3l5/IQQxqiIjI5/Q2Wrrrmjl8j+RhUENERD4nDd+zyNSIo8zY0k2OYlBDREQ+Z2ubBADQatQICdbY+hGiDhjUEBGRz9kavgewnobkYVBDREQ+Z2ubBIBLTyQPgxoiIvK5zjI1LBImORjUEBGRz4XaKBQGmKkheRjUEBGRz4nD95pajVaXc/AeycGghoiIfE7cJqE9Lj+RHAxqiIjI57QaNYLUqg6XM6ghORjUEBGRz6lUKqmuxhJrakgOBjVEROQXxLoaS5xTQ3IwqCEiIr9gq66GhcIkB4MaIiLyC7YyNRFcfiIZGNQQEZFfCLNRU8NCYZKDQQ0REfkFW0ENC4VJDgY1RETkF8JsBDCsqSE5GNQQEZFf0HP5iVzEoIaIiPxCmK2Wbi4/kQwMaoiIyC/obbR0c04NycGghoiI/EL7TE1IsBrBGr5NkeP4bCEiIr/QvvuJS08kF4MaIiLyC+2H7zGoIbkY1BARkV9ov00CO59ILgY1RETkF9ovP+mZqSGZGNQQEZFfaF8ozOUnkovPGCIiPxGmDUL+SzN9fRg+06GmhstPJBOfMQEq0F88icj/tK+pYaaG5OLyExER+YX2mZoIBjUkE4MaIiLyC6EsFCYXMaghIiK/0L77iS3dJBeDGiIi8gvBGjW0Qea3JdbUkFwMaoiIyG9YZmu4/ERyMaghIiK/YRnUcPmJ5GJQQ0REfiM02BzUcPmJ5GJQQ0REfsNyqjCH75FcDGqIiMhvWC4/MVNDcjGoISIiv2E5Vbj9MD6irjCoISIivxFmUVOjVqt8eCTUHTGoISIiv9F+p24iORjUEBGR32g/VZhIDgY1RETkNxjUkCsY1BARkd/g8hO5gkENERH5jbgIra8PgboxBjVEROQ3pg9L9PUhUDfGoIaIiPxGSDBrash5DGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBTBqaBmzZo1SE9PR0hICDIyMrB79267t//4448xatQohIWFISkpCfPmzUNFRYXVbVavXo1BgwYhNDQUKSkp+N3vfofGxkbp+hUrVkClUll9JSYmOnP4REREpECyg5oNGzZg8eLFWLZsGY4cOYLJkydjxowZKCgosHn7PXv24K677sJ9992HEydO4JNPPsHBgwcxf/586TYff/wxnnrqKTz33HM4efIk/v73v2PDhg1YunSp1X0NGzYMJSUl0tfx48flHj4REREpVJDcH1i1ahXuu+8+KShZvXo1tm7dirVr12LlypUdbr9v3z6kpaVh0aJFAID09HQ8+OCDeOWVV6Tb/PDDD5g4cSLuuOMOAEBaWhrmzJmDAwcOWB9sUBCzM0RERGSTrExNc3MzsrKyMG3aNKvLp02bhr1799r8mczMTJw7dw5btmyBIAg4f/48Pv30U8ycOVO6zaRJk5CVlSUFMbm5udiyZYvVbQAgJycHycnJSE9Px+23347c3Fy7x9vU1ITq6mqrLyIiIlImWUFNeXk5DAYDEhISrC5PSEhAaWmpzZ/JzMzExx9/jNmzZ0Or1SIxMRHR0dF44403pNvcfvvt+OMf/4hJkyYhODgY/fr1w9VXX42nnnpKus24ceOwbt06bN26Fe+88w5KS0uRmZnZoTbH0sqVKxEVFSV9paSkyPl1iYiIqBtxqlBYpVJZfS8IQofLRNnZ2Vi0aBGeffZZZGVl4euvv0ZeXh4WLFgg3Wbnzp3405/+hDVr1uDw4cPYtGkTvvjiC/zxj3+UbjNjxgzceuutGDFiBKZOnYovv/wSAPDhhx92epxLly5FVVWV9FVYWOjMr0tERETdgKyamri4OGg0mg5ZmbKysg7ZG9HKlSsxceJEPPHEEwCAkSNHQq/XY/LkyXjhhReQlJSEZ555BnPnzpXqdEaMGIG6ujo88MADWLZsGdTqjrGXXq/HiBEjkJOT0+nx6nQ66HQ6Ob8iERERdVOyMjVarRYZGRnYvn271eXbt29HZmamzZ+pr6/vEJRoNBoApgyPvdsIgiDdpr2mpiacPHkSSUlJcn4FIiIiUijZ3U9LlizB3LlzMXr0aEyYMAFvv/02CgoKpOWkpUuXoqioCOvWrQMAzJo1C/fffz/Wrl2L6dOno6SkBIsXL8bYsWORnJws3WbVqlW4/PLLMW7cOJw+fRrPPPMMbrzxRikA+v3vf49Zs2ahT58+KCsrwwsvvIDq6mrcfffd7joXRERE1I3JDmpmz56NiooKPP/88ygpKcHw4cOxZcsWpKamAgBKSkqsZtbcc889qKmpwZtvvonHH38c0dHRuOaaa/Dyyy9Lt1m+fDlUKhWWL1+OoqIixMfHY9asWfjTn/4k3ebcuXOYM2cOysvLER8fj/Hjx2Pfvn3S4xIREVFgUwmdre8oUHV1NaKiolBVVYXIyEhfHw4REbVT39yKoc9uBQBkPz8dYVrZn71JgRx9/+beT0RERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaIiIiUgQGNURERKQIDGqIiIhIERjUEBERkSIwqCEiIiJFCPL1ARAREYnCtEHIf2mmrw+DuilmaoiIiEgRGNQQERGRIjCoISIiIkVgUENERESKwKCGiIiIFIFBDRERESkCgxoiIiJSBAY1REREpAgMaoiIiEgRGNQQERGRIjCoISIiIkVgUENERESKwKCGiIiIFIFBDRERESkCgxoiIiJShCBfH4A3CYIAAKiurvbxkRAREZGjxPdt8X28MwEV1NTU1AAAUlJSfHwkREREJFdNTQ2ioqI6vV4ldBX2KIjRaERxcTEiIiKgUqncdr/V1dVISUlBYWEhIiMj3Xa/ZBvPt3fxfHsXz7d38Xx7l7PnWxAE1NTUIDk5GWp155UzAZWpUavV6N27t8fuPzIykn8UXsTz7V08397F8+1dPN/e5cz5tpehEbFQmIiIiBSBQQ0REREpAoMaN9DpdHjuueeg0+l8fSgBgefbu3i+vYvn27t4vr3L0+c7oAqFiYiISLmYqSEiIiJFYFBDREREisCghoiIiBSBQQ0REREpAoMaN1izZg3S09MREhKCjIwM7N6929eHpAjfffcdZs2aheTkZKhUKnz22WdW1wuCgBUrViA5ORmhoaG46qqrcOLECd8cbDe3cuVKjBkzBhEREejZsyduvvlmnDp1yuo2PN/us3btWowcOVIaQDZhwgR89dVX0vU81561cuVKqFQqLF68WLqM59x9VqxYAZVKZfWVmJgoXe/Jc82gxkUbNmzA4sWLsWzZMhw5cgSTJ0/GjBkzUFBQ4OtD6/bq6uowatQovPnmmzavf+WVV7Bq1Sq8+eabOHjwIBITE/GrX/1K2uOLHLdr1y488sgj2LdvH7Zv347W1lZMmzYNdXV10m14vt2nd+/eeOmll3Do0CEcOnQI11xzDW666SbphZ3n2nMOHjyIt99+GyNHjrS6nOfcvYYNG4aSkhLp6/jx49J1Hj3XArlk7NixwoIFC6wuGzx4sPDUU0/56IiUCYCwefNm6Xuj0SgkJiYKL730knRZY2OjEBUVJfztb3/zwREqS1lZmQBA2LVrlyAIPN/eEBMTI7z77rs81x5UU1MjDBgwQNi+fbswZcoU4bHHHhMEgc9vd3vuueeEUaNG2bzO0+eamRoXNDc3IysrC9OmTbO6fNq0adi7d6+Pjiow5OXlobS01Orc63Q6TJkyhefeDaqqqgAAPXr0AMDz7UkGgwHr169HXV0dJkyYwHPtQY888ghmzpyJqVOnWl3Oc+5+OTk5SE5ORnp6Om6//Xbk5uYC8Py5DqgNLd2tvLwcBoMBCQkJVpcnJCSgtLTUR0cVGMTza+vcnz171heHpBiCIGDJkiWYNGkShg8fDoDn2xOOHz+OCRMmoLGxEeHh4di8eTOGDh0qvbDzXLvX+vXrcfjwYRw8eLDDdXx+u9e4ceOwbt06DBw4EOfPn8cLL7yAzMxMnDhxwuPnmkGNG6hUKqvvBUHocBl5Bs+9+z366KM4duwY9uzZ0+E6nm/3GTRoEI4ePYrKykps3LgRd999N3bt2iVdz3PtPoWFhXjsscewbds2hISEdHo7nnP3mDFjhvT/I0aMwIQJE9CvXz98+OGHGD9+PADPnWsuP7kgLi4OGo2mQ1amrKysQxRK7iVW0vPcu9fChQvx73//G99++y169+4tXc7z7X5arRb9+/fH6NGjsXLlSowaNQqvvfYaz7UHZGVloaysDBkZGQgKCkJQUBB27dqF119/HUFBQdJ55Tn3DL1ejxEjRiAnJ8fjz28GNS7QarXIyMjA9u3brS7fvn07MjMzfXRUgSE9PR2JiYlW5765uRm7du3iuXeCIAh49NFHsWnTJuzYsQPp6elW1/N8e54gCGhqauK59oBrr70Wx48fx9GjR6Wv0aNH484778TRo0fRt29fnnMPampqwsmTJ5GUlOT557fLpcYBbv369UJwcLDw97//XcjOzhYWL14s6PV6IT8/39eH1u3V1NQIR44cEY4cOSIAEFatWiUcOXJEOHv2rCAIgvDSSy8JUVFRwqZNm4Tjx48Lc+bMEZKSkoTq6mofH3n389BDDwlRUVHCzp07hZKSEumrvr5eug3Pt/ssXbpU+O6774S8vDzh2LFjwtNPPy2o1Wph27ZtgiDwXHuDZfeTIPCcu9Pjjz8u7Ny5U8jNzRX27dsn3HDDDUJERIT0vujJc82gxg3++te/CqmpqYJWqxWuuOIKqQ2WXPPtt98KADp83X333YIgmFoDn3vuOSExMVHQ6XTClVdeKRw/fty3B91N2TrPAIT3339fug3Pt/vce++90mtGfHy8cO2110oBjSDwXHtD+6CG59x9Zs+eLSQlJQnBwcFCcnKy8Otf/1o4ceKEdL0nz7VKEATB9XwPERERkW+xpoaIiIgUgUENERERKQKDGiIiIlIEBjVERESkCAxqiIiISBEY1BAREZEiMKghIiIiRWBQQ0RERIrAoIaIiIgUgUENERERKQKDGiIiIlIEBjVERESkCP8fvtIv5TzD+LoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_2.plot.line(y='mean_test_score', yerr='std_test_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1cc7779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_2.best_index_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7047c00",
   "metadata": {},
   "source": [
    "Marginal improvement, but lambda can be increased even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c97fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_3 = {\n",
    "    'n_estimators': Integer(2000, 5000, prior='log-uniform', base=10),\n",
    "    'max_depth': Integer(2, 4, prior='uniform'),\n",
    "    'learning_rate': Real(0.05, 0.2, prior='log-uniform', base=10),\n",
    "    'reg_lambda': Real(50, 1000, prior='log-uniform', base=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f0469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_clf_3 = XGBClassifier(random_state=8,\n",
    "                         max_leaves=0,\n",
    "                         n_jobs=-1,\n",
    "                           reg_alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8303b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_3 = BayesSearchCV(estimator=xgboost_clf_3,\n",
    "                       search_spaces=space_3,\n",
    "                       n_iter=50, \n",
    "                       scoring='roc_auc',\n",
    "                       n_jobs=1,\n",
    "                       n_points=1, \n",
    "                       refit=True,\n",
    "                       cv=5,\n",
    "                       verbose=1,\n",
    "                       random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47d670ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "CPU times: user 4h 47min 38s, sys: 2min 23s, total: 4h 50min 2s\n",
      "Wall time: 1h 12min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "search_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b4bb9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.12613697225614465),\n",
       "             ('max_depth', 3),\n",
       "             ('n_estimators', 4894),\n",
       "             ('reg_lambda', 79.49916855475958)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4904118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992639785535159"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72815aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_3 = pd.DataFrame(search_2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f0e0d7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_3.plot.line(y='mean_test_score', yerr='std_test_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa07c33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_3.best_index_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d26ad",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba63f2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42100</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42101</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42102</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42103</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42104</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70163</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70164</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70165</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70166</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70167</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "id                                                                             \n",
       "42100             3               0                     1                  4   \n",
       "42101             2               0                     0                  3   \n",
       "42102             2               2                     0                  1   \n",
       "42103             2               0                     0                  3   \n",
       "42104             1               0                     0                  2   \n",
       "...             ...             ...                   ...                ...   \n",
       "70163             2               0                     1                  2   \n",
       "70164             2               0                     2                  2   \n",
       "70165             2               0                     1                  2   \n",
       "70166             3               0                     0                  4   \n",
       "70167             2               0                     2                  3   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "id                                                                         \n",
       "42100                  0                           0                   1   \n",
       "42101                  0                           0                   0   \n",
       "42102                  0                           0                   3   \n",
       "42103                  0                           0                   0   \n",
       "42104                  2                           0                   0   \n",
       "...                  ...                         ...                 ...   \n",
       "70163                  0                           0                   0   \n",
       "70164                  0                           0                   0   \n",
       "70165                  0                           0                   0   \n",
       "70166                  0                           0                   1   \n",
       "70167                  0                           0                   0   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "id                                                            \n",
       "42100        111          2018             12             5   \n",
       "42101         22          2017             10            21   \n",
       "42102         18          2018              8            10   \n",
       "42103         88          2018              5            30   \n",
       "42104          7          2018              9            21   \n",
       "...          ...           ...            ...           ...   \n",
       "70163        315          2018              9            30   \n",
       "70164         81          2018              3            25   \n",
       "70165         40          2018             10            22   \n",
       "70166          4          2018              9             6   \n",
       "70167        191          2018              8            28   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "id                                                                         \n",
       "42100                    1               0                             0   \n",
       "42101                    0               0                             0   \n",
       "42102                    1               0                             0   \n",
       "42103                    0               0                             0   \n",
       "42104                    1               0                             0   \n",
       "...                    ...             ...                           ...   \n",
       "70163                    1               0                             0   \n",
       "70164                    0               0                             0   \n",
       "70165                    0               0                             0   \n",
       "70166                    1               0                             0   \n",
       "70167                    1               0                             0   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "id                                                                \n",
       "42100                                     0              115.60   \n",
       "42101                                     0               85.00   \n",
       "42102                                     0              240.00   \n",
       "42103                                     0               80.75   \n",
       "42104                                     0              144.00   \n",
       "...                                     ...                 ...   \n",
       "70163                                     0              160.00   \n",
       "70164                                     0               65.00   \n",
       "70165                                     0               85.00   \n",
       "70166                                     0              162.75   \n",
       "70167                                     0               84.31   \n",
       "\n",
       "       no_of_special_requests  \n",
       "id                             \n",
       "42100                       2  \n",
       "42101                       0  \n",
       "42102                       1  \n",
       "42103                       0  \n",
       "42104                       0  \n",
       "...                       ...  \n",
       "70163                       0  \n",
       "70164                       1  \n",
       "70165                       0  \n",
       "70166                       0  \n",
       "70167                       0  \n",
       "\n",
       "[28068 rows x 17 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./data/test.csv', index_col='id'); test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "624223ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42100</th>\n",
       "      <td>2.056005</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>1.122386</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>0.685890</td>\n",
       "      <td>0.087728</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>1.557404</td>\n",
       "      <td>-1.226638</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>0.297092</td>\n",
       "      <td>1.842849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42101</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>0.421768</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-1.010111</td>\n",
       "      <td>-2.441040</td>\n",
       "      <td>0.850531</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.526846</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42102</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>4.129777</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.979466</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>3.088017</td>\n",
       "      <td>-1.059452</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.143658</td>\n",
       "      <td>-0.664112</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>3.646696</td>\n",
       "      <td>0.552579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42103</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>0.421768</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-0.195983</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>-0.916652</td>\n",
       "      <td>1.585992</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.641282</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42104</th>\n",
       "      <td>-1.753925</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>2.996268</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-1.195140</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.497095</td>\n",
       "      <td>0.573445</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>1.061793</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70163</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>2.604122</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.497095</td>\n",
       "      <td>1.585992</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>1.492610</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70164</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>1.259332</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-0.282330</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>-1.623525</td>\n",
       "      <td>1.023466</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-1.065367</td>\n",
       "      <td>0.552579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70165</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>0.130259</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>-0.788076</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.850531</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>-1.149928</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.526846</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70166</th>\n",
       "      <td>2.056005</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>-0.998814</td>\n",
       "      <td>1.122386</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>0.685890</td>\n",
       "      <td>-1.232145</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.497095</td>\n",
       "      <td>-1.114133</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>1.566656</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70167</th>\n",
       "      <td>0.151040</td>\n",
       "      <td>-0.313454</td>\n",
       "      <td>1.259332</td>\n",
       "      <td>0.421768</td>\n",
       "      <td>-0.407020</td>\n",
       "      <td>-0.160945</td>\n",
       "      <td>-0.515173</td>\n",
       "      <td>1.074549</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.143658</td>\n",
       "      <td>1.360982</td>\n",
       "      <td>0.428551</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.060506</td>\n",
       "      <td>-0.101479</td>\n",
       "      <td>-0.545425</td>\n",
       "      <td>-0.737691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "id                                                                             \n",
       "42100      2.056005       -0.313454              0.130259           1.122386   \n",
       "42101      0.151040       -0.313454             -0.998814           0.421768   \n",
       "42102      0.151040        4.129777             -0.998814          -0.979466   \n",
       "42103      0.151040       -0.313454             -0.998814           0.421768   \n",
       "42104     -1.753925       -0.313454             -0.998814          -0.278849   \n",
       "...             ...             ...                   ...                ...   \n",
       "70163      0.151040       -0.313454              0.130259          -0.278849   \n",
       "70164      0.151040       -0.313454              1.259332          -0.278849   \n",
       "70165      0.151040       -0.313454              0.130259          -0.278849   \n",
       "70166      2.056005       -0.313454             -0.998814           1.122386   \n",
       "70167      0.151040       -0.313454              1.259332           0.421768   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "id                                                                         \n",
       "42100          -0.407020                   -0.160945            0.685890   \n",
       "42101          -0.407020                   -0.160945           -0.515173   \n",
       "42102          -0.407020                   -0.160945            3.088017   \n",
       "42103          -0.407020                   -0.160945           -0.515173   \n",
       "42104           2.996268                   -0.160945           -0.515173   \n",
       "...                  ...                         ...                 ...   \n",
       "70163          -0.407020                   -0.160945           -0.515173   \n",
       "70164          -0.407020                   -0.160945           -0.515173   \n",
       "70165          -0.407020                   -0.160945           -0.515173   \n",
       "70166          -0.407020                   -0.160945            0.685890   \n",
       "70167          -0.407020                   -0.160945           -0.515173   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "id                                                            \n",
       "42100   0.087728      0.409661       1.557404     -1.226638   \n",
       "42101  -1.010111     -2.441040       0.850531      0.573445   \n",
       "42102  -1.059452      0.409661       0.143658     -0.664112   \n",
       "42103  -0.195983      0.409661      -0.916652      1.585992   \n",
       "42104  -1.195140      0.409661       0.497095      0.573445   \n",
       "...          ...           ...            ...           ...   \n",
       "70163   2.604122      0.409661       0.497095      1.585992   \n",
       "70164  -0.282330      0.409661      -1.623525      1.023466   \n",
       "70165  -0.788076      0.409661       0.850531      0.685950   \n",
       "70166  -1.232145      0.409661       0.497095     -1.114133   \n",
       "70167   1.074549      0.409661       0.143658      1.360982   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "id                                                                         \n",
       "42100             0.428551       -0.173408                     -0.060506   \n",
       "42101            -1.149928       -0.173408                     -0.060506   \n",
       "42102             0.428551       -0.173408                     -0.060506   \n",
       "42103            -1.149928       -0.173408                     -0.060506   \n",
       "42104             0.428551       -0.173408                     -0.060506   \n",
       "...                    ...             ...                           ...   \n",
       "70163             0.428551       -0.173408                     -0.060506   \n",
       "70164            -1.149928       -0.173408                     -0.060506   \n",
       "70165            -1.149928       -0.173408                     -0.060506   \n",
       "70166             0.428551       -0.173408                     -0.060506   \n",
       "70167             0.428551       -0.173408                     -0.060506   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "id                                                                \n",
       "42100                             -0.101479            0.297092   \n",
       "42101                             -0.101479           -0.526846   \n",
       "42102                             -0.101479            3.646696   \n",
       "42103                             -0.101479           -0.641282   \n",
       "42104                             -0.101479            1.061793   \n",
       "...                                     ...                 ...   \n",
       "70163                             -0.101479            1.492610   \n",
       "70164                             -0.101479           -1.065367   \n",
       "70165                             -0.101479           -0.526846   \n",
       "70166                             -0.101479            1.566656   \n",
       "70167                             -0.101479           -0.545425   \n",
       "\n",
       "       no_of_special_requests  \n",
       "id                             \n",
       "42100                1.842849  \n",
       "42101               -0.737691  \n",
       "42102                0.552579  \n",
       "42103               -0.737691  \n",
       "42104               -0.737691  \n",
       "...                       ...  \n",
       "70163               -0.737691  \n",
       "70164                0.552579  \n",
       "70165               -0.737691  \n",
       "70166               -0.737691  \n",
       "70167               -0.737691  \n",
       "\n",
       "[28068 rows x 17 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adee3ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8794274 , 0.12057264],\n",
       "       [0.93384933, 0.06615064],\n",
       "       [0.6442263 , 0.35577366],\n",
       "       ...,\n",
       "       [0.9308622 , 0.06913778],\n",
       "       [0.41879284, 0.58120716],\n",
       "       [0.09027481, 0.9097252 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = search.predict_proba(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06492a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42100</td>\n",
       "      <td>0.120573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42101</td>\n",
       "      <td>0.066151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42102</td>\n",
       "      <td>0.355774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42103</td>\n",
       "      <td>0.047295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42104</td>\n",
       "      <td>0.325677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28063</th>\n",
       "      <td>70163</td>\n",
       "      <td>0.911546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28064</th>\n",
       "      <td>70164</td>\n",
       "      <td>0.037858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28065</th>\n",
       "      <td>70165</td>\n",
       "      <td>0.069138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>70166</td>\n",
       "      <td>0.581207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28067</th>\n",
       "      <td>70167</td>\n",
       "      <td>0.909725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  booking_status\n",
       "0      42100        0.120573\n",
       "1      42101        0.066151\n",
       "2      42102        0.355774\n",
       "3      42103        0.047295\n",
       "4      42104        0.325677\n",
       "...      ...             ...\n",
       "28063  70163        0.911546\n",
       "28064  70164        0.037858\n",
       "28065  70165        0.069138\n",
       "28066  70166        0.581207\n",
       "28067  70167        0.909725\n",
       "\n",
       "[28068 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'id': X_test.index, 'booking_status':y_pred[:, 1]})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84372fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('bayes_search_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7fe31a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89191437, 0.10808564],\n",
       "       [0.94127655, 0.05872346],\n",
       "       [0.54789585, 0.45210415],\n",
       "       ...,\n",
       "       [0.93234897, 0.06765104],\n",
       "       [0.49088573, 0.50911427],\n",
       "       [0.08618528, 0.9138147 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = search_2.predict_proba(X_test)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c08e821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42100</td>\n",
       "      <td>0.108086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42101</td>\n",
       "      <td>0.058723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42102</td>\n",
       "      <td>0.452104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42103</td>\n",
       "      <td>0.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42104</td>\n",
       "      <td>0.401423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28063</th>\n",
       "      <td>70163</td>\n",
       "      <td>0.914897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28064</th>\n",
       "      <td>70164</td>\n",
       "      <td>0.030142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28065</th>\n",
       "      <td>70165</td>\n",
       "      <td>0.067651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>70166</td>\n",
       "      <td>0.509114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28067</th>\n",
       "      <td>70167</td>\n",
       "      <td>0.913815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  booking_status\n",
       "0      42100        0.108086\n",
       "1      42101        0.058723\n",
       "2      42102        0.452104\n",
       "3      42103        0.042141\n",
       "4      42104        0.401423\n",
       "...      ...             ...\n",
       "28063  70163        0.914897\n",
       "28064  70164        0.030142\n",
       "28065  70165        0.067651\n",
       "28066  70166        0.509114\n",
       "28067  70167        0.913815\n",
       "\n",
       "[28068 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = pd.DataFrame({'id': X_test.index, 'booking_status':y_pred_2[:, 1]})\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92354907",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2.to_csv('bayes_search_xgboost_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "470b2c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87308025, 0.12691975],\n",
       "       [0.94111997, 0.05888005],\n",
       "       [0.56395143, 0.43604857],\n",
       "       ...,\n",
       "       [0.93267506, 0.06732492],\n",
       "       [0.48821574, 0.51178426],\n",
       "       [0.08909529, 0.9109047 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_3 = search_3.predict_proba(X_test)\n",
    "y_pred_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f260b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42100</td>\n",
       "      <td>0.126920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42101</td>\n",
       "      <td>0.058880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42102</td>\n",
       "      <td>0.436049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42103</td>\n",
       "      <td>0.043721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42104</td>\n",
       "      <td>0.387253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28063</th>\n",
       "      <td>70163</td>\n",
       "      <td>0.921964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28064</th>\n",
       "      <td>70164</td>\n",
       "      <td>0.037139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28065</th>\n",
       "      <td>70165</td>\n",
       "      <td>0.067325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>70166</td>\n",
       "      <td>0.511784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28067</th>\n",
       "      <td>70167</td>\n",
       "      <td>0.910905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  booking_status\n",
       "0      42100        0.126920\n",
       "1      42101        0.058880\n",
       "2      42102        0.436049\n",
       "3      42103        0.043721\n",
       "4      42104        0.387253\n",
       "...      ...             ...\n",
       "28063  70163        0.921964\n",
       "28064  70164        0.037139\n",
       "28065  70165        0.067325\n",
       "28066  70166        0.511784\n",
       "28067  70167        0.910905\n",
       "\n",
       "[28068 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_3 = pd.DataFrame({'id': X_test.index, 'booking_status':y_pred_3[:, 1]})\n",
    "result_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb25b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3.to_csv('bayes_search_xgboost_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6780b3c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The min_resources parameter was too small so the best manually seleted HP was left out at the first iteration. The resulting score was a bit lower both on crocc-validation and the public test set at the platform.\n",
    "Need to retry with a larger min. samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
